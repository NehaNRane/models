{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ff154a0-abe5-4a30-90ba-0393bd1ffc9d",
   "metadata": {},
   "source": [
    "# Data: Ad Sales Data\n",
    "# Use Case: Revenue Prediction\n",
    "# Model: Regression Models\n",
    "\n",
    "Code link: https://www.kaggle.com/code/akshaysunil07/ad-tech-revenue-regression/notebook "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83c8bfe",
   "metadata": {},
   "source": [
    "# Installing packages section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddb0b697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "Collecting pip\n",
      "  Downloading pip-24.2-py3-none-any.whl.metadata (3.6 kB)\n",
      "Downloading pip-24.2-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "Successfully installed pip-24.2\n",
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "Collecting snowflake-snowpark-python==1.9.0\n",
      "  Using cached snowflake_snowpark_python-1.9.0-py3-none-any.whl.metadata (44 kB)\n",
      "Collecting fosforio==1.0.1\n",
      "  Downloading fosforio-1.0.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting snowflake-connector-python[pandas]\n",
      "  Using cached snowflake_connector_python-3.12.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (64 kB)\n",
      "Using cached snowflake_snowpark_python-1.9.0-py3-none-any.whl (327 kB)\n",
      "Downloading fosforio-1.0.1-py3-none-any.whl (20 kB)\n",
      "Using cached snowflake_connector_python-3.12.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
      "Installing collected packages: fosforio, snowflake-snowpark-python, snowflake-connector-python\n",
      "Successfully installed fosforio-1.0.1 snowflake-connector-python-3.12.0 snowflake-snowpark-python-1.9.0\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/fosforio already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/snowflake_snowpark_python-1.9.0-py3.11-nspkg.pth already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/snowflake already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/snowflake_snowpark_python-1.9.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/snowflake_connector_python-3.12.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/bin already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0mWARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "Collecting fosforml==1.0.1\n",
      "  Using cached fosforml-1.0.1-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting pandas==2.2.2\n",
      "  Using cached pandas-2.2.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.9.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting scikit-learn==1.5.1\n",
      "  Using cached scikit_learn-1.5.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting xgboost\n",
      "  Using cached xgboost-2.1.1-py3-none-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting python-dateutil\n",
      "  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Downloading fosforml-1.0.1-py3-none-any.whl (42 kB)\n",
      "Using cached pandas-2.2.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "Downloading scikit_learn-1.5.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m104.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached matplotlib-3.9.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
      "Using cached xgboost-2.1.1-py3-none-manylinux_2_28_x86_64.whl (153.9 MB)\n",
      "Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "Installing collected packages: fosforml, xgboost, scikit-learn, python-dateutil, pandas, matplotlib\n",
      "Successfully installed fosforml-1.0.1 matplotlib-3.9.1 pandas-2.2.2 python-dateutil-2.9.0.post0 scikit-learn-1.5.1 xgboost-2.1.1\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/fosforml already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/tests already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/xgboost already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/xgboost-2.1.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/xgboost.libs already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/sklearn already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/scikit_learn.libs already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/dateutil already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/python_dateutil-2.9.0.post0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/pandas already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/pandas-2.2.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/pylab.py already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/matplotlib already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/matplotlib-3.9.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/mpl_toolkits already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/__pycache__ already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0mWARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "Collecting pytz==2024.1\n",
      "  Using cached pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting six==1.16.0\n",
      "  Using cached six-1.16.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting tzdata==2024.1\n",
      "  Using cached tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting numpy==1.26.4\n",
      "  Downloading numpy-1.26.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Using cached pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Using cached tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "Downloading numpy-1.26.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m120.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pytz, tzdata, six, numpy\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "jupyterlab 3.2.4 requires jupyter-server~=1.4, but you have jupyter-server 2.7.3 which is incompatible.\n",
      "mosaic-ai-client 1.0.0 requires matplotlib==3.1.1, but you have matplotlib 3.9.1 which is incompatible.\n",
      "mosaic-ai-serving 1.0.0 requires Flask==2.1.1; python_version >= \"3.7\", but you have flask 2.2.5 which is incompatible.\n",
      "mosaic-ai-serving 1.0.0 requires matplotlib==3.6.0; python_version >= \"3.8\", but you have matplotlib 3.9.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-1.26.4 pytz-2024.1 six-1.16.0 tzdata-2024.1\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/pytz already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/pytz-2024.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/tzdata already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/tzdata-2024.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/six.py already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/six-1.16.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/__pycache__ already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/numpy already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/numpy.libs already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/bin already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0mWARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "fosforml 1.0.0 requires cloudpickle==1.6.0, but you have cloudpickle 2.0.0 which is incompatible.\n",
      "fosforml 1.0.0 requires PyYAML==6.0, but you have pyyaml 6.0.1 which is incompatible.\n",
      "fosforml 1.0.0 requires urllib3==1.26.15, but you have urllib3 1.26.19 which is incompatible.\n",
      "jsonschema-path 0.3.2 requires referencing<0.32.0,>=0.28.0, but you have referencing 0.33.0 which is incompatible.\n",
      "jupyterlab 3.2.4 requires jupyter-server~=1.4, but you have jupyter-server 2.7.3 which is incompatible.\n",
      "mosaic-ai-client 1.0.0 requires matplotlib==3.1.1, but you have matplotlib 3.9.1 which is incompatible.\n",
      "mosaic-ai-serving 1.0.0 requires Flask==2.1.1; python_version >= \"3.7\", but you have flask 2.2.5 which is incompatible.\n",
      "mosaic-ai-serving 1.0.0 requires matplotlib==3.6.0; python_version >= \"3.8\", but you have matplotlib 3.9.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mWARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "Found existing installation: urllib3 1.26.15\n",
      "Uninstalling urllib3-1.26.15:\n",
      "  Successfully uninstalled urllib3-1.26.15\n",
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "Collecting urllib3==1.26.15\n",
      "  Using cached urllib3-1.26.15-py2.py3-none-any.whl.metadata (48 kB)\n",
      "Using cached urllib3-1.26.15-py2.py3-none-any.whl (140 kB)\n",
      "Installing collected packages: urllib3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "fosforml 1.0.0 requires PyYAML==6.0, but you have pyyaml 6.0.1 which is incompatible.\n",
      "jsonschema-path 0.3.2 requires referencing<0.32.0,>=0.28.0, but you have referencing 0.33.0 which is incompatible.\n",
      "mosaic-ai-client 1.0.0 requires matplotlib==3.1.1, but you have matplotlib 3.9.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed urllib3-1.26.15\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/urllib3 already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0mWARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "Collecting seaborn\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting numpy!=1.24.0,>=1.20 (from seaborn)\n",
      "  Using cached numpy-2.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "Collecting pandas>=1.2 (from seaborn)\n",
      "  Using cached pandas-2.2.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Collecting matplotlib!=3.6.1,>=3.4 (from seaborn)\n",
      "  Using cached matplotlib-3.9.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Using cached contourpy-1.2.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Using cached fonttools-4.53.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (162 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Using cached kiwisolver-1.4.5-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting packaging>=20.0 (from matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Using cached packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting pillow>=8 (from matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Using cached pillow-10.4.0-cp39-cp39-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Using cached pyparsing-3.1.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting python-dateutil>=2.7 (from matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting importlib-resources>=3.2.0 (from matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Using cached importlib_resources-6.4.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting pytz>=2020.1 (from pandas>=1.2->seaborn)\n",
      "  Using cached pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas>=1.2->seaborn)\n",
      "  Using cached tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting zipp>=3.1.0 (from importlib-resources>=3.2.0->matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Using cached zipp-3.19.2-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting six>=1.5 (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Using cached six-1.16.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Using cached matplotlib-3.9.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
      "Using cached numpy-2.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.5 MB)\n",
      "Using cached pandas-2.2.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "Using cached contourpy-1.2.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (304 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached fonttools-4.53.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "Using cached importlib_resources-6.4.0-py3-none-any.whl (38 kB)\n",
      "Using cached kiwisolver-1.4.5-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "Using cached packaging-24.1-py3-none-any.whl (53 kB)\n",
      "Using cached pillow-10.4.0-cp39-cp39-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "Using cached pyparsing-3.1.2-py3-none-any.whl (103 kB)\n",
      "Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "Using cached pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "Using cached tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Using cached zipp-3.19.2-py3-none-any.whl (9.0 kB)\n",
      "Installing collected packages: pytz, zipp, tzdata, six, pyparsing, pillow, packaging, numpy, kiwisolver, fonttools, cycler, python-dateutil, importlib-resources, contourpy, pandas, matplotlib, seaborn\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "fosforio 1.0.1 requires pandas==2.0.0, but you have pandas 2.2.2 which is incompatible.\n",
      "jupyterlab 3.2.4 requires jupyter-server~=1.4, but you have jupyter-server 2.7.3 which is incompatible.\n",
      "mosaic-ai-client 1.0.0 requires matplotlib==3.1.1, but you have matplotlib 3.9.1 which is incompatible.\n",
      "mosaic-ai-serving 1.0.0 requires Flask==2.1.1; python_version >= \"3.7\", but you have flask 2.2.5 which is incompatible.\n",
      "mosaic-ai-serving 1.0.0 requires matplotlib==3.6.0; python_version >= \"3.8\", but you have matplotlib 3.9.1 which is incompatible.\n",
      "numba 0.58.1 requires numpy<1.27,>=1.22, but you have numpy 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed contourpy-1.2.1 cycler-0.12.1 fonttools-4.53.1 importlib-resources-6.4.0 kiwisolver-1.4.5 matplotlib-3.9.1 numpy-2.0.1 packaging-24.1 pandas-2.2.2 pillow-10.4.0 pyparsing-3.1.2 python-dateutil-2.9.0.post0 pytz-2024.1 seaborn-0.13.2 six-1.16.0 tzdata-2024.1 zipp-3.19.2\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/pytz already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/pytz-2024.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/zipp already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/zipp-3.19.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/tzdata already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/tzdata-2024.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/six.py already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/six-1.16.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/__pycache__ already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/pyparsing already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/pyparsing-3.1.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/pillow.libs already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/PIL already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/pillow-10.4.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/packaging already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/packaging-24.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/numpy.libs already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/numpy already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/numpy-2.0.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/kiwisolver-1.4.5.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/kiwisolver already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/fontTools already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/fonttools-4.53.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/cycler already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/cycler-0.12.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/dateutil already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/python_dateutil-2.9.0.post0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/importlib_resources already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/importlib_resources-6.4.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/contourpy already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/contourpy-1.2.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/pandas already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/pandas-2.2.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/pylab.py already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/matplotlib already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/matplotlib-3.9.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/mpl_toolkits already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/seaborn already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/seaborn-0.13.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/bin already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/share already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Installing packages set for without init script\n",
    "!pip install --upgrade pip\n",
    "\n",
    "!pip install --upgrade snowflake-connector-python[pandas] \n",
    "!pip install --upgrade snowflake-snowpark-python[pandas] \n",
    "!pip install --upgrade snowflake-snowpark-python==1.9.0 \n",
    "!pip install --upgrade fosforio==1.0.1 --no-deps \n",
    "!pip install --upgrade fosforml==1.0.1 \n",
    "!pip install --upgrade pandas==2.2.2 --no-deps \n",
    "!pip install --upgrade matplotlib scikit-learn==1.5.1 xgboost python-dateutil\n",
    "!pip install --upgrade pytz==2024.1 six==1.16.0 tzdata==2024.1 numpy==1.26.4\n",
    "#!pip install tqdm \n",
    "!pip install --upgrade --q snowflake-snowpark-python==1.9.0\n",
    "!pip uninstall urllib3 -y\n",
    "!pip install urllib3==1.26.15\n",
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06a4ab2",
   "metadata": {},
   "source": [
    "# Restart and clear outputs\n",
    "\n",
    "# Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf7fe85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fosforio import snowflake\n",
    "from fosforml import *\n",
    "from fosforml.constants import MLModelFlavours\n",
    "from fosforio import get_dataframe\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "pd.set_option('display.max_columns', 500)\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "from joblib import dump, load\n",
    "import requests\n",
    "#from tqdm import tqdm\n",
    "import time\n",
    "import calendar\n",
    "import configparser\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import datetime\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from time import sleep\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from dateutil.easter import easter\n",
    "from scipy.optimize import minimize_scalar\n",
    "from scipy.optimize import curve_fit\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5999d5f2",
   "metadata": {},
   "source": [
    "# Importing data from snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e536f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from fosforio import snowflake\n",
    "#from fosforio import get_dataframe\n",
    "snowflake.get_connection(connection_name=\"ME_AD_SALES_CXN\")\n",
    "#df = get_dataframe(\"AD_SALES_IMP\")\n",
    "df_all = get_dataframe(\"AD_TECH_INPUT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb41bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df_all.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9d379d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f59857",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d633377b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.lower()\n",
    "df_all.columns = df_all.columns.str.lower()\n",
    "#df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3758d0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89878fb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2db2869-09aa-4132-8972-a3cc74bb0263",
   "metadata": {},
   "source": [
    "# Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158fc2cd-8e2e-4e27-b288-87a549556779",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_col=['ad_date', 'site_id','advertiser_id', 'order_id','ad_type', 'ad_format', 'ad_media_type',\n",
    "         'device_type', 'city', 'line_item_group', 'line_item_type', 'monetization_channel','os_type']\n",
    "scat_col = ['site_id','ad_type', 'ad_format', 'device_type', 'advertiser_id',\n",
    "            'line_item_group', 'line_item_type', 'os_type','monetization_channel']\n",
    "num_col=list(df_all.select_dtypes(np.number).columns)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "34d3e90d",
   "metadata": {},
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(df_all.isnull(),cbar=False,cbar_kws={'color':'r'})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00e0244-4680-44bf-9dfb-a67f5f61eff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(4,2, figsize=(14,12))\n",
    "axes_ = [axes_row for axes in ax for axes_row in axes]\n",
    "\n",
    "for i,col in enumerate(scat_col):\n",
    "    sns.countplot(data=df_all,x=col,ax=axes_[i])\n",
    "    if col=='advertiser_id':\n",
    "        plt.xticks(rotation=90)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f37132-8305-4793-8c92-f8828d07970d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in num_col:\n",
    "    if i!='total_revenue':\n",
    "        sns.scatterplot(data=df_all,x=i,y='total_revenue')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb091da-8e4e-46a6-b24f-af4eb795f0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f266fcc2-2b3b-47a2-9dcb-cf2c2efb53de",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in (scat_col):\n",
    "    title='Relationship of '+col+' with total_revenue'\n",
    "    plt.figure(figsize=(6,4))\n",
    "    sns.barplot(y=df_all['total_revenue'],x=df_all[col])\n",
    "    if col=='advertiser_id':\n",
    "        plt.xticks(rotation=90)\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c88c3cf-8b3f-490d-8cdd-abef798c12dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in (scat_col):\n",
    "    title='Relationship of '+ col +' with total_impressions'\n",
    "    plt.figure(figsize=(6,4))\n",
    "    sns.barplot(y=df_all['total_impressions'],x=df_all[col],)\n",
    "    if col=='advertiser_id':\n",
    "        plt.xticks(rotation=90)\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a867e33c-830f-4478-89f8-10dc9e3c7c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cat_col:\n",
    "    df_all[i]=df_all[i].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8f14dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f35e75-ff39-485a-a87d-f01ff77b4399",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.drop(['ad_unit_id','revenue_share_percent','ad_type_id','site_id','advertiser_id',\n",
    "        'ad_date','geo_id','order_id', 'ad_type', 'ad_format', 'ad_media_type', 'line_item_group',\n",
    "            'city', 'city_code'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71b2543",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4698ba70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.drop(['device_category_id', 'line_item_type_id', 'os_id',\n",
    "       'monetization_channel_id','population', 'city_lat', 'city_lon'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963034fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.select_dtypes(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006f89ae-6bbc-4d63-8624-3f37c9c04fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df_all.select_dtypes(object).columns:\n",
    "    pd.crosstab(df_all['monetization_channel'],df_all[i]).plot(kind='bar')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab7196b",
   "metadata": {},
   "source": [
    "# Predictive Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12453c4-15b8-4d77-8d7d-b4a8aa2162db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4df5c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9147704-4046-457d-8ca2-c7235c0c0051",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xd = df_all.drop('total_revenue',axis=1)\n",
    "y = df_all['total_revenue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b3694b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xd.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a446e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d15e0b2-fc4c-4df7-93dc-ae3d829a5d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = pd.get_dummies(Xd,drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a35cbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86301728-34bc-4f81-8f38-9b73a6e5e206",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import StandardScaler\n",
    "#ss = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0caeacf-bba9-47e3-b386-ebd2c62d4f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X[pc_col] = pd.DataFrame(ss.fit_transform(X[pc_col]),columns=[pc_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a361d941-0784-4adc-aed8-69adba480dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(Xd,y,test_size=0.2,random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25dd13b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f62ad3-0adc-418b-8d21-e558d18a7a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_col = ['total_impressions', 'viewable_impressions', 'measurable_impressions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58216303",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a39c2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline(steps=[\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('pca', PCA(n_components=2))\n",
    "        ]), pc_col),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), ['device_type', 'line_item_type', 'os_type',\n",
    "       'monetization_channel'])\n",
    "    ])\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3c3b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "\n",
    "    {\n",
    "        'name': 'RandomForestRegressor',\n",
    "        'regressor': [RandomForestRegressor()],\n",
    "        'regressor__n_estimators': [50],\n",
    "        'regressor__max_depth': [10],\n",
    "        'regressor__min_samples_split': [2],\n",
    "        'regressor__min_samples_leaf': [1],\n",
    "        'regressor__bootstrap': [True]\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb07eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline = Pipeline(steps=[\n",
    "#    ('preprocessor', preprocessor),\n",
    "#    ('regressor', LinearRegression())  # Placeholder\n",
    "#])\n",
    "\n",
    "best_estimators = []\n",
    "for model_params in models:\n",
    "    model_name = model_params.pop('name')  # Extract the model name\n",
    "    grid_search = GridSearchCV(pipeline, model_params, cv=3, scoring='r2', n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_estimator = grid_search.best_estimator_\n",
    "    best_estimators.append(best_estimator)\n",
    "    print(f\"Training completed for model {model_name}\")\n",
    "    \n",
    "    # Save the best model\n",
    "    joblib.dump(best_estimator, f'best_model_{model_name}.pkl')\n",
    "    print(f\"Best model {model_name} saved to best_model_{model_name}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7411d987",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d95ccda",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for estimator in best_estimators:\n",
    "    y_pred_train = estimator.predict(X_train)\n",
    "    y_pred_test = estimator.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred_test)\n",
    "    r2 = r2_score(y_test, y_pred_test)\n",
    "    results.append({\n",
    "        'model': estimator.named_steps['regressor'].__class__.__name__,\n",
    "        'best_params': estimator.named_steps['regressor'].get_params(),\n",
    "        'mse': mse,\n",
    "        'r2': r2\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7391ab90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['predicted_revenue'] = best_estimator.predict(Xd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59701539",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy['predicted_revenue'] = best_estimator.predict(Xd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00dadc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17063d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c786b737",
   "metadata": {},
   "source": [
    "# In this section we are joining multiple tables, realigning indexes to get the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ded1557",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check type of data (series/ array/ dataframe)\n",
    "\n",
    "type(Xd), type(X_train), type(X_test), type(y), type(y_train), type(y_test), type(results), type(y_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca293e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62a676a",
   "metadata": {},
   "source": [
    "# Creating Data frames as necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32c7977",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df= pd.DataFrame(y)\n",
    "y_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687b267c-3d9a-4dfe-b133-f57d9a7c18d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_df= pd.DataFrame(y_train)\n",
    "y_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f5446b-9b87-4bdc-9221-ab78e778b0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_df= pd.DataFrame(y_test)\n",
    "y_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa94720",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list_temp = y_train_df.index.values.tolist()\n",
    "min(index_list_temp), max(index_list_temp), len(index_list_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f287897",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list_temp = y_test_df.index.values.tolist()\n",
    "min(index_list_temp), max(index_list_temp), len(index_list_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fd6e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fc0ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check type of data (series/ array/ dataframe)\n",
    "\n",
    "type(X_train), type(X_test), type(y_train_df), type(y_test_df), type(y_pred_train), type(y_pred_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa1fd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0f10db",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_df = pd.DataFrame(y_pred_train, columns=['predicted_revenue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcbf005",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e8f093",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_df = pd.DataFrame(y_pred_test,columns=['predicted_revenue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbcc5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_df.reset_index(drop = True)\n",
    "y_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d6de17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba05dcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining Actuals and predicted Y columns\n",
    "\n",
    "y_train_final= pd.concat([y_train_df, y_train_pred_df.set_index(y_train_df.index)], axis=1)\n",
    "y_train_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9f7c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_final= pd.concat([y_test_df, y_test_pred_df.set_index(y_test_df.index)], axis=1)\n",
    "y_test_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b72733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining Train and test Y columns\n",
    "\n",
    "y_all = pd.concat([y_train_final, y_test_final])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e9f598",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832f863b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_compare = pd.merge(y_df, y_all, left_index=True, right_index=True)\n",
    "y_compare.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd061042",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_compare[y_compare['total_revenue_x']!=y_compare['total_revenue_y']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062ec433",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_all = y_all.sort_index(axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183fdd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_all.sort_index(axis=0, inplace = True)\n",
    "y_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469aee3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf11e052",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4246596",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5b941a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_all.sort_index(axis=0)\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f0d593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining x and y columns with all details\n",
    "\n",
    "model_output = pd.merge(df, y_all, left_index=True, right_index=True)\n",
    "#model_output = pd.concat([df_all, y_all], axis = 1)\n",
    "#model_output = df_all.join(y_all)\n",
    "model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27330f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check\n",
    "\n",
    "print(model_output['predicted_revenue'].sum())\n",
    "print(model_output['total_revenue_x'].sum())\n",
    "print(model_output['total_revenue_y'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f760ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_output.columns"
   ]
  },
  {
   "cell_type": "raw",
   "id": "978febe5",
   "metadata": {},
   "source": [
    "# fixing column names of revenue which comes in input as well as output data\n",
    "\n",
    "model_output.columns = ['ad_date', 'site_id', 'ad_type_id', 'geo_id', 'device_category_id',\n",
    "       'advertiser_id', 'order_id', 'line_item_type_id', 'os_id',\n",
    "       'monetization_channel_id', 'ad_unit_id', 'total_impressions', 'total_revenue',\n",
    "       'viewable_impressions', 'measurable_impressions',\n",
    "       'revenue_share_percent', 'ad_type', 'ad_format', 'ad_media_type',\n",
    "       'device_type', 'city', 'city_code', 'population', 'city_lat',\n",
    "       'city_lon', 'line_item_group', 'line_item_type', 'monetization_channel',\n",
    "       'os_type', 'total_revenue2', 'predicted_revenue']\n",
    "model_output.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b7f5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output[model_output['total_revenue_x']!=model_output['total_revenue_y']].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb6010a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if both the columns actually have same values\n",
    "\n",
    "#model_output['total_revenue'].equals(model_output['total_revenue2']) \n",
    "model_output['total_revenue_x'].equals(model_output['total_revenue_y']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515b17b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output['check'] = model_output.apply(lambda x: x['total_revenue_x'] if x['total_revenue_x'] <\n",
    "                     x['total_revenue_y'] else np.nan, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dc7a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output['check'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4501ef",
   "metadata": {},
   "source": [
    "# Pushing Model output to Snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc1f342",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from snowflake.snowpark.session import Session\n",
    "user = os.getenv(\"user\")\n",
    "warehouse = os.getenv(\"warehouse\")\n",
    "schema= os.getenv(\"schema\")\n",
    "database = os.getenv(\"database\")\n",
    "role =  os.getenv(\"role\")\n",
    "account =  os.getenv(\"account\")\n",
    "password= os.getenv(\"password\")\n",
    "\n",
    "connection_params = dict(user=user, \n",
    "                         password=password, \n",
    "                         account=account, \n",
    "                         warehouse=warehouse, \n",
    "                         database=database,\n",
    "                         schema=schema, \n",
    "                         role=role)\n",
    "\n",
    "session = Session.builder.configs(connection_params).create()\n",
    "\n",
    "session.sql('use warehouse {};'.format(warehouse)).collect()\n",
    "\n",
    "session.sql('use database {};'.format(database)).collect()\n",
    "\n",
    "session.sql('use schema {}.{};'.format(database, schema)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731f951b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_snowflake = session.createDataFrame(df_all.values.tolist(),\n",
    "        schema = df_all.columns.tolist())\n",
    "\n",
    "df_snowflake.write.mode(\"overwrite\").save_as_table(\"ME_DB.ME_AD_SALES_SCHEMA.AD_TECH_OUTPUT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f999a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245f5ae1",
   "metadata": {},
   "source": [
    "# Model Registrartion using fosforml SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19b3564",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Snowpark lib\n",
    "from snowflake.snowpark import Session\n",
    "\n",
    "# Data Science Libs\n",
    "#import numpy as np\n",
    "#import pandas as pd\n",
    "\n",
    "# create_temp_table warning suppresion\n",
    "#import warnings; warnings.simplefilter('ignore')\n",
    "\n",
    "#ConfigParser to read ini file\n",
    "# import configparser\n",
    "#!pip install fosforml\n",
    "from fosforio import snowflake\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60650415",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688c4ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fosforml import *\n",
    "from fosforml.constants import MLModelFlavours\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7c13c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@scoring_func\n",
    "def score(model, request):\n",
    "\n",
    "    import json\n",
    "    payload = request.json[\"payload\"]\n",
    "    if isinstance(request.json[\"payload\"],str):\n",
    "        payload_data = eval(payload)\n",
    "        if isinstance(payload_data['total_impressions'], int):\n",
    "                data_json = eval(payload)\n",
    "                data = pd.DataFrame([data_json])\n",
    "                prediction = pd.DataFrame(model.predict(data))\n",
    "                return prediction[0].to_list()[0]\n",
    "        elif isinstance(payload_data['total_impressions'], dict):\n",
    "                data = pd.DataFrame(eval(payload))\n",
    "                prediction = pd.DataFrame(model.predict(data))\n",
    "                return prediction[0].tolist()\n",
    "        elif isinstance(payload_data['total_impressions'], list):\n",
    "                data = pd.DataFrame(payload_data)\n",
    "                prediction = pd.DataFrame(model.predict(data))\n",
    "                return prediction.tolist()\n",
    "    return \"This method is not allowed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e082e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "payload = str(X_test.iloc[1:3].to_dict())\n",
    "req = requests.Request()\n",
    "req.json = {\"payload\": payload}\n",
    "print(score(best_estimator, req))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2ec1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee733fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "payload = str(X_test.iloc[1].to_dict())\n",
    "req = requests.Request()\n",
    "req.json = {\"payload\": payload}\n",
    "print(score(best_estimator, req))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42572f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64668451",
   "metadata": {},
   "source": [
    "# Sample Payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b293079",
   "metadata": {},
   "outputs": [],
   "source": [
    "req.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c03957",
   "metadata": {},
   "outputs": [],
   "source": [
    "yo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf5f4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## registering the model in Fosfor.\n",
    "register_model(best_estimator,\n",
    "               score, \n",
    "               name=\"Ad_Sales_Prediction_Model\", \n",
    "               description=\"Ad_Sales_Prediction_RandomForest_Model\",\n",
    "               flavour=MLModelFlavours.sklearn,\n",
    "               model_type=\"regression\",\n",
    "               init_script=\"\\\\n pip install fosforml \\\\n pip install fosforio[snowflake] \\\\n pip install sklearn\\\\n pip install snowflake-connector-python[pandas]\",\n",
    "               y_true=y_test,\n",
    "               y_pred=y_pred_test,\n",
    "               #prob=y_prob,\n",
    "               features=X_train.columns,\n",
    "               input_type=\"json\", \n",
    "               explain_ai=True,\n",
    "               x_train=X_train, \n",
    "               x_test=X_test, \n",
    "               y_train=y_train,\n",
    "               y_test=y_test,\n",
    "               feature_names=X_train.columns.tolist(),\n",
    "               original_features=X_train.columns.tolist(),\n",
    "               feature_ids=X_train.columns,\n",
    "               kyd=True, kyd_score = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b12bedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b7d581",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
