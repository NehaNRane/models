{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ff154a0-abe5-4a30-90ba-0393bd1ffc9d",
   "metadata": {},
   "source": [
    "# Data: Ad Sales Data\n",
    "# Use Case: Revenue Prediction\n",
    "# Model: Regression Models\n",
    "\n",
    "Code link: https://www.kaggle.com/code/akshaysunil07/ad-tech-revenue-regression/notebook "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83c8bfe",
   "metadata": {},
   "source": [
    "# Installing packages section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddb0b697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "Collecting pip\n",
      "  Using cached pip-24.2-py3-none-any.whl.metadata (3.6 kB)\n",
      "Using cached pip-24.2-py3-none-any.whl (1.8 MB)\n",
      "Installing collected packages: pip\n",
      "Successfully installed pip-24.2\n",
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "Collecting snowflake-connector-python[pandas]\n",
      "  Using cached snowflake_connector_python-3.12.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (64 kB)\n",
      "Collecting asn1crypto<2.0.0,>0.24.0 (from snowflake-connector-python[pandas])\n",
      "  Using cached asn1crypto-1.5.1-py2.py3-none-any.whl.metadata (13 kB)\n",
      "Collecting cffi<2.0.0,>=1.9 (from snowflake-connector-python[pandas])\n",
      "  Using cached cffi-1.16.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting cryptography<43.0.0,>=3.1.0 (from snowflake-connector-python[pandas])\n",
      "  Using cached cryptography-42.0.8-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting pyOpenSSL<25.0.0,>=16.2.0 (from snowflake-connector-python[pandas])\n",
      "  Using cached pyOpenSSL-24.2.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pyjwt<3.0.0 (from snowflake-connector-python[pandas])\n",
      "  Using cached PyJWT-2.8.0-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting pytz (from snowflake-connector-python[pandas])\n",
      "  Using cached pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting requests<3.0.0 (from snowflake-connector-python[pandas])\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting packaging (from snowflake-connector-python[pandas])\n",
      "  Using cached packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from snowflake-connector-python[pandas])\n",
      "  Using cached charset_normalizer-3.3.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (33 kB)\n",
      "Collecting idna<4,>=2.5 (from snowflake-connector-python[pandas])\n",
      "  Using cached idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting certifi>=2017.4.17 (from snowflake-connector-python[pandas])\n",
      "  Using cached certifi-2024.7.4-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting typing-extensions<5,>=4.3 (from snowflake-connector-python[pandas])\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting filelock<4,>=3.5 (from snowflake-connector-python[pandas])\n",
      "  Using cached filelock-3.15.4-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting sortedcontainers>=2.4.0 (from snowflake-connector-python[pandas])\n",
      "  Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting platformdirs<5.0.0,>=2.6.0 (from snowflake-connector-python[pandas])\n",
      "  Using cached platformdirs-4.2.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting tomlkit (from snowflake-connector-python[pandas])\n",
      "  Using cached tomlkit-0.13.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting urllib3<2.0.0,>=1.21.1 (from snowflake-connector-python[pandas])\n",
      "  Using cached urllib3-1.26.19-py2.py3-none-any.whl.metadata (49 kB)\n",
      "Collecting pandas<3.0.0,>=1.0.0 (from snowflake-connector-python[pandas])\n",
      "  Using cached pandas-2.2.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Collecting pyarrow (from snowflake-connector-python[pandas])\n",
      "  Using cached pyarrow-17.0.0-cp39-cp39-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting pycparser (from cffi<2.0.0,>=1.9->snowflake-connector-python[pandas])\n",
      "  Using cached pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Collecting numpy>=1.22.4 (from pandas<3.0.0,>=1.0.0->snowflake-connector-python[pandas])\n",
      "  Using cached numpy-2.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "Collecting python-dateutil>=2.8.2 (from pandas<3.0.0,>=1.0.0->snowflake-connector-python[pandas])\n",
      "  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas<3.0.0,>=1.0.0->snowflake-connector-python[pandas])\n",
      "  Using cached tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting six>=1.5 (from python-dateutil>=2.8.2->pandas<3.0.0,>=1.0.0->snowflake-connector-python[pandas])\n",
      "  Using cached six-1.16.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Using cached asn1crypto-1.5.1-py2.py3-none-any.whl (105 kB)\n",
      "Using cached certifi-2024.7.4-py3-none-any.whl (162 kB)\n",
      "Using cached cffi-1.16.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (443 kB)\n",
      "Using cached charset_normalizer-3.3.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
      "Using cached cryptography-42.0.8-cp39-abi3-manylinux_2_28_x86_64.whl (3.9 MB)\n",
      "Using cached filelock-3.15.4-py3-none-any.whl (16 kB)\n",
      "Using cached idna-3.7-py3-none-any.whl (66 kB)\n",
      "Using cached pandas-2.2.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "Using cached platformdirs-4.2.2-py3-none-any.whl (18 kB)\n",
      "Using cached PyJWT-2.8.0-py3-none-any.whl (22 kB)\n",
      "Using cached pyOpenSSL-24.2.1-py3-none-any.whl (58 kB)\n",
      "Using cached pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Using cached urllib3-1.26.19-py2.py3-none-any.whl (143 kB)\n",
      "Using cached packaging-24.1-py3-none-any.whl (53 kB)\n",
      "Using cached pyarrow-17.0.0-cp39-cp39-manylinux_2_28_x86_64.whl (39.9 MB)\n",
      "Using cached snowflake_connector_python-3.12.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
      "Using cached tomlkit-0.13.0-py3-none-any.whl (37 kB)\n",
      "Using cached numpy-2.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.5 MB)\n",
      "Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "Using cached tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "Using cached pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Installing collected packages: sortedcontainers, pytz, asn1crypto, urllib3, tzdata, typing-extensions, tomlkit, six, pyjwt, pycparser, platformdirs, packaging, numpy, idna, filelock, charset-normalizer, certifi, requests, python-dateutil, pyarrow, cffi, pandas, cryptography, pyOpenSSL, snowflake-connector-python\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "fosforio 1.0.1 requires pandas==2.0.0, but you have pandas 2.2.2 which is incompatible.\n",
      "fosforml 1.0.1 requires cloudpickle==3.0.0, but you have cloudpickle 2.0.0 which is incompatible.\n",
      "fosforml 1.0.1 requires numpy==1.26.4; python_version > \"3.8\", but you have numpy 2.0.1 which is incompatible.\n",
      "fosforml 1.0.1 requires urllib3==2.2.1, but you have urllib3 1.26.19 which is incompatible.\n",
      "jsonschema-path 0.3.2 requires referencing<0.32.0,>=0.28.0, but you have referencing 0.33.0 which is incompatible.\n",
      "jupyterlab 3.2.4 requires jupyter-server~=1.4, but you have jupyter-server 2.7.3 which is incompatible.\n",
      "mosaic-ai-client 1.0.0 requires matplotlib==3.1.1, but you have matplotlib 3.9.1 which is incompatible.\n",
      "mosaic-ai-client 1.0.0 requires requests-toolbelt==0.9.1, but you have requests-toolbelt 1.0.0 which is incompatible.\n",
      "mosaic-ai-serving 1.0.0 requires Flask==2.1.1; python_version >= \"3.7\", but you have flask 2.2.5 which is incompatible.\n",
      "mosaic-ai-serving 1.0.0 requires matplotlib==3.6.0; python_version >= \"3.8\", but you have matplotlib 3.9.1 which is incompatible.\n",
      "numba 0.58.1 requires numpy<1.27,>=1.22, but you have numpy 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed asn1crypto-1.5.1 certifi-2024.7.4 cffi-1.16.0 charset-normalizer-3.3.2 cryptography-42.0.8 filelock-3.15.4 idna-3.7 numpy-2.0.1 packaging-24.1 pandas-2.2.2 platformdirs-4.2.2 pyOpenSSL-24.2.1 pyarrow-17.0.0 pycparser-2.22 pyjwt-2.8.0 python-dateutil-2.9.0.post0 pytz-2024.1 requests-2.32.3 six-1.16.0 snowflake-connector-python-3.12.0 sortedcontainers-2.4.0 tomlkit-0.13.0 typing-extensions-4.12.2 tzdata-2024.1 urllib3-1.26.19\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/sortedcontainers already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/sortedcontainers-2.4.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/pytz already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/pytz-2024.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/asn1crypto already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/asn1crypto-1.5.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/urllib3 already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/urllib3-1.26.19.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/tzdata already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/tzdata-2024.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/typing_extensions.py already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/typing_extensions-4.12.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/__pycache__ already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/tomlkit already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/tomlkit-0.13.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/six.py already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/six-1.16.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/jwt already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/PyJWT-2.8.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/pycparser already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/pycparser-2.22.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/platformdirs already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/platformdirs-4.2.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/packaging already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/packaging-24.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/numpy.libs already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/numpy already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/numpy-2.0.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/idna already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/idna-3.7.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/filelock already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/filelock-3.15.4.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/charset_normalizer already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/charset_normalizer-3.3.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/certifi already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/certifi-2024.7.4.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/requests already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/requests-2.32.3.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/dateutil already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/python_dateutil-2.9.0.post0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/scripts already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/benchmarks already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/pyarrow-17.0.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/examples already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/pyarrow already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/cmake_modules already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/_cffi_backend.cpython-39-x86_64-linux-gnu.so already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/cffi already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/cffi-1.16.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/pandas already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/pandas-2.2.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/cryptography already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/cryptography-42.0.8.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/OpenSSL already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/pyOpenSSL-24.2.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/snowflake already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/snowflake_connector_python-3.12.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/bin already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0mWARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "Collecting snowflake-snowpark-python[pandas]\n",
      "  Using cached snowflake_snowpark_python-1.20.0-py3-none-any.whl.metadata (80 kB)\n",
      "Collecting setuptools>=40.6.0 (from snowflake-snowpark-python[pandas])\n",
      "  Using cached setuptools-72.1.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting wheel (from snowflake-snowpark-python[pandas])\n",
      "  Using cached wheel-0.43.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting snowflake-connector-python<4.0.0,>=3.10.0 (from snowflake-snowpark-python[pandas])\n",
      "  Using cached snowflake_connector_python-3.12.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (64 kB)\n",
      "Collecting typing-extensions<5.0.0,>=4.1.0 (from snowflake-snowpark-python[pandas])\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting pyyaml (from snowflake-snowpark-python[pandas])\n",
      "  Using cached PyYAML-6.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting cloudpickle!=2.1.0,!=2.2.0,<=2.2.1,>=1.6.0 (from snowflake-snowpark-python[pandas])\n",
      "  Using cached cloudpickle-2.2.1-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting asn1crypto<2.0.0,>0.24.0 (from snowflake-connector-python<4.0.0,>=3.10.0->snowflake-snowpark-python[pandas])\n",
      "  Using cached asn1crypto-1.5.1-py2.py3-none-any.whl.metadata (13 kB)\n",
      "Collecting cffi<2.0.0,>=1.9 (from snowflake-connector-python<4.0.0,>=3.10.0->snowflake-snowpark-python[pandas])\n",
      "  Using cached cffi-1.16.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting cryptography<43.0.0,>=3.1.0 (from snowflake-connector-python<4.0.0,>=3.10.0->snowflake-snowpark-python[pandas])\n",
      "  Using cached cryptography-42.0.8-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting pyOpenSSL<25.0.0,>=16.2.0 (from snowflake-connector-python<4.0.0,>=3.10.0->snowflake-snowpark-python[pandas])\n",
      "  Using cached pyOpenSSL-24.2.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pyjwt<3.0.0 (from snowflake-connector-python<4.0.0,>=3.10.0->snowflake-snowpark-python[pandas])\n",
      "  Using cached PyJWT-2.8.0-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting pytz (from snowflake-connector-python<4.0.0,>=3.10.0->snowflake-snowpark-python[pandas])\n",
      "  Using cached pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting requests<3.0.0 (from snowflake-connector-python<4.0.0,>=3.10.0->snowflake-snowpark-python[pandas])\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting packaging (from snowflake-connector-python<4.0.0,>=3.10.0->snowflake-snowpark-python[pandas])\n",
      "  Using cached packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from snowflake-connector-python<4.0.0,>=3.10.0->snowflake-snowpark-python[pandas])\n",
      "  Using cached charset_normalizer-3.3.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (33 kB)\n",
      "Collecting idna<4,>=2.5 (from snowflake-connector-python<4.0.0,>=3.10.0->snowflake-snowpark-python[pandas])\n",
      "  Using cached idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting certifi>=2017.4.17 (from snowflake-connector-python<4.0.0,>=3.10.0->snowflake-snowpark-python[pandas])\n",
      "  Using cached certifi-2024.7.4-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting filelock<4,>=3.5 (from snowflake-connector-python<4.0.0,>=3.10.0->snowflake-snowpark-python[pandas])\n",
      "  Using cached filelock-3.15.4-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting sortedcontainers>=2.4.0 (from snowflake-connector-python<4.0.0,>=3.10.0->snowflake-snowpark-python[pandas])\n",
      "  Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting platformdirs<5.0.0,>=2.6.0 (from snowflake-connector-python<4.0.0,>=3.10.0->snowflake-snowpark-python[pandas])\n",
      "  Using cached platformdirs-4.2.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting tomlkit (from snowflake-connector-python<4.0.0,>=3.10.0->snowflake-snowpark-python[pandas])\n",
      "  Using cached tomlkit-0.13.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting urllib3<2.0.0,>=1.21.1 (from snowflake-connector-python<4.0.0,>=3.10.0->snowflake-snowpark-python[pandas])\n",
      "  Using cached urllib3-1.26.19-py2.py3-none-any.whl.metadata (49 kB)\n",
      "Collecting pandas<3.0.0,>=1.0.0 (from snowflake-connector-python[pandas]<4.0.0,>=3.10.0; extra == \"pandas\"->snowflake-snowpark-python[pandas])\n",
      "  Using cached pandas-2.2.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Collecting pyarrow (from snowflake-connector-python[pandas]<4.0.0,>=3.10.0; extra == \"pandas\"->snowflake-snowpark-python[pandas])\n",
      "  Using cached pyarrow-17.0.0-cp39-cp39-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting pycparser (from cffi<2.0.0,>=1.9->snowflake-connector-python<4.0.0,>=3.10.0->snowflake-snowpark-python[pandas])\n",
      "  Using cached pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Collecting numpy>=1.22.4 (from pandas<3.0.0,>=1.0.0->snowflake-connector-python[pandas]<4.0.0,>=3.10.0; extra == \"pandas\"->snowflake-snowpark-python[pandas])\n",
      "  Using cached numpy-2.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "Collecting python-dateutil>=2.8.2 (from pandas<3.0.0,>=1.0.0->snowflake-connector-python[pandas]<4.0.0,>=3.10.0; extra == \"pandas\"->snowflake-snowpark-python[pandas])\n",
      "  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas<3.0.0,>=1.0.0->snowflake-connector-python[pandas]<4.0.0,>=3.10.0; extra == \"pandas\"->snowflake-snowpark-python[pandas])\n",
      "  Using cached tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting six>=1.5 (from python-dateutil>=2.8.2->pandas<3.0.0,>=1.0.0->snowflake-connector-python[pandas]<4.0.0,>=3.10.0; extra == \"pandas\"->snowflake-snowpark-python[pandas])\n",
      "  Using cached six-1.16.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Using cached cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
      "Using cached setuptools-72.1.0-py3-none-any.whl (2.3 MB)\n",
      "Using cached snowflake_connector_python-3.12.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Using cached PyYAML-6.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (738 kB)\n",
      "Using cached snowflake_snowpark_python-1.20.0-py3-none-any.whl (1.2 MB)\n",
      "Using cached wheel-0.43.0-py3-none-any.whl (65 kB)\n",
      "Using cached asn1crypto-1.5.1-py2.py3-none-any.whl (105 kB)\n",
      "Using cached certifi-2024.7.4-py3-none-any.whl (162 kB)\n",
      "Using cached cffi-1.16.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (443 kB)\n",
      "Using cached charset_normalizer-3.3.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
      "Using cached cryptography-42.0.8-cp39-abi3-manylinux_2_28_x86_64.whl (3.9 MB)\n",
      "Using cached filelock-3.15.4-py3-none-any.whl (16 kB)\n",
      "Using cached idna-3.7-py3-none-any.whl (66 kB)\n",
      "Using cached pandas-2.2.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "Using cached platformdirs-4.2.2-py3-none-any.whl (18 kB)\n",
      "Using cached PyJWT-2.8.0-py3-none-any.whl (22 kB)\n",
      "Using cached pyOpenSSL-24.2.1-py3-none-any.whl (58 kB)\n",
      "Using cached pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Using cached urllib3-1.26.19-py2.py3-none-any.whl (143 kB)\n",
      "Using cached packaging-24.1-py3-none-any.whl (53 kB)\n",
      "Using cached pyarrow-17.0.0-cp39-cp39-manylinux_2_28_x86_64.whl (39.9 MB)\n",
      "Using cached tomlkit-0.13.0-py3-none-any.whl (37 kB)\n",
      "Using cached numpy-2.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.5 MB)\n",
      "Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "Using cached tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "Using cached pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Installing collected packages: sortedcontainers, pytz, asn1crypto, wheel, urllib3, tzdata, typing-extensions, tomlkit, six, setuptools, pyyaml, pyjwt, pycparser, platformdirs, packaging, numpy, idna, filelock, cloudpickle, charset-normalizer, certifi, requests, python-dateutil, pyarrow, cffi, pandas, cryptography, pyOpenSSL, snowflake-connector-python, snowflake-snowpark-python\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "fosforio 1.0.1 requires pandas==2.0.0, but you have pandas 2.2.2 which is incompatible.\r\n",
      "fosforml 1.0.1 requires cloudpickle==3.0.0, but you have cloudpickle 2.2.1 which is incompatible.\r\n",
      "fosforml 1.0.1 requires numpy==1.26.4; python_version > \"3.8\", but you have numpy 2.0.1 which is incompatible.\r\n",
      "fosforml 1.0.1 requires urllib3==2.2.1, but you have urllib3 1.26.19 which is incompatible.\r\n",
      "jsonschema-path 0.3.2 requires referencing<0.32.0,>=0.28.0, but you have referencing 0.33.0 which is incompatible.\r\n",
      "jupyterlab 3.2.4 requires jupyter-server~=1.4, but you have jupyter-server 2.7.3 which is incompatible.\r\n",
      "mosaic-ai-client 1.0.0 requires matplotlib==3.1.1, but you have matplotlib 3.9.1 which is incompatible.\r\n",
      "mosaic-ai-client 1.0.0 requires requests-toolbelt==0.9.1, but you have requests-toolbelt 1.0.0 which is incompatible.\r\n",
      "mosaic-ai-serving 1.0.0 requires Flask==2.1.1; python_version >= \"3.7\", but you have flask 2.2.5 which is incompatible.\r\n",
      "mosaic-ai-serving 1.0.0 requires matplotlib==3.6.0; python_version >= \"3.8\", but you have matplotlib 3.9.1 which is incompatible.\r\n",
      "numba 0.58.1 requires numpy<1.27,>=1.22, but you have numpy 2.0.1 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed asn1crypto-1.5.1 certifi-2024.7.4 cffi-1.16.0 charset-normalizer-3.3.2 cloudpickle-2.2.1 cryptography-42.0.8 filelock-3.15.4 idna-3.7 numpy-2.0.1 packaging-24.1 pandas-2.2.2 platformdirs-4.2.2 pyOpenSSL-24.2.1 pyarrow-17.0.0 pycparser-2.22 pyjwt-2.8.0 python-dateutil-2.9.0.post0 pytz-2024.1 pyyaml-6.0.1 requests-2.32.3 setuptools-72.1.0 six-1.16.0 snowflake-connector-python-3.12.0 snowflake-snowpark-python-1.20.0 sortedcontainers-2.4.0 tomlkit-0.13.0 typing-extensions-4.12.2 tzdata-2024.1 urllib3-1.26.19 wheel-0.43.0\r\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/sortedcontainers already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/sortedcontainers-2.4.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/pytz already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/pytz-2024.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/asn1crypto already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/asn1crypto-1.5.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/wheel already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/wheel-0.43.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/urllib3 already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/urllib3-1.26.19.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/tzdata already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/tzdata-2024.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/typing_extensions.py already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/typing_extensions-4.12.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/__pycache__ already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/tomlkit already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/tomlkit-0.13.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/six.py already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/six-1.16.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/distutils-precedence.pth already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/_distutils_hack already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/pkg_resources already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/setuptools already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/setuptools-72.1.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/yaml already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/_yaml already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/PyYAML-6.0.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/jwt already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/PyJWT-2.8.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/pycparser already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/pycparser-2.22.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/platformdirs already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/platformdirs-4.2.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/packaging already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/packaging-24.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/numpy.libs already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/numpy already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/numpy-2.0.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/idna already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/idna-3.7.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/filelock already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/filelock-3.15.4.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/cloudpickle already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/cloudpickle-2.2.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/charset_normalizer already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/charset_normalizer-3.3.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/certifi already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/certifi-2024.7.4.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/requests already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/requests-2.32.3.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/dateutil already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/python_dateutil-2.9.0.post0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/scripts already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/benchmarks already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/pyarrow-17.0.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/examples already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/pyarrow already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/cmake_modules already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/_cffi_backend.cpython-39-x86_64-linux-gnu.so already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/cffi already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/cffi-1.16.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/pandas already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/pandas-2.2.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/cryptography already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/cryptography-42.0.8.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/OpenSSL already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/pyOpenSSL-24.2.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/snowflake already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/snowflake_connector_python-3.12.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/snowflake_snowpark_python-1.20.0-py3.12-nspkg.pth already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/snowflake_snowpark_python-1.20.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/bin already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0mWARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "Collecting snowflake-snowpark-python==1.9.0\n",
      "  Using cached snowflake_snowpark_python-1.9.0-py3-none-any.whl.metadata (44 kB)\n",
      "Collecting setuptools>=40.6.0 (from snowflake-snowpark-python==1.9.0)\n",
      "  Using cached setuptools-72.1.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting wheel (from snowflake-snowpark-python==1.9.0)\n",
      "  Using cached wheel-0.43.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting snowflake-connector-python<4.0.0,>=3.2.0 (from snowflake-snowpark-python==1.9.0)\n",
      "  Using cached snowflake_connector_python-3.12.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (64 kB)\n",
      "Collecting typing-extensions<5.0.0,>=4.1.0 (from snowflake-snowpark-python==1.9.0)\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting pyyaml (from snowflake-snowpark-python==1.9.0)\n",
      "  Using cached PyYAML-6.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting cloudpickle<=2.0.0,>=1.6.0 (from snowflake-snowpark-python==1.9.0)\n",
      "  Using cached cloudpickle-2.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting asn1crypto<2.0.0,>0.24.0 (from snowflake-connector-python<4.0.0,>=3.2.0->snowflake-snowpark-python==1.9.0)\n",
      "  Using cached asn1crypto-1.5.1-py2.py3-none-any.whl.metadata (13 kB)\n",
      "Collecting cffi<2.0.0,>=1.9 (from snowflake-connector-python<4.0.0,>=3.2.0->snowflake-snowpark-python==1.9.0)\n",
      "  Using cached cffi-1.16.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting cryptography<43.0.0,>=3.1.0 (from snowflake-connector-python<4.0.0,>=3.2.0->snowflake-snowpark-python==1.9.0)\n",
      "  Using cached cryptography-42.0.8-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting pyOpenSSL<25.0.0,>=16.2.0 (from snowflake-connector-python<4.0.0,>=3.2.0->snowflake-snowpark-python==1.9.0)\n",
      "  Using cached pyOpenSSL-24.2.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pyjwt<3.0.0 (from snowflake-connector-python<4.0.0,>=3.2.0->snowflake-snowpark-python==1.9.0)\n",
      "  Using cached PyJWT-2.8.0-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting pytz (from snowflake-connector-python<4.0.0,>=3.2.0->snowflake-snowpark-python==1.9.0)\n",
      "  Using cached pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting requests<3.0.0 (from snowflake-connector-python<4.0.0,>=3.2.0->snowflake-snowpark-python==1.9.0)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting packaging (from snowflake-connector-python<4.0.0,>=3.2.0->snowflake-snowpark-python==1.9.0)\n",
      "  Using cached packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from snowflake-connector-python<4.0.0,>=3.2.0->snowflake-snowpark-python==1.9.0)\n",
      "  Using cached charset_normalizer-3.3.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (33 kB)\n",
      "Collecting idna<4,>=2.5 (from snowflake-connector-python<4.0.0,>=3.2.0->snowflake-snowpark-python==1.9.0)\n",
      "  Using cached idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting certifi>=2017.4.17 (from snowflake-connector-python<4.0.0,>=3.2.0->snowflake-snowpark-python==1.9.0)\n",
      "  Using cached certifi-2024.7.4-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting filelock<4,>=3.5 (from snowflake-connector-python<4.0.0,>=3.2.0->snowflake-snowpark-python==1.9.0)\n",
      "  Using cached filelock-3.15.4-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting sortedcontainers>=2.4.0 (from snowflake-connector-python<4.0.0,>=3.2.0->snowflake-snowpark-python==1.9.0)\n",
      "  Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting platformdirs<5.0.0,>=2.6.0 (from snowflake-connector-python<4.0.0,>=3.2.0->snowflake-snowpark-python==1.9.0)\n",
      "  Using cached platformdirs-4.2.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting tomlkit (from snowflake-connector-python<4.0.0,>=3.2.0->snowflake-snowpark-python==1.9.0)\n",
      "  Using cached tomlkit-0.13.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting urllib3<2.0.0,>=1.21.1 (from snowflake-connector-python<4.0.0,>=3.2.0->snowflake-snowpark-python==1.9.0)\n",
      "  Using cached urllib3-1.26.19-py2.py3-none-any.whl.metadata (49 kB)\n",
      "Collecting pycparser (from cffi<2.0.0,>=1.9->snowflake-connector-python<4.0.0,>=3.2.0->snowflake-snowpark-python==1.9.0)\n",
      "  Using cached pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Using cached snowflake_snowpark_python-1.9.0-py3-none-any.whl (327 kB)\n",
      "Using cached cloudpickle-2.0.0-py3-none-any.whl (25 kB)\n",
      "Using cached setuptools-72.1.0-py3-none-any.whl (2.3 MB)\n",
      "Using cached snowflake_connector_python-3.12.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Using cached PyYAML-6.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (738 kB)\n",
      "Using cached wheel-0.43.0-py3-none-any.whl (65 kB)\n",
      "Using cached asn1crypto-1.5.1-py2.py3-none-any.whl (105 kB)\n",
      "Using cached certifi-2024.7.4-py3-none-any.whl (162 kB)\n",
      "Using cached cffi-1.16.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (443 kB)\n",
      "Using cached charset_normalizer-3.3.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
      "Using cached cryptography-42.0.8-cp39-abi3-manylinux_2_28_x86_64.whl (3.9 MB)\n",
      "Using cached filelock-3.15.4-py3-none-any.whl (16 kB)\n",
      "Using cached idna-3.7-py3-none-any.whl (66 kB)\n",
      "Using cached platformdirs-4.2.2-py3-none-any.whl (18 kB)\n",
      "Using cached PyJWT-2.8.0-py3-none-any.whl (22 kB)\n",
      "Using cached pyOpenSSL-24.2.1-py3-none-any.whl (58 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Using cached urllib3-1.26.19-py2.py3-none-any.whl (143 kB)\n",
      "Using cached packaging-24.1-py3-none-any.whl (53 kB)\n",
      "Using cached pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "Using cached tomlkit-0.13.0-py3-none-any.whl (37 kB)\n",
      "Using cached pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Installing collected packages: sortedcontainers, pytz, asn1crypto, wheel, urllib3, typing-extensions, tomlkit, setuptools, pyyaml, pyjwt, pycparser, platformdirs, packaging, idna, filelock, cloudpickle, charset-normalizer, certifi, requests, cffi, cryptography, pyOpenSSL, snowflake-connector-python, snowflake-snowpark-python\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "fosforml 1.0.1 requires cloudpickle==3.0.0, but you have cloudpickle 2.0.0 which is incompatible.\n",
      "fosforml 1.0.1 requires urllib3==2.2.1, but you have urllib3 1.26.19 which is incompatible.\n",
      "jsonschema-path 0.3.2 requires referencing<0.32.0,>=0.28.0, but you have referencing 0.33.0 which is incompatible.\n",
      "jupyterlab 3.2.4 requires jupyter-server~=1.4, but you have jupyter-server 2.7.3 which is incompatible.\n",
      "mosaic-ai-client 1.0.0 requires matplotlib==3.1.1, but you have matplotlib 3.9.1 which is incompatible.\n",
      "mosaic-ai-client 1.0.0 requires requests-toolbelt==0.9.1, but you have requests-toolbelt 1.0.0 which is incompatible.\n",
      "mosaic-ai-serving 1.0.0 requires Flask==2.1.1; python_version >= \"3.7\", but you have flask 2.2.5 which is incompatible.\n",
      "mosaic-ai-serving 1.0.0 requires matplotlib==3.6.0; python_version >= \"3.8\", but you have matplotlib 3.9.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed asn1crypto-1.5.1 certifi-2024.7.4 cffi-1.16.0 charset-normalizer-3.3.2 cloudpickle-2.0.0 cryptography-42.0.8 filelock-3.15.4 idna-3.7 packaging-24.1 platformdirs-4.2.2 pyOpenSSL-24.2.1 pycparser-2.22 pyjwt-2.8.0 pytz-2024.1 pyyaml-6.0.1 requests-2.32.3 setuptools-72.1.0 snowflake-connector-python-3.12.0 snowflake-snowpark-python-1.9.0 sortedcontainers-2.4.0 tomlkit-0.13.0 typing-extensions-4.12.2 urllib3-1.26.19 wheel-0.43.0\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/sortedcontainers already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/sortedcontainers-2.4.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/pytz already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/pytz-2024.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/asn1crypto already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/asn1crypto-1.5.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/wheel already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/wheel-0.43.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/urllib3 already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/urllib3-1.26.19.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/typing_extensions.py already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/typing_extensions-4.12.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/__pycache__ already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/tomlkit already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/tomlkit-0.13.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/distutils-precedence.pth already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/_distutils_hack already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/pkg_resources already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/setuptools already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/setuptools-72.1.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/yaml already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/_yaml already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/PyYAML-6.0.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/jwt already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/PyJWT-2.8.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/pycparser already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/pycparser-2.22.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/platformdirs already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/platformdirs-4.2.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/packaging already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/packaging-24.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/idna already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/idna-3.7.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/filelock already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/filelock-3.15.4.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/cloudpickle already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/cloudpickle-2.0.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/charset_normalizer already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/charset_normalizer-3.3.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/certifi already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/certifi-2024.7.4.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/requests already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/requests-2.32.3.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/_cffi_backend.cpython-39-x86_64-linux-gnu.so already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/cffi already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/cffi-1.16.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/cryptography already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/cryptography-42.0.8.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/OpenSSL already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/pyOpenSSL-24.2.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/snowflake already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/snowflake_connector_python-3.12.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/snowflake_snowpark_python-1.9.0-py3.11-nspkg.pth already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/snowflake_snowpark_python-1.9.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/bin already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0mWARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "Collecting scikit-learn==1.5.1\n",
      "  Using cached scikit_learn-1.5.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Using cached scikit_learn-1.5.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.4 MB)\n",
      "Installing collected packages: scikit-learn\n",
      "Successfully installed scikit-learn-1.5.1\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/scikit_learn-1.5.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/sklearn already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/scikit_learn.libs already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0mWARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "Collecting joblib==1.4.2\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Installing collected packages: joblib\n",
      "Successfully installed joblib-1.4.2\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/joblib already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/joblib-1.4.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0mWARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "Collecting scipy==1.13.1\n",
      "  Using cached scipy-1.13.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "Using cached scipy-1.13.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
      "Installing collected packages: scipy\n",
      "Successfully installed scipy-1.13.1\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/scipy already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/scipy-1.13.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/scipy.libs already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0mWARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "Collecting threadpoolctl==3.5.0\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl\n",
      "Successfully installed threadpoolctl-3.5.0\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/threadpoolctl.py already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/threadpoolctl-3.5.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/__pycache__ already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0mWARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "Collecting fosforml==1.0.1\n",
      "  Using cached fosforml-1.0.1-py3-none-any.whl.metadata (1.5 kB)\n",
      "Using cached fosforml-1.0.1-py3-none-any.whl (42 kB)\n",
      "Installing collected packages: fosforml\n",
      "Successfully installed fosforml-1.0.1\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/fosforml already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/tests already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/fosforml-1.0.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0mWARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "Collecting fosforio==1.0.1\n",
      "  Using cached fosforio-1.0.1-py3-none-any.whl.metadata (13 kB)\n",
      "Using cached fosforio-1.0.1-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: fosforio\n",
      "Successfully installed fosforio-1.0.1\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/fosforio already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/fosforio-1.0.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0mWARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "Collecting pandas==2.2.2\n",
      "  Using cached pandas-2.2.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Using cached pandas-2.2.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "Installing collected packages: pandas\n",
      "Successfully installed pandas-2.2.2\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/pandas already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/pandas-2.2.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0mWARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.9.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Using cached matplotlib-3.9.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
      "Installing collected packages: matplotlib\n",
      "Successfully installed matplotlib-3.9.1\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/pylab.py already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/matplotlib already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/matplotlib-3.9.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/mpl_toolkits already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/__pycache__ already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0mWARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "Collecting xgboost\n",
      "  Using cached xgboost-2.1.1-py3-none-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
      "Using cached xgboost-2.1.1-py3-none-manylinux_2_28_x86_64.whl (153.9 MB)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-2.1.1\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/xgboost already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/xgboost-2.1.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/xgboost.libs already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0mWARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "Collecting python-dateutil==2.9.0\n",
      "  Using cached python_dateutil-2.9.0-py2.py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting six>=1.5 (from python-dateutil==2.9.0)\n",
      "  Using cached six-1.16.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Using cached python_dateutil-2.9.0-py2.py3-none-any.whl (230 kB)\n",
      "Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Installing collected packages: six, python-dateutil\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "jupyterlab 3.2.4 requires jupyter-server~=1.4, but you have jupyter-server 2.7.3 which is incompatible.\n",
      "mosaic-ai-client 1.0.0 requires matplotlib==3.1.1, but you have matplotlib 3.9.1 which is incompatible.\n",
      "mosaic-ai-client 1.0.0 requires requests-toolbelt==0.9.1, but you have requests-toolbelt 1.0.0 which is incompatible.\n",
      "mosaic-ai-serving 1.0.0 requires Flask==2.1.1; python_version >= \"3.7\", but you have flask 2.2.5 which is incompatible.\n",
      "mosaic-ai-serving 1.0.0 requires matplotlib==3.6.0; python_version >= \"3.8\", but you have matplotlib 3.9.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed python-dateutil-2.9.0 six-1.16.0\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/six.py already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/six-1.16.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/__pycache__ already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/dateutil already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/python_dateutil-2.9.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0mWARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "Collecting pytz==2024.1\n",
      "  Using cached pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Using cached pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "Installing collected packages: pytz\n",
      "Successfully installed pytz-2024.1\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/pytz already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/pytz-2024.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0mWARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "Collecting six==1.16.0\n",
      "  Using cached six-1.16.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Installing collected packages: six\n",
      "Successfully installed six-1.16.0\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/six.py already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/six-1.16.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/__pycache__ already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0mWARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "Collecting tzdata==2024.1\n",
      "  Using cached tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Using cached tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "Installing collected packages: tzdata\n",
      "Successfully installed tzdata-2024.1\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/tzdata already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/tzdata-2024.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0mWARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "Collecting tqdm\n",
      "  Using cached tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
      "Using cached tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm\n",
      "Successfully installed tqdm-4.66.4\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/tqdm already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/tqdm-4.66.4.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/bin already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0mWARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "Collecting numpy==1.26.4\n",
      "  Using cached numpy-1.26.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Using cached numpy-1.26.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "Installing collected packages: numpy\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "fosforml 1.0.1 requires cloudpickle==3.0.0, but you have cloudpickle 2.0.0 which is incompatible.\n",
      "fosforml 1.0.1 requires urllib3==2.2.1, but you have urllib3 1.26.15 which is incompatible.\n",
      "mosaic-ai-client 1.0.0 requires matplotlib==3.1.1, but you have matplotlib 3.9.1 which is incompatible.\n",
      "mosaic-ai-client 1.0.0 requires requests-toolbelt==0.9.1, but you have requests-toolbelt 1.0.0 which is incompatible.\n",
      "mosaic-ai-serving 1.0.0 requires Flask==2.1.1; python_version >= \"3.7\", but you have flask 2.2.5 which is incompatible.\n",
      "mosaic-ai-serving 1.0.0 requires matplotlib==3.6.0; python_version >= \"3.8\", but you have matplotlib 3.9.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-1.26.4\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/numpy already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/numpy-1.26.4.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/numpy.libs already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/bin already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0mWARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "Found existing installation: urllib3 1.26.15\n",
      "Uninstalling urllib3-1.26.15:\n",
      "  Successfully uninstalled urllib3-1.26.15\n",
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "Collecting urllib3==1.26.15\n",
      "  Using cached urllib3-1.26.15-py2.py3-none-any.whl.metadata (48 kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached urllib3-1.26.15-py2.py3-none-any.whl (140 kB)\n",
      "Installing collected packages: urllib3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "fosforml 1.0.1 requires cloudpickle==3.0.0, but you have cloudpickle 2.0.0 which is incompatible.\n",
      "fosforml 1.0.1 requires urllib3==2.2.1, but you have urllib3 1.26.15 which is incompatible.\n",
      "jsonschema-path 0.3.2 requires referencing<0.32.0,>=0.28.0, but you have referencing 0.33.0 which is incompatible.\n",
      "mosaic-ai-client 1.0.0 requires matplotlib==3.1.1, but you have matplotlib 3.9.1 which is incompatible.\n",
      "mosaic-ai-client 1.0.0 requires requests-toolbelt==0.9.1, but you have requests-toolbelt 1.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed urllib3-1.26.15\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/urllib3 already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0mWARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "Collecting seaborn\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.13.2\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/seaborn already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/seaborn-0.13.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0mWARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "Collecting contourpy==1.2.1\n",
      "  Using cached contourpy-1.2.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
      "Using cached contourpy-1.2.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (304 kB)\n",
      "Installing collected packages: contourpy\n",
      "Successfully installed contourpy-1.2.1\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/contourpy already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/contourpy-1.2.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0mWARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "Collecting cycler==0.12.1\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Installing collected packages: cycler\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "mosaic-ai-client 1.0.0 requires matplotlib==3.1.1, but you have matplotlib 3.9.1 which is incompatible.\n",
      "mosaic-ai-client 1.0.0 requires requests-toolbelt==0.9.1, but you have requests-toolbelt 1.0.0 which is incompatible.\n",
      "mosaic-ai-serving 1.0.0 requires Flask==2.1.1; python_version >= \"3.7\", but you have flask 2.2.5 which is incompatible.\n",
      "mosaic-ai-serving 1.0.0 requires matplotlib==3.6.0; python_version >= \"3.8\", but you have matplotlib 3.9.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed cycler-0.12.1\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/cycler already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/cycler-0.12.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0mWARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "Collecting fonttools==4.53.1\n",
      "  Using cached fonttools-4.53.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (162 kB)\n",
      "Using cached fonttools-4.53.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "Installing collected packages: fonttools\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "mosaic-ai-client 1.0.0 requires matplotlib==3.1.1, but you have matplotlib 3.9.1 which is incompatible.\n",
      "mosaic-ai-client 1.0.0 requires requests-toolbelt==0.9.1, but you have requests-toolbelt 1.0.0 which is incompatible.\n",
      "mosaic-ai-serving 1.0.0 requires Flask==2.1.1; python_version >= \"3.7\", but you have flask 2.2.5 which is incompatible.\n",
      "mosaic-ai-serving 1.0.0 requires matplotlib==3.6.0; python_version >= \"3.8\", but you have matplotlib 3.9.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed fonttools-4.53.1\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/fontTools already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/fonttools-4.53.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/share already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/bin already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0mWARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "Collecting kiwisolver==1.4.5\n",
      "  Using cached kiwisolver-1.4.5-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.4 kB)\n",
      "Using cached kiwisolver-1.4.5-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "Installing collected packages: kiwisolver\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "mosaic-ai-client 1.0.0 requires matplotlib==3.1.1, but you have matplotlib 3.9.1 which is incompatible.\n",
      "mosaic-ai-client 1.0.0 requires requests-toolbelt==0.9.1, but you have requests-toolbelt 1.0.0 which is incompatible.\n",
      "mosaic-ai-serving 1.0.0 requires Flask==2.1.1; python_version >= \"3.7\", but you have flask 2.2.5 which is incompatible.\n",
      "mosaic-ai-serving 1.0.0 requires matplotlib==3.6.0; python_version >= \"3.8\", but you have matplotlib 3.9.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed kiwisolver-1.4.5\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/kiwisolver-1.4.5.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/kiwisolver already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0mWARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "Collecting packaging==24.1\n",
      "  Using cached packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\n",
      "Using cached packaging-24.1-py3-none-any.whl (53 kB)\n",
      "Installing collected packages: packaging\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "jupyterlab 3.2.4 requires jupyter-server~=1.4, but you have jupyter-server 2.7.3 which is incompatible.\n",
      "mosaic-ai-client 1.0.0 requires matplotlib==3.1.1, but you have matplotlib 3.9.1 which is incompatible.\n",
      "mosaic-ai-client 1.0.0 requires requests-toolbelt==0.9.1, but you have requests-toolbelt 1.0.0 which is incompatible.\n",
      "mosaic-ai-serving 1.0.0 requires Flask==2.1.1; python_version >= \"3.7\", but you have flask 2.2.5 which is incompatible.\n",
      "mosaic-ai-serving 1.0.0 requires matplotlib==3.6.0; python_version >= \"3.8\", but you have matplotlib 3.9.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed packaging-24.1\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/packaging already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/packaging-24.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0mWARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "Collecting pillow==10.4.0\n",
      "  Using cached pillow-10.4.0-cp39-cp39-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
      "Using cached pillow-10.4.0-cp39-cp39-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "Installing collected packages: pillow\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "mosaic-ai-client 1.0.0 requires matplotlib==3.1.1, but you have matplotlib 3.9.1 which is incompatible.\n",
      "mosaic-ai-client 1.0.0 requires requests-toolbelt==0.9.1, but you have requests-toolbelt 1.0.0 which is incompatible.\n",
      "mosaic-ai-serving 1.0.0 requires Flask==2.1.1; python_version >= \"3.7\", but you have flask 2.2.5 which is incompatible.\n",
      "mosaic-ai-serving 1.0.0 requires matplotlib==3.6.0; python_version >= \"3.8\", but you have matplotlib 3.9.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed pillow-10.4.0\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/pillow.libs already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/PIL already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/pillow-10.4.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0mWARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "Collecting pyparsing==3.1.2\n",
      "  Using cached pyparsing-3.1.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Using cached pyparsing-3.1.2-py3-none-any.whl (103 kB)\n",
      "Installing collected packages: pyparsing\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "mosaic-ai-client 1.0.0 requires matplotlib==3.1.1, but you have matplotlib 3.9.1 which is incompatible.\n",
      "mosaic-ai-client 1.0.0 requires requests-toolbelt==0.9.1, but you have requests-toolbelt 1.0.0 which is incompatible.\n",
      "mosaic-ai-serving 1.0.0 requires Flask==2.1.1; python_version >= \"3.7\", but you have flask 2.2.5 which is incompatible.\n",
      "mosaic-ai-serving 1.0.0 requires matplotlib==3.6.0; python_version >= \"3.8\", but you have matplotlib 3.9.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed pyparsing-3.1.2\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/pyparsing already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/pyparsing-3.1.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0mWARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "Collecting importlib_resources==6.4.0\n",
      "  Using cached importlib_resources-6.4.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting zipp>=3.1.0 (from importlib_resources==6.4.0)\n",
      "  Using cached zipp-3.19.2-py3-none-any.whl.metadata (3.6 kB)\n",
      "Using cached importlib_resources-6.4.0-py3-none-any.whl (38 kB)\n",
      "Using cached zipp-3.19.2-py3-none-any.whl (9.0 kB)\n",
      "Installing collected packages: zipp, importlib_resources\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "jupyterlab 3.2.4 requires jupyter-server~=1.4, but you have jupyter-server 2.7.3 which is incompatible.\n",
      "mosaic-ai-client 1.0.0 requires matplotlib==3.1.1, but you have matplotlib 3.9.1 which is incompatible.\n",
      "mosaic-ai-client 1.0.0 requires requests-toolbelt==0.9.1, but you have requests-toolbelt 1.0.0 which is incompatible.\n",
      "mosaic-ai-serving 1.0.0 requires Flask==2.1.1; python_version >= \"3.7\", but you have flask 2.2.5 which is incompatible.\n",
      "mosaic-ai-serving 1.0.0 requires matplotlib==3.6.0; python_version >= \"3.8\", but you have matplotlib 3.9.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed importlib_resources-6.4.0 zipp-3.19.2\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/zipp already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/zipp-3.19.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/importlib_resources already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/importlib_resources-6.4.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0mWARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "Collecting zipp==3.19.2\n",
      "  Using cached zipp-3.19.2-py3-none-any.whl.metadata (3.6 kB)\n",
      "Using cached zipp-3.19.2-py3-none-any.whl (9.0 kB)\n",
      "Installing collected packages: zipp\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "jupyterlab 3.2.4 requires jupyter-server~=1.4, but you have jupyter-server 2.7.3 which is incompatible.\n",
      "mosaic-ai-client 1.0.0 requires matplotlib==3.1.1, but you have matplotlib 3.9.1 which is incompatible.\n",
      "mosaic-ai-client 1.0.0 requires requests-toolbelt==0.9.1, but you have requests-toolbelt 1.0.0 which is incompatible.\n",
      "mosaic-ai-serving 1.0.0 requires Flask==2.1.1; python_version >= \"3.7\", but you have flask 2.2.5 which is incompatible.\n",
      "mosaic-ai-serving 1.0.0 requires matplotlib==3.6.0; python_version >= \"3.8\", but you have matplotlib 3.9.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed zipp-3.19.2\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/zipp already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /tmp/pip_packages/zipp-3.19.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Installing packages set for without init script\n",
    "\n",
    "!pip install --upgrade pip\n",
    "!pip install snowflake-connector-python[pandas]\n",
    "!pip install snowflake-snowpark-python[pandas]\n",
    "!pip install snowflake-snowpark-python==1.9.0\n",
    "!pip install scikit-learn==1.5.1 --no-deps\n",
    "!pip install joblib==1.4.2\n",
    "!pip install scipy==1.13.1 --no-deps\n",
    "!pip install threadpoolctl==3.5.0\n",
    "!pip install fosforml==1.0.1 --no-deps\n",
    "!pip install fosforio==1.0.1 --no-deps\n",
    "!pip install pandas==2.2.2 --no-deps\n",
    "!pip install matplotlib --no-deps\n",
    "!pip install xgboost --no-deps\n",
    "!pip install python-dateutil==2.9.0\n",
    "!pip install pytz==2024.1\n",
    "!pip install six==1.16.0 --no-deps\n",
    "!pip install tzdata==2024.1\n",
    "!pip install tqdm\n",
    "!pip install numpy==1.26.4\n",
    "# !pip install --upgrade --q snowflake-snowpark-python==1.9.0\n",
    "!pip uninstall urllib3 -y\n",
    "!pip install urllib3==1.26.15\n",
    "!pip install seaborn --no-deps \n",
    "!pip install contourpy==1.2.1 --no-deps\n",
    "!pip install cycler==0.12.1\n",
    "!pip install fonttools==4.53.1\n",
    "!pip install kiwisolver==1.4.5\n",
    "!pip install packaging==24.1\n",
    "!pip install pillow==10.4.0\n",
    "!pip install pyparsing==3.1.2\n",
    "!pip install importlib_resources==6.4.0\n",
    "!pip install zipp==3.19.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b72de8e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aiohttp==3.9.3\n",
      "aiosignal==1.3.1\n",
      "alembic==1.13.1\n",
      "anyio==4.2.0\n",
      "archspec @ file:///croot/archspec_1697725767277/work\n",
      "argon2-cffi==23.1.0\n",
      "argon2-cffi-bindings==21.2.0\n",
      "asn1crypto==1.5.1\n",
      "asttokens==2.4.1\n",
      "async-generator==1.10\n",
      "async-timeout==4.0.3\n",
      "attrs==23.2.0\n",
      "Babel==2.14.0\n",
      "beautifulsoup4==4.12.3\n",
      "bleach==4.1.0\n",
      "boltons @ file:///croot/boltons_1677628692245/work\n",
      "bqplot==0.12.42\n",
      "Brotli @ file:///tmp/abs_ecyw11_7ze/croots/recipe/brotli-split_1659616059936/work\n",
      "certifi==2024.7.4\n",
      "certipy==0.1.3\n",
      "cffi==1.16.0\n",
      "charset-normalizer==3.3.2\n",
      "click==8.1.7\n",
      "clickclick==20.10.2\n",
      "cloudpickle==2.0.0\n",
      "comm==0.2.1\n",
      "conda @ file:///croot/conda_1701719518285/work\n",
      "conda-content-trust @ file:///tmp/abs_5952f1c8-355c-4855-ad2e-538535021ba5h26t22e5/croots/recipe/conda-content-trust_1658126371814/work\n",
      "conda-libmamba-solver @ file:///croot/conda-libmamba-solver_1702997573971/work/src\n",
      "conda-package-handling @ file:///croot/conda-package-handling_1690999929514/work\n",
      "conda_package_streaming @ file:///croot/conda-package-streaming_1690987966409/work\n",
      "configparser==7.0.0\n",
      "connexion==2.6.0\n",
      "contourpy==1.2.1\n",
      "cryptography==42.0.8\n",
      "cycler==0.12.1\n",
      "Cython==0.29.15\n",
      "decorator==5.1.1\n",
      "defusedxml==0.7.1\n",
      "dill==0.3.8\n",
      "distro @ file:///croot/distro_1701455004953/work\n",
      "ds-lime==0.1.1.27\n",
      "entrypoints==0.4\n",
      "exceptiongroup==1.2.0\n",
      "executing==2.0.1\n",
      "fastjsonschema==2.19.1\n",
      "filelock==3.15.4\n",
      "flasgger==0.9.5\n",
      "Flask==2.2.5\n",
      "fonttools==4.53.1\n",
      "fosforio==1.0.1\n",
      "fosforml==1.0.1\n",
      "frozenlist==1.4.1\n",
      "greenlet==3.0.3\n",
      "gunicorn==19.9.0\n",
      "idna==3.7\n",
      "importlib-metadata==7.0.1\n",
      "importlib_resources==6.4.0\n",
      "inflection==0.5.1\n",
      "ipykernel==5.5.5\n",
      "ipython==8.18.1\n",
      "ipython-genutils==0.2.0\n",
      "ipywidgets==8.0.4\n",
      "itsdangerous==2.0.1\n",
      "jedi==0.19.1\n",
      "Jinja2==3.0.3\n",
      "joblib==1.4.2\n",
      "json5==0.9.14\n",
      "jsonpatch @ file:///tmp/build/80754af9/jsonpatch_1615747632069/work\n",
      "jsonpointer==2.1\n",
      "jsonschema==4.19.0\n",
      "jsonschema-path==0.3.2\n",
      "jsonschema-specifications==2023.12.1\n",
      "jupyter-events==0.9.0\n",
      "jupyter-lsp==2.2.1\n",
      "jupyter-telemetry==0.1.0\n",
      "jupyter_client==8.6.0\n",
      "jupyter_core==5.7.1\n",
      "jupyter_server==2.7.3\n",
      "jupyter_server_proxy==4.1.0\n",
      "jupyter_server_terminals==0.5.2\n",
      "jupyterhub==1.5.0\n",
      "jupyterlab==3.2.4\n",
      "jupyterlab-widgets==3.0.9\n",
      "jupyterlab_pygments==0.3.0\n",
      "jupyterlab_server==2.25.2\n",
      "kiwisolver==1.4.5\n",
      "lazy-object-proxy==1.10.0\n",
      "libmambapy @ file:///croot/mamba-split_1704219408234/work/libmambapy\n",
      "llvmlite==0.41.1\n",
      "Mako==1.3.2\n",
      "MarkupSafe==2.1.4\n",
      "marshmallow==2.19.5\n",
      "matplotlib==3.9.1\n",
      "matplotlib-inline==0.1.6\n",
      "menuinst @ file:///croot/menuinst_1702390294373/work\n",
      "mistune==3.0.2\n",
      "mosaic-ai-client==1.0.0\n",
      "mosaic-ai-serving==1.0.0\n",
      "mosaic-common-utils==1.0.0\n",
      "mosaic-utils==1.0.2\n",
      "multidict==6.0.4\n",
      "multiprocess==0.70.16\n",
      "nbclassic==0.5.6\n",
      "nbclient==0.5.4\n",
      "nbconvert==7.14.2\n",
      "nbformat==5.9.2\n",
      "nest-asyncio==1.6.0\n",
      "notebook==6.4.10\n",
      "notebook_shim==0.2.3\n",
      "numba==0.58.1\n",
      "numpy==1.26.4\n",
      "oauthlib==3.2.2\n",
      "openapi-schema-validator==0.6.2\n",
      "openapi-spec-validator==0.7.1\n",
      "overrides==7.7.0\n",
      "packaging==24.1\n",
      "pamela==1.1.0\n",
      "pandas==2.2.2\n",
      "pandocfilters==1.5.1\n",
      "parso==0.8.3\n",
      "pathable==0.4.3\n",
      "pexpect==4.9.0\n",
      "pillow==10.4.0\n",
      "platformdirs==4.2.2\n",
      "pluggy @ file:///tmp/build/80754af9/pluggy_1648024445381/work\n",
      "prometheus-client==0.19.0\n",
      "prompt-toolkit==3.0.43\n",
      "protobuf==3.20.2\n",
      "psycopg2-binary==2.8.6\n",
      "ptyprocess==0.7.0\n",
      "pure-eval==0.2.2\n",
      "pyarrow==17.0.0\n",
      "pycosat @ file:///croot/pycosat_1696536503704/work\n",
      "pycparser==2.22\n",
      "Pygments==2.17.2\n",
      "PyJWT==2.8.0\n",
      "PyMySQL==1.1.1\n",
      "pyOpenSSL==24.2.1\n",
      "pyparsing==3.1.2\n",
      "PySocks @ file:///tmp/build/80754af9/pysocks_1605305812635/work\n",
      "python-dateutil==2.9.0\n",
      "python-dotenv==0.20.0\n",
      "python-json-logger==2.0.7\n",
      "pytz==2024.1\n",
      "PyYAML==6.0.1\n",
      "pyzmq==25.1.2\n",
      "referencing==0.33.0\n",
      "requests==2.32.3\n",
      "requests-toolbelt==1.0.0\n",
      "rfc3339-validator==0.1.4\n",
      "rfc3986-validator==0.1.1\n",
      "rpds-py==0.17.1\n",
      "ruamel.yaml==0.16.9\n",
      "ruamel.yaml.clib @ file:///croot/ruamel.yaml.clib_1666302247304/work\n",
      "scikit-learn==1.2.1\n",
      "scipy==1.13.1\n",
      "seaborn==0.13.2\n",
      "Send2Trash==1.8.2\n",
      "shap==0.44.1\n",
      "shutils==0.1.0\n",
      "simpervisor==1.0.0\n",
      "six==1.16.0\n",
      "skater==1.0.4\n",
      "slicer==0.0.7\n",
      "sniffio==1.3.0\n",
      "snowflake-connector-python==3.12.0\n",
      "snowflake-snowpark-python==1.20.0\n",
      "sortedcontainers==2.4.0\n",
      "soupsieve==2.5\n",
      "SQLAlchemy==1.3.5\n",
      "stack-data==0.6.3\n",
      "terminado==0.18.0\n",
      "threadpoolctl==3.5.0\n",
      "tinycss2==1.2.1\n",
      "tomlkit==0.13.0\n",
      "tornado==6.4\n",
      "tqdm==4.66.4\n",
      "traitlets==5.9.0\n",
      "traittypes==0.2.1\n",
      "typing_extensions==4.12.2\n",
      "tzdata==2024.1\n",
      "urllib3==1.26.15\n",
      "uWSGI @ file:///home/conda/feedstock_root/build_artifacts/uwsgi_1681743169039/work\n",
      "wcwidth==0.2.13\n",
      "webencodings==0.5.1\n",
      "websocket-client==1.7.0\n",
      "Werkzeug==3.0.1\n",
      "widgetsnbextension==4.0.9\n",
      "xgboost==2.1.1\n",
      "yarl==1.9.4\n",
      "zipp==3.19.2\n",
      "zstandard @ file:///croot/zstandard_1677013143055/work\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip freeze"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06a4ab2",
   "metadata": {},
   "source": [
    "# Restart and clear outputs\n",
    "\n",
    "# Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbf7fe85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection manager service url initialised to http://fdc-project-manager:80/project-manager\n",
      "If you need to update its value then update the variable CONNECTION_MANAGER_BASE_URL in os env.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfosforio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m snowflake\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfosforml\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfosforml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstants\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MLModelFlavours\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfosforio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_dataframe\n",
      "File \u001b[0;32m/tmp/pip_packages/fosforml/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# -*- coding: utf-8 -*-\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      4\u001b[0m     add_version,\n\u001b[1;32m      5\u001b[0m     apply_model_strategy,\n\u001b[1;32m      6\u001b[0m     build_time_metrics,\n\u001b[1;32m      7\u001b[0m     delete_model,\n\u001b[1;32m      8\u001b[0m     deploy_model,\n\u001b[1;32m      9\u001b[0m     describe_model,\n\u001b[1;32m     10\u001b[0m     describe_model_using_model_name,\n\u001b[1;32m     11\u001b[0m     ensemble_model_list,\n\u001b[1;32m     12\u001b[0m     fetch_model_resources,\n\u001b[1;32m     13\u001b[0m     generate_schema,\n\u001b[1;32m     14\u001b[0m     get_model_info,\n\u001b[1;32m     15\u001b[0m     get_model_profiling,\n\u001b[1;32m     16\u001b[0m     list_models,\n\u001b[1;32m     17\u001b[0m     load_model,\n\u001b[1;32m     18\u001b[0m     load_train_and_test_data,\n\u001b[1;32m     19\u001b[0m     promote_model,\n\u001b[1;32m     20\u001b[0m     register_ensemble_model,\n\u001b[1;32m     21\u001b[0m     register_model,\n\u001b[1;32m     22\u001b[0m     stop_model,\n\u001b[1;32m     23\u001b[0m     update_existing_model,\n\u001b[1;32m     24\u001b[0m     update_metadata_info,\n\u001b[1;32m     25\u001b[0m     update_model_details,\n\u001b[1;32m     26\u001b[0m     update_version_details,\n\u001b[1;32m     27\u001b[0m     fetch_feedback_accuracy,\n\u001b[1;32m     28\u001b[0m     delete_model_version,\n\u001b[1;32m     29\u001b[0m     add_artifacts,\n\u001b[1;32m     30\u001b[0m     download_artifacts,\n\u001b[1;32m     31\u001b[0m     get_model_obj\n\u001b[1;32m     32\u001b[0m )\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfosforml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwidgets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregister_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RegisterModel\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecorators\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m scoring_func\n",
      "File \u001b[0;32m/tmp/pip_packages/fosforml/api.py:13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datetime\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmosaic_utils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbuild_time_metrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m metrics_stats\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmosaic_utils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mencoding_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m base64_encode\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmosaic_utils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfile_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     16\u001b[0m     create_model_tar,\n\u001b[1;32m     17\u001b[0m     extract_tar,\n\u001b[1;32m     18\u001b[0m     pickle_dumps,\n\u001b[1;32m     19\u001b[0m     pickle_loads,\n\u001b[1;32m     20\u001b[0m )\n",
      "File \u001b[0;32m/tmp/pip_packages/mosaic_utils/ai/build_time_metrics/metrics.py:7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01myaml\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m metrics\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      9\u001b[0m     accuracy_score,\n\u001b[1;32m     10\u001b[0m     average_precision_score,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m     roc_auc_score,\n\u001b[1;32m     27\u001b[0m )\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     30\u001b[0m     get_headers,\n\u001b[1;32m     31\u001b[0m     get_model_type_handler,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     35\u001b[0m     update_progress,\n\u001b[1;32m     36\u001b[0m )\n",
      "File \u001b[0;32m/tmp/pip_packages/sklearn/__init__.py:82\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _distributor_init  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __check_build  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m---> 82\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clone\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_show_versions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m show_versions\n\u001b[1;32m     85\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcalibration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshow_versions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    129\u001b[0m ]\n",
      "File \u001b[0;32m/tmp/pip_packages/sklearn/base.py:17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_config\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _IS_32BIT\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_set_output\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _SetOutputMixin\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_tags\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     20\u001b[0m     _DEFAULT_TAGS,\n\u001b[1;32m     21\u001b[0m )\n",
      "File \u001b[0;32m/tmp/pip_packages/sklearn/utils/__init__.py:19\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m issparse\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmurmurhash\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m murmurhash3_32\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclass_weight\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compute_class_weight, compute_sample_weight\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _joblib\n",
      "File \u001b[0;32msklearn/utils/murmurhash.pyx:1\u001b[0m, in \u001b[0;36minit sklearn.utils.murmurhash\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "from fosforio import snowflake\n",
    "from fosforml import *\n",
    "from fosforml.constants import MLModelFlavours\n",
    "from fosforio import get_dataframe\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "pd.set_option('display.max_columns', 500)\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "from joblib import dump, load\n",
    "import requests\n",
    "#from tqdm import tqdm\n",
    "import time\n",
    "import calendar\n",
    "import configparser\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import datetime\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from time import sleep\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from dateutil.easter import easter\n",
    "from scipy.optimize import minimize_scalar\n",
    "from scipy.optimize import curve_fit\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5999d5f2",
   "metadata": {},
   "source": [
    "# Importing data from snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e536f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from fosforio import snowflake\n",
    "#from fosforio import get_dataframe\n",
    "# snowflake.get_connection(connection_name=\"ME_AD_SALES_CXN\")\n",
    "#df = get_dataframe(\"AD_SALES_IMP\")\n",
    "# df_all = get_dataframe(\"AD_TECH_INPUT\")\n",
    "df_all = pd.read_csv(\"./ad_tech_input.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb41bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df_all.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9d379d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f59857",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d633377b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.columns = df.columns.str.lower()\n",
    "df_all.columns = df_all.columns.str.lower()\n",
    "#df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3758d0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2db2869-09aa-4132-8972-a3cc74bb0263",
   "metadata": {},
   "source": [
    "# Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158fc2cd-8e2e-4e27-b288-87a549556779",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_col=['ad_date', 'site_id','advertiser_id', 'order_id','ad_type', 'ad_format', 'ad_media_type',\n",
    "         'device_type', 'city', 'line_item_group', 'line_item_type', 'monetization_channel','os_type']\n",
    "scat_col = ['site_id','ad_type', 'ad_format', 'device_type', 'advertiser_id',\n",
    "            'line_item_group', 'line_item_type', 'os_type','monetization_channel']\n",
    "num_col=list(df_all.select_dtypes(np.number).columns)\n",
    "\n",
    "import seaborn as sns\n",
    "sns.heatmap(df_all.isnull(),cbar=False,cbar_kws={'color':'r'})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "34d3e90d",
   "metadata": {},
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(df_all.isnull(),cbar=False,cbar_kws={'color':'r'})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00e0244-4680-44bf-9dfb-a67f5f61eff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(4,2, figsize=(14,12))\n",
    "axes_ = [axes_row for axes in ax for axes_row in axes]\n",
    "\n",
    "for i,col in enumerate(scat_col):\n",
    "    sns.countplot(data=df_all,x=col,ax=axes_[i])\n",
    "    if col=='advertiser_id':\n",
    "        plt.xticks(rotation=90)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f37132-8305-4793-8c92-f8828d07970d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in num_col:\n",
    "    if i!='total_revenue':\n",
    "        sns.scatterplot(data=df_all,x=i,y='total_revenue')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb091da-8e4e-46a6-b24f-af4eb795f0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f266fcc2-2b3b-47a2-9dcb-cf2c2efb53de",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in (scat_col):\n",
    "    title='Relationship of '+col+' with total_revenue'\n",
    "    plt.figure(figsize=(6,4))\n",
    "    sns.barplot(y=df_all['total_revenue'],x=df_all[col])\n",
    "    if col=='advertiser_id':\n",
    "        plt.xticks(rotation=90)\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c88c3cf-8b3f-490d-8cdd-abef798c12dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in (scat_col):\n",
    "    title='Relationship of '+ col +' with total_impressions'\n",
    "    plt.figure(figsize=(6,4))\n",
    "    sns.barplot(y=df_all['total_impressions'],x=df_all[col],)\n",
    "    if col=='advertiser_id':\n",
    "        plt.xticks(rotation=90)\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a867e33c-830f-4478-89f8-10dc9e3c7c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cat_col:\n",
    "    df_all[i]=df_all[i].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8f14dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f35e75-ff39-485a-a87d-f01ff77b4399",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.drop(['ad_unit_id','revenue_share_percent','ad_type_id','site_id','advertiser_id',\n",
    "        'ad_date','geo_id','order_id', 'ad_type', 'ad_format', 'ad_media_type', 'line_item_group',\n",
    "            'city', 'city_code'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71b2543",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4698ba70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.drop(['device_category_id', 'line_item_type_id', 'os_id',\n",
    "       'monetization_channel_id','population', 'city_lat', 'city_lon'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963034fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.select_dtypes(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006f89ae-6bbc-4d63-8624-3f37c9c04fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df_all.select_dtypes(object).columns:\n",
    "    pd.crosstab(df_all['monetization_channel'],df_all[i]).plot(kind='bar')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab7196b",
   "metadata": {},
   "source": [
    "# Predictive Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12453c4-15b8-4d77-8d7d-b4a8aa2162db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4df5c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9147704-4046-457d-8ca2-c7235c0c0051",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xd = df_all.drop('total_revenue',axis=1)\n",
    "y = df_all['total_revenue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b3694b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xd.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a446e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d15e0b2-fc4c-4df7-93dc-ae3d829a5d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = pd.get_dummies(Xd,drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a35cbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86301728-34bc-4f81-8f38-9b73a6e5e206",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import StandardScaler\n",
    "#ss = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0caeacf-bba9-47e3-b386-ebd2c62d4f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X[pc_col] = pd.DataFrame(ss.fit_transform(X[pc_col]),columns=[pc_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a361d941-0784-4adc-aed8-69adba480dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(Xd,y,test_size=0.2,random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f62ad3-0adc-418b-8d21-e558d18a7a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_col = ['total_impressions', 'viewable_impressions', 'measurable_impressions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a39c2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline(steps=[\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('pca', PCA(n_components=2))\n",
    "        ]), pc_col),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), ['device_type', 'line_item_type', 'os_type',\n",
    "       'monetization_channel'])\n",
    "    ])\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3c3b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "\n",
    "    {\n",
    "        'name': 'RandomForestRegressor',\n",
    "        'regressor': [RandomForestRegressor()],\n",
    "        'regressor__n_estimators': [50],\n",
    "        'regressor__max_depth': [10],\n",
    "        'regressor__min_samples_split': [2],\n",
    "        'regressor__min_samples_leaf': [1],\n",
    "        'regressor__bootstrap': [True]\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb07eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline = Pipeline(steps=[\n",
    "#    ('preprocessor', preprocessor),\n",
    "#    ('regressor', LinearRegression())  # Placeholder\n",
    "#])\n",
    "\n",
    "best_estimators = []\n",
    "for model_params in models:\n",
    "    model_name = model_params.pop('name')  # Extract the model name\n",
    "    grid_search = GridSearchCV(pipeline, model_params, cv=3, scoring='r2', n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_estimator = grid_search.best_estimator_\n",
    "    best_estimators.append(best_estimator)\n",
    "    print(f\"Training completed for model {model_name}\")\n",
    "    \n",
    "    # Save the best model\n",
    "    joblib.dump(best_estimator, f'best_model_{model_name}.pkl')\n",
    "    print(f\"Best model {model_name} saved to best_model_{model_name}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7411d987",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d95ccda",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for estimator in best_estimators:\n",
    "    y_pred_train = estimator.predict(X_train)\n",
    "    y_pred_test = estimator.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred_test)\n",
    "    r2 = r2_score(y_test, y_pred_test)\n",
    "    results.append({\n",
    "        'model': estimator.named_steps['regressor'].__class__.__name__,\n",
    "        'best_params': estimator.named_steps['regressor'].get_params(),\n",
    "        'mse': mse,\n",
    "        'r2': r2\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7391ab90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['predicted_revenue'] = best_estimator.predict(Xd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59701539",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy['predicted_revenue'] = best_estimator.predict(Xd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00dadc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17063d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c786b737",
   "metadata": {},
   "source": [
    "# In this section we are joining multiple tables, realigning indexes to get the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ded1557",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check type of data (series/ array/ dataframe)\n",
    "\n",
    "type(Xd), type(X_train), type(X_test), type(y), type(y_train), type(y_test), type(results), type(y_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca293e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62a676a",
   "metadata": {},
   "source": [
    "# Creating Data frames as necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32c7977",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df= pd.DataFrame(y)\n",
    "y_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687b267c-3d9a-4dfe-b133-f57d9a7c18d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_df= pd.DataFrame(y_train)\n",
    "y_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f5446b-9b87-4bdc-9221-ab78e778b0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_df= pd.DataFrame(y_test)\n",
    "y_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa94720",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list_temp = y_train_df.index.values.tolist()\n",
    "min(index_list_temp), max(index_list_temp), len(index_list_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f287897",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list_temp = y_test_df.index.values.tolist()\n",
    "min(index_list_temp), max(index_list_temp), len(index_list_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fd6e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fc0ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check type of data (series/ array/ dataframe)\n",
    "\n",
    "type(X_train), type(X_test), type(y_train_df), type(y_test_df), type(y_pred_train), type(y_pred_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa1fd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0f10db",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_df = pd.DataFrame(y_pred_train, columns=['predicted_revenue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcbf005",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e8f093",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_df = pd.DataFrame(y_pred_test,columns=['predicted_revenue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbcc5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_df.reset_index(drop = True)\n",
    "y_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba05dcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining Actuals and predicted Y columns\n",
    "\n",
    "y_train_final= pd.concat([y_train_df, y_train_pred_df.set_index(y_train_df.index)], axis=1)\n",
    "y_train_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9f7c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_final= pd.concat([y_test_df, y_test_pred_df.set_index(y_test_df.index)], axis=1)\n",
    "y_test_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b72733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining Train and test Y columns\n",
    "\n",
    "y_all = pd.concat([y_train_final, y_test_final])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e9f598",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832f863b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_compare = pd.merge(y_df, y_all, left_index=True, right_index=True)\n",
    "y_compare.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd061042",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_compare[y_compare['total_revenue_x']!=y_compare['total_revenue_y']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062ec433",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_all = y_all.sort_index(axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183fdd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_all.sort_index(axis=0, inplace = True)\n",
    "y_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469aee3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf11e052",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4246596",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5b941a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_all.sort_index(axis=0)\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f0d593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining x and y columns with all details\n",
    "\n",
    "model_output = pd.merge(df_final, y_all, left_index=True, right_index=True)\n",
    "#model_output = pd.concat([df_all, y_all], axis = 1)\n",
    "#model_output = df_all.join(y_all)\n",
    "model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27330f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check\n",
    "\n",
    "print(model_output['predicted_revenue_x'].sum())\n",
    "print(model_output['total_revenue_x'].sum())\n",
    "print(model_output['total_revenue_y'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f760ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_output.columns\n",
    "# fixing column names of revenue which comes in input as well as output data\n",
    "\n",
    "model_output.columns = ['ad_date', 'site_id', 'ad_type_id', 'geo_id', 'device_category_id',\n",
    "       'advertiser_id', 'order_id', 'line_item_type_id', 'os_id',\n",
    "       'monetization_channel_id', 'ad_unit_id', 'total_impressions', 'total_revenue',\n",
    "       'viewable_impressions', 'measurable_impressions',\n",
    "       'revenue_share_percent', 'ad_type', 'ad_format', 'ad_media_type',\n",
    "       'device_type', 'city', 'city_code', 'population', 'city_lat',\n",
    "       'city_lon', 'line_item_group', 'line_item_type', 'monetization_channel',\n",
    "       'os_type', 'total_revenue2', 'predicted_revenue']\n",
    "model_output.info()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "978febe5",
   "metadata": {},
   "source": [
    "# fixing column names of revenue which comes in input as well as output data\n",
    "\n",
    "model_output.columns = ['ad_date', 'site_id', 'ad_type_id', 'geo_id', 'device_category_id',\n",
    "       'advertiser_id', 'order_id', 'line_item_type_id', 'os_id',\n",
    "       'monetization_channel_id', 'ad_unit_id', 'total_impressions', 'total_revenue',\n",
    "       'viewable_impressions', 'measurable_impressions',\n",
    "       'revenue_share_percent', 'ad_type', 'ad_format', 'ad_media_type',\n",
    "       'device_type', 'city', 'city_code', 'population', 'city_lat',\n",
    "       'city_lon', 'line_item_group', 'line_item_type', 'monetization_channel',\n",
    "       'os_type', 'total_revenue2', 'predicted_revenue']\n",
    "model_output.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b7f5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output[model_output['total_revenue_x']!=model_output['total_revenue_y']].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb6010a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if both the columns actually have same values\n",
    "\n",
    "#model_output['total_revenue'].equals(model_output['total_revenue2']) \n",
    "model_output['total_revenue_x'].equals(model_output['total_revenue_y']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515b17b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output['check'] = model_output.apply(lambda x: x['total_revenue_x'] if x['total_revenue_x'] <\n",
    "                     x['total_revenue_y'] else np.nan, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dc7a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output['check'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4501ef",
   "metadata": {},
   "source": [
    "# Pushing Model output to Snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc1f342",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from snowflake.snowpark.session import Session\n",
    "user = os.getenv(\"user\")\n",
    "warehouse = os.getenv(\"warehouse\")\n",
    "schema= os.getenv(\"schema\")\n",
    "database = os.getenv(\"database\")\n",
    "role =  os.getenv(\"role\")\n",
    "account =  os.getenv(\"account\")\n",
    "password= os.getenv(\"password\")\n",
    "\n",
    "connection_params = dict(user=user, \n",
    "                         password=password, \n",
    "                         account=account, \n",
    "                         warehouse=warehouse, \n",
    "                         database=database,\n",
    "                         schema=schema, \n",
    "                         role=role)\n",
    "\n",
    "session = Session.builder.configs(connection_params).create()\n",
    "\n",
    "session.sql('use warehouse {};'.format(warehouse)).collect()\n",
    "\n",
    "session.sql('use database {};'.format(database)).collect()\n",
    "\n",
    "session.sql('use schema {}.{};'.format(database, schema)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731f951b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_snowflake = session.createDataFrame(df_all.values.tolist(),\n",
    "        schema = df_all.columns.tolist())\n",
    "\n",
    "df_snowflake.write.mode(\"overwrite\").save_as_table(\"ME_DB.ME_AD_SALES_SCHEMA.AD_TECH_OUTPUT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f999a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245f5ae1",
   "metadata": {},
   "source": [
    "# Model Registrartion using fosforml SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19b3564",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Snowpark lib\n",
    "from snowflake.snowpark import Session\n",
    "\n",
    "# Data Science Libs\n",
    "#import numpy as np\n",
    "#import pandas as pd\n",
    "\n",
    "# create_temp_table warning suppresion\n",
    "#import warnings; warnings.simplefilter('ignore')\n",
    "\n",
    "#ConfigParser to read ini file\n",
    "# import configparser\n",
    "#!pip install fosforml\n",
    "from fosforio import snowflake\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60650415",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688c4ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fosforml import *\n",
    "from fosforml.constants import MLModelFlavours\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7c13c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@scoring_func\n",
    "def score(model, request):\n",
    "\n",
    "    import json\n",
    "    payload = request.json[\"payload\"]\n",
    "    if isinstance(request.json[\"payload\"],str):\n",
    "        payload_data = eval(payload)\n",
    "        if isinstance(payload_data['total_impressions'], int):\n",
    "                data_json = eval(payload)\n",
    "                data = pd.DataFrame([data_json])\n",
    "                prediction = pd.DataFrame(model.predict(data))\n",
    "                return prediction[0].to_list()[0]\n",
    "        elif isinstance(payload_data['total_impressions'], dict):\n",
    "                data = pd.DataFrame(eval(payload))\n",
    "                prediction = pd.DataFrame(model.predict(data))\n",
    "                return prediction[0].tolist()\n",
    "        elif isinstance(payload_data['total_impressions'], list):\n",
    "                data = pd.DataFrame(payload_data)\n",
    "                prediction = pd.DataFrame(model.predict(data))\n",
    "                return prediction.tolist()\n",
    "    return \"This method is not allowed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e082e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "payload = str(X_test.iloc[1:3].to_dict())\n",
    "req = requests.Request()\n",
    "req.json = {\"payload\": payload}\n",
    "print(score(best_estimator, req))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2ec1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee733fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "payload = str(X_test.iloc[1].to_dict())\n",
    "req = requests.Request()\n",
    "req.json = {\"payload\": payload}\n",
    "print(score(best_estimator, req))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42572f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64668451",
   "metadata": {},
   "source": [
    "# Sample Payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b293079",
   "metadata": {},
   "outputs": [],
   "source": [
    "req.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c03957",
   "metadata": {},
   "outputs": [],
   "source": [
    "yo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf5f4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## registering the model in Fosfor.\n",
    "register_model(best_estimator,\n",
    "               score, \n",
    "               name=\"Ad_Sales_Prediction_Model_Custom_3_9\", \n",
    "               description=\"Ad_Sales_Prediction_RandomForest_Model_Custom_3_9\",\n",
    "               flavour=MLModelFlavours.sklearn,\n",
    "               model_type=\"regression\",\n",
    "#                init_script=\"\\\\n pip install fosforml==1.0.1 \\\\n pip install fosforio[snowflake] \\\\n pip install sklearn\\\\n pip install snowflake-connector-python[pandas]\",\n",
    "               init_script=\"\\\\n pip install scikit-learn==1.5.1 --no-deps\\\\n pip install joblib==1.4.2\\\\n pip install scipy==1.13.1\\\\n pip install threadpoolctl==3.5.0\\\\n pip install fosforml==1.0.1\\\\n pip install fosforio==1.0.1 --no-deps\\\\n pip install holidays==0.9.9\\\\n pip install pandas==2.2.2 --no-deps\\\\n pip install holidays==0.9.9\\\\n pip install python-dateutil==2.9.0\\\\n pip install pytz==2024.1\\\\n pip install six==1.16.0\\\\n pip install tzdata==2024.1\\\\n pip install numpy==1.26.4\",\n",
    "               y_true=y_test,\n",
    "               y_pred=y_pred_test,\n",
    "               #prob=y_prob,\n",
    "               features=X_train.columns,\n",
    "               input_type=\"json\", \n",
    "               explain_ai=True,\n",
    "               x_train=X_train, \n",
    "               x_test=X_test, \n",
    "               y_train=y_train,\n",
    "               y_test=y_test,\n",
    "               feature_names=X_train.columns.tolist(),\n",
    "               original_features=X_train.columns.tolist(),\n",
    "               feature_ids=X_train.columns,\n",
    "               kyd=True, kyd_score = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b12bedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b7d581",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
