{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ff154a0-abe5-4a30-90ba-0393bd1ffc9d",
   "metadata": {},
   "source": [
    "# Data: Ad Sales Data\n",
    "# Use Case: Revenue Prediction\n",
    "# Model: Regression Models\n",
    "\n",
    "Code link: https://www.kaggle.com/code/akshaysunil07/ad-tech-revenue-regression/notebook "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83c8bfe",
   "metadata": {},
   "source": [
    "# Installing packages section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddb0b697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting snowflake-connector-python[pandas]\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b1/89/e8ad64316c505bdf1ae9d2537f72882349a8ef259b00ba6309ead16f76f7/snowflake_connector_python-3.12.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5MB)\n",
      "\u001b[K     |████████████████████████████████| 2.5MB 2.9MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting snowflake-snowpark-python[pandas]\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/77/fd/f4cb374a50559c996f62a4367fa4919c7a52932326c086b9e7496cd786c6/snowflake_snowpark_python-1.20.0-py3-none-any.whl (1.2MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2MB 5.3MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting fosforio==1.0.1\n",
      "  Downloading https://files.pythonhosted.org/packages/39/85/527779b1003babb2deff0438e746d6b7ef8140d5c07f8d4992edcf758f3e/fosforio-1.0.1-py3-none-any.whl\n",
      "Collecting fosforml==1.0.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4b/5e/1f5d25766139d502d7c0df82303d85bcaaa0613c0b833cb77abef618e829/fosforml-1.0.1-py3-none-any.whl (42kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 6.1MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numpy==1.26.4\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/54/30/c2a907b9443cf42b90c17ad10c1e8fa801975f01cb9764f3f8eb8aea638b/numpy-1.26.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2MB)\n",
      "\u001b[K     |████████████████████████████████| 18.3MB 1.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pandas==2.2.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/30/f6f1f1ac36250f50c421b1b6af08c35e5a8b5a84385ef928625336b93e6f/pandas-2.2.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1MB)\n",
      "\u001b[K     |████████████████████████████████| 13.1MB 1.6MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting matplotlib\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/67/e75134cb83d2e533e46d72e2033a413772efdc18291beb981f5d574a829f/matplotlib-3.9.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3MB)\n",
      "\u001b[K     |████████████████████████████████| 8.3MB 21.0MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scikit-learn==1.5.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/12/f8/d6bc56d20c60b2b66e005dfed16fdf8c46dbe559d40896d06c448a65f134/scikit_learn-1.5.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.4MB)\n",
      "\u001b[K     |████████████████████████████████| 13.4MB 24.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting xgboost\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/91/fdbd611bfa9a2c91001ccbbc32b3717d370551a98d083fd0a0bbfcb4b537/xgboost-2.1.1-py3-none-manylinux2014_x86_64.whl (4.5MB)\n",
      "\u001b[K     |████████████████████████████████| 4.5MB 30.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting python-dateutil\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ec/57/56b9bcc3c9c6a792fcbaf139543cee77261f3651ca9da0c93f5c1221264b/python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229kB)\n",
      "\u001b[K     |████████████████████████████████| 235kB 40.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pytz\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/3d/a121f284241f08268b21359bd425f7d4825cffc5ac5cd0e1b3d82ffd2b10/pytz-2024.1-py2.py3-none-any.whl (505kB)\n",
      "\u001b[K     |████████████████████████████████| 512kB 37.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting requests<3.0.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/9b/335f9764261e915ed497fcdeb11df5dfd6f7bf257d4a6a2a686d80da4d54/requests-2.32.3-py3-none-any.whl (64kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 15.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cryptography<43.0.0,>=3.1.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/49/1c/9f6d13cc8041c05eebff1154e4e71bedd1db8e174fff999054435994187a/cryptography-42.0.8-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8MB)\n",
      "\u001b[K     |████████████████████████████████| 3.9MB 42.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting certifi>=2017.4.17\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/d5/c84e1a17bf61d4df64ca866a1c9a913874b4e9bdc131ec689a0ad013fb36/certifi-2024.7.4-py3-none-any.whl (162kB)\n",
      "\u001b[K     |████████████████████████████████| 163kB 24.0MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting platformdirs<5.0.0,>=2.6.0\n",
      "  Downloading https://files.pythonhosted.org/packages/68/13/2aa1f0e1364feb2c9ef45302f387ac0bd81484e9c9a4c5688a322fbdfd08/platformdirs-4.2.2-py3-none-any.whl\n",
      "Collecting asn1crypto<2.0.0,>0.24.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c9/7f/09065fd9e27da0eda08b4d6897f1c13535066174cc023af248fc2a8d5e5a/asn1crypto-1.5.1-py2.py3-none-any.whl (105kB)\n",
      "\u001b[K     |████████████████████████████████| 112kB 27.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cffi<2.0.0,>=1.9\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/ac/e9e77bc385729035143e54cc8c4785bd480eaca9df17565963556b0b7a93/cffi-1.16.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (443kB)\n",
      "\u001b[K     |████████████████████████████████| 450kB 23.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting idna<4,>=2.5\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/3e/741d8c82801c347547f8a2a06aa57dbb1992be9e948df2ea0eda2c8b79e8/idna-3.7-py3-none-any.whl (66kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 16.1MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting charset-normalizer<4,>=2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/69/5d8751b4b670d623aa7a47bef061d69c279e9f922f6705147983aa76c3ce/charset_normalizer-3.3.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142kB)\n",
      "\u001b[K     |████████████████████████████████| 143kB 23.1MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting packaging\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/aa/cc0199a5f0ad350994d660967a8efb233fe0416e4639146c089643407ce6/packaging-24.1-py3-none-any.whl (53kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 15.7MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sortedcontainers>=2.4.0\n",
      "  Downloading https://files.pythonhosted.org/packages/32/46/9cb0e58b2deb7f82b84065f37f3bffeb12413f947f9388e4cac22c4621ce/sortedcontainers-2.4.0-py2.py3-none-any.whl\n",
      "Collecting pyOpenSSL<25.0.0,>=16.2.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/dd/e0aa7ebef5168c75b772eda64978c597a9129b46be17779054652a7999e4/pyOpenSSL-24.2.1-py3-none-any.whl (58kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 14.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting filelock<4,>=3.5\n",
      "  Downloading https://files.pythonhosted.org/packages/ae/f0/48285f0262fe47103a4a45972ed2f9b93e4c80b8fd609fa98da78b2a5706/filelock-3.15.4-py3-none-any.whl\n",
      "Collecting typing-extensions<5,>=4.3\n",
      "  Downloading https://files.pythonhosted.org/packages/26/9f/ad63fc0248c5379346306f8668cda6e2e2e9c95e01216d2b8ffd9ff037d0/typing_extensions-4.12.2-py3-none-any.whl\n",
      "Collecting tomlkit\n",
      "  Downloading https://files.pythonhosted.org/packages/fd/7c/b753bf603852cab0a660da6e81f4ea5d2ca0f0b2b4870766d7aa9bceb7a2/tomlkit-0.13.0-py3-none-any.whl\n",
      "Collecting pyjwt<3.0.0\n",
      "  Downloading https://files.pythonhosted.org/packages/2b/4f/e04a8067c7c96c364cef7ef73906504e2f40d690811c021e1a1901473a19/PyJWT-2.8.0-py3-none-any.whl\n",
      "Collecting urllib3<2.0.0,>=1.21.1; python_version < \"3.10\"\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/6a/99eaaeae8becaa17a29aeb334a18e5d582d873b6f084c11f02581b8d7f7f/urllib3-1.26.19-py2.py3-none-any.whl (143kB)\n",
      "\u001b[K     |████████████████████████████████| 153kB 23.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyarrow; extra == \"pandas\"\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/61/bcd9b58e38ead6ad42b9ed00da33a3f862bc1d445e3d3164799c25550ac2/pyarrow-17.0.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (39.9MB)\n",
      "\u001b[K     |████████████████████████████████| 39.9MB 31.3MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting setuptools>=40.6.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e1/58/e0ef3b9974a04ce9cde2a7a33881ddcb2d68450803745804545cdd8d258f/setuptools-72.1.0-py3-none-any.whl (2.3MB)\n",
      "\u001b[K     |████████████████████████████████| 2.3MB 43.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cloudpickle!=2.1.0,!=2.2.0,<=2.2.1,>=1.6.0; python_version < \"3.11\"\n",
      "  Downloading https://files.pythonhosted.org/packages/15/80/44286939ca215e88fa827b2aeb6fa3fd2b4a7af322485c7170d6f9fd96e0/cloudpickle-2.2.1-py3-none-any.whl\n",
      "Collecting pyyaml\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/39/472f2554a0f1e825bd7c5afc11c817cd7a2f3657460f7159f691fbb37c51/PyYAML-6.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (738kB)\n",
      "\u001b[K     |████████████████████████████████| 747kB 42.5MB/s eta 0:00:01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25hCollecting wheel\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/cd/d7460c9a869b16c3dd4e1e403cce337df165368c71d6af229a74699622ce/wheel-0.43.0-py3-none-any.whl (65kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 21.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting mosaic-utils\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/09/d7/8424b1dcaa5b1a2f824fc440aa1c4ef45e0bf6593d11b37962311614f365/mosaic_utils-1.0.2-py2.py3-none-any.whl (70kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 14.1MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting shutils==0.1.0\n",
      "  Downloading https://files.pythonhosted.org/packages/46/1d/8c6017828045c2d510e2d1d480b563936be7755c97cff660afed947928b6/shutils-0.1.0.tar.gz\n",
      "Collecting requests-toolbelt==1.0.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/51/d4db610ef29373b879047326cbf6fa98b6c1969d6f6dc423279de2b1be2c/requests_toolbelt-1.0.0-py2.py3-none-any.whl (54kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 18.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tzdata>=2022.7\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/65/58/f9c9e6be752e9fcb8b6a0ee9fb87e6e7a1f6bcab2cdc73f02bb7ba91ada0/tzdata-2024.1-py2.py3-none-any.whl (345kB)\n",
      "\u001b[K     |████████████████████████████████| 348kB 41.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cycler>=0.10\n",
      "  Downloading https://files.pythonhosted.org/packages/e7/05/c19819d5e3d95294a6f5947fb9b9629efb316b96de511b418c53d245aae6/cycler-0.12.1-py3-none-any.whl\n",
      "Collecting contourpy>=1.0.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/31/a2/2f12e3a6e45935ff694654b710961b03310b0e1ec997ee9f416d3c873f87/contourpy-1.2.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (304kB)\n",
      "\u001b[K     |████████████████████████████████| 307kB 45.7MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting importlib-resources>=3.2.0; python_version < \"3.10\"\n",
      "  Downloading https://files.pythonhosted.org/packages/75/06/4df55e1b7b112d183f65db9503bff189e97179b256e1ea450a3c365241e0/importlib_resources-6.4.0-py3-none-any.whl\n",
      "Collecting kiwisolver>=1.3.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c0/a8/841594f11d0b88d8aeb26991bc4dac38baa909dc58d0c4262a4f7893bcbf/kiwisolver-1.4.5-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6MB 50.0MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting fonttools>=4.22.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7b/30/ad4483dfc5a1999f26b7bc5edc311576f433a3e00dd8aea01f2099c3a29f/fonttools-4.53.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6MB)\n",
      "\u001b[K     |████████████████████████████████| 4.6MB 49.3MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pillow>=8\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/3f/c02268d0c6fb6b3958bdda673c17b315c821d97df29ae6969f20fb49388a/pillow-10.4.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4MB)\n",
      "\u001b[K     |████████████████████████████████| 4.4MB 45.1MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyparsing>=2.3.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/ea/6d76df31432a0e6fdf81681a895f009a4bb47b3c39036db3e1b528191d52/pyparsing-3.1.2-py3-none-any.whl (103kB)\n",
      "\u001b[K     |████████████████████████████████| 112kB 65.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting joblib>=1.2.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/29/df4b9b42f2be0b623cbd5e2140cafcaa2bef0759a00b7b70104dcfe2fb51/joblib-1.4.2-py3-none-any.whl (301kB)\n",
      "\u001b[K     |████████████████████████████████| 307kB 58.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting threadpoolctl>=3.1.0\n",
      "  Downloading https://files.pythonhosted.org/packages/4b/2c/ffbf7a134b9ab11a67b0cf0726453cedd9c5043a4fe7a35d1cefa9a1bcfb/threadpoolctl-3.5.0-py3-none-any.whl\n",
      "Collecting scipy>=1.6.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/f5/d0ad1a96f80962ba65e2ce1de6a1e59edecd1f0a7b55990ed208848012e0/scipy-1.13.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6MB)\n",
      "\u001b[K     |████████████████████████████████| 38.6MB 24.9MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting six>=1.5\n",
      "  Downloading https://files.pythonhosted.org/packages/d9/5a/e7c31adbe875f2abbb91bd84cf2dc52d792b5a01506781dbcf25c91daf11/six-1.16.0-py2.py3-none-any.whl\n",
      "Collecting pycparser\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/a3/a812df4e2dd5696d1f351d58b8fe16a405b234ad2886a0dab9183fb78109/pycparser-2.22-py3-none-any.whl (117kB)\n",
      "\u001b[K     |████████████████████████████████| 122kB 45.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting configparser\n",
      "  Downloading https://files.pythonhosted.org/packages/a8/20/f4aab9a42378542295c3be2bbdab353de10eb95396f6d4a5bc7a21b00952/configparser-7.0.0-py3-none-any.whl\n",
      "Collecting pymysql\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0c/94/e4181a1f6286f545507528c78016e00065ea913276888db2262507693ce5/PyMySQL-1.1.1-py3-none-any.whl (44kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 8.6MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting zipp>=3.1.0; python_version < \"3.10\"\n",
      "  Downloading https://files.pythonhosted.org/packages/20/38/f5c473fe9b90c8debdd29ea68d5add0289f1936d6f923b6b9cc0b931194c/zipp-3.19.2-py3-none-any.whl\n",
      "Building wheels for collected packages: shutils\n",
      "  Building wheel for shutils (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for shutils: filename=shutils-0.1.0-cp39-none-any.whl size=3283 sha256=48863db6917ebe5bf79a4c77bf70e4605b61bc5e2449a61269c5c8e1ee0e2890\n",
      "  Stored in directory: /home/mosaic-ai/.cache/pip/wheels/ab/d0/0e/613976a1b51b5654859e2a82ade64329859bce431e280f2a39\n",
      "Successfully built shutils\n",
      "\u001b[31mERROR: openapi-schema-validator 0.6.2 has requirement jsonschema<5.0.0,>=4.19.1, but you'll have jsonschema 4.19.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: mosaic-ai-serving 1.0.0 has requirement Flask==2.1.1; python_version >= \"3.7\", but you'll have flask 2.2.5 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: mosaic-ai-serving 1.0.0 has requirement matplotlib==3.6.0; python_version >= \"3.8\", but you'll have matplotlib 3.9.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: mosaic-ai-client 1.0.0 has requirement matplotlib==3.1.1, but you'll have matplotlib 3.9.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: mosaic-ai-client 1.0.0 has requirement requests-toolbelt==0.9.1, but you'll have requests-toolbelt 1.0.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: jupyterlab 3.2.4 has requirement jupyter-server~=1.4, but you'll have jupyter-server 2.7.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: jsonschema-path 0.3.2 has requirement referencing<0.32.0,>=0.28.0, but you'll have referencing 0.33.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: fosforio 1.0.1 has requirement pandas==2.0.0, but you'll have pandas 2.2.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: mosaic-utils 1.0.2 has requirement scikit-learn==1.2.1; python_version >= \"3.8\", but you'll have scikit-learn 1.5.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: fosforml 1.0.1 has requirement cloudpickle==3.0.0, but you'll have cloudpickle 2.2.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: fosforml 1.0.1 has requirement urllib3==2.2.1, but you'll have urllib3 1.26.19 which is incompatible.\u001b[0m\n",
      "Installing collected packages: pytz, urllib3, idna, charset-normalizer, certifi, requests, pycparser, cffi, cryptography, platformdirs, asn1crypto, packaging, sortedcontainers, pyOpenSSL, filelock, typing-extensions, tomlkit, pyjwt, tzdata, six, python-dateutil, numpy, pandas, pyarrow, snowflake-connector-python, setuptools, cloudpickle, pyyaml, wheel, snowflake-snowpark-python, fosforio, joblib, threadpoolctl, scipy, scikit-learn, mosaic-utils, configparser, pymysql, shutils, requests-toolbelt, fosforml, cycler, contourpy, zipp, importlib-resources, kiwisolver, fonttools, pillow, pyparsing, matplotlib, xgboost\n",
      "Successfully installed asn1crypto-1.5.1 certifi-2024.7.4 cffi-1.16.0 charset-normalizer-3.3.2 cloudpickle-2.2.1 configparser-7.0.0 contourpy-1.2.1 cryptography-42.0.8 cycler-0.12.1 filelock-3.15.4 fonttools-4.53.1 fosforio-1.0.1 fosforml-1.0.1 idna-3.7 importlib-resources-6.4.0 joblib-1.4.2 kiwisolver-1.4.5 matplotlib-3.9.1 mosaic-utils-1.0.2 numpy-1.26.4 packaging-24.1 pandas-2.2.2 pillow-10.4.0 platformdirs-4.2.2 pyOpenSSL-24.2.1 pyarrow-17.0.0 pycparser-2.22 pyjwt-2.8.0 pymysql-1.1.1 pyparsing-3.1.2 python-dateutil-2.9.0.post0 pytz-2024.1 pyyaml-6.0.1 requests-2.32.3 requests-toolbelt-1.0.0 scikit-learn-1.5.1 scipy-1.13.1 setuptools-72.1.0 shutils-0.1.0 six-1.16.0 snowflake-connector-python-3.12.0 snowflake-snowpark-python-1.20.0 sortedcontainers-2.4.0 threadpoolctl-3.5.0 tomlkit-0.13.0 typing-extensions-4.12.2 tzdata-2024.1 urllib3-1.26.19 wheel-0.43.0 xgboost-2.1.1 zipp-3.19.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 24.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting tqdm\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/eb/fdb7eb9e48b7b02554e1664afd3bd3f117f6b6d6c5881438a0b055554f9b/tqdm-4.66.4-py3-none-any.whl (78kB)\n",
      "\u001b[K     |████████████████████████████████| 81kB 4.6MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: tqdm\n",
      "Successfully installed tqdm-4.66.4\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/bin already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 24.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Uninstalling urllib3-1.26.19:\n",
      "  Successfully uninstalled urllib3-1.26.19\n",
      "Collecting urllib3==1.26.15\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7b/f5/890a0baca17a61c1f92f72b81d3c31523c99bec609e60c292ea55b387ae8/urllib3-1.26.15-py2.py3-none-any.whl (140kB)\n",
      "\u001b[K     |████████████████████████████████| 143kB 4.9MB/s eta 0:00:01\n",
      "\u001b[31mERROR: fosforml 1.0.1 has requirement cloudpickle==3.0.0, but you'll have cloudpickle 2.2.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: fosforml 1.0.1 has requirement urllib3==2.2.1, but you'll have urllib3 1.26.15 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: mosaic-ai-client 1.0.0 has requirement matplotlib==3.1.1, but you'll have matplotlib 3.9.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: mosaic-ai-client 1.0.0 has requirement requests-toolbelt==0.9.1, but you'll have requests-toolbelt 1.0.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: jsonschema-path 0.3.2 has requirement referencing<0.32.0,>=0.28.0, but you'll have referencing 0.33.0 which is incompatible.\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: urllib3\n",
      "Successfully installed urllib3-1.26.15\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 24.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting seaborn\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/83/11/00d3c3dfc25ad54e731d91449895a79e4bf2384dc3ac01809010ba88f6d5/seaborn-0.13.2-py3-none-any.whl (294kB)\n",
      "\u001b[K     |████████████████████████████████| 296kB 4.3MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numpy!=1.24.0,>=1.20\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b1/e3/24d289c5a3255bf52824bd52295e9a7923cad8ae5ec29539fc971e1122f6/numpy-2.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.5MB)\n",
      "\u001b[K     |████████████████████████████████| 19.5MB 56.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pandas>=1.2\n",
      "  Using cached https://files.pythonhosted.org/packages/bb/30/f6f1f1ac36250f50c421b1b6af08c35e5a8b5a84385ef928625336b93e6f/pandas-2.2.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Collecting matplotlib!=3.6.1,>=3.4\n",
      "  Using cached https://files.pythonhosted.org/packages/8e/67/e75134cb83d2e533e46d72e2033a413772efdc18291beb981f5d574a829f/matplotlib-3.9.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Collecting tzdata>=2022.7\n",
      "  Using cached https://files.pythonhosted.org/packages/65/58/f9c9e6be752e9fcb8b6a0ee9fb87e6e7a1f6bcab2cdc73f02bb7ba91ada0/tzdata-2024.1-py2.py3-none-any.whl\n",
      "Collecting python-dateutil>=2.8.2\n",
      "  Using cached https://files.pythonhosted.org/packages/ec/57/56b9bcc3c9c6a792fcbaf139543cee77261f3651ca9da0c93f5c1221264b/python_dateutil-2.9.0.post0-py2.py3-none-any.whl\n",
      "Collecting pytz>=2020.1\n",
      "  Using cached https://files.pythonhosted.org/packages/9c/3d/a121f284241f08268b21359bd425f7d4825cffc5ac5cd0e1b3d82ffd2b10/pytz-2024.1-py2.py3-none-any.whl\n",
      "Collecting pyparsing>=2.3.1\n",
      "  Using cached https://files.pythonhosted.org/packages/9d/ea/6d76df31432a0e6fdf81681a895f009a4bb47b3c39036db3e1b528191d52/pyparsing-3.1.2-py3-none-any.whl\n",
      "Collecting contourpy>=1.0.1\n",
      "  Using cached https://files.pythonhosted.org/packages/31/a2/2f12e3a6e45935ff694654b710961b03310b0e1ec997ee9f416d3c873f87/contourpy-1.2.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Collecting importlib-resources>=3.2.0; python_version < \"3.10\"\n",
      "  Using cached https://files.pythonhosted.org/packages/75/06/4df55e1b7b112d183f65db9503bff189e97179b256e1ea450a3c365241e0/importlib_resources-6.4.0-py3-none-any.whl\n",
      "Collecting cycler>=0.10\n",
      "  Using cached https://files.pythonhosted.org/packages/e7/05/c19819d5e3d95294a6f5947fb9b9629efb316b96de511b418c53d245aae6/cycler-0.12.1-py3-none-any.whl\n",
      "Collecting pillow>=8\n",
      "  Using cached https://files.pythonhosted.org/packages/32/3f/c02268d0c6fb6b3958bdda673c17b315c821d97df29ae6969f20fb49388a/pillow-10.4.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Collecting kiwisolver>=1.3.1\n",
      "  Using cached https://files.pythonhosted.org/packages/c0/a8/841594f11d0b88d8aeb26991bc4dac38baa909dc58d0c4262a4f7893bcbf/kiwisolver-1.4.5-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n",
      "Collecting packaging>=20.0\n",
      "  Using cached https://files.pythonhosted.org/packages/08/aa/cc0199a5f0ad350994d660967a8efb233fe0416e4639146c089643407ce6/packaging-24.1-py3-none-any.whl\n",
      "Collecting fonttools>=4.22.0\n",
      "  Using cached https://files.pythonhosted.org/packages/7b/30/ad4483dfc5a1999f26b7bc5edc311576f433a3e00dd8aea01f2099c3a29f/fonttools-4.53.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Collecting six>=1.5\n",
      "  Using cached https://files.pythonhosted.org/packages/d9/5a/e7c31adbe875f2abbb91bd84cf2dc52d792b5a01506781dbcf25c91daf11/six-1.16.0-py2.py3-none-any.whl\n",
      "Collecting zipp>=3.1.0; python_version < \"3.10\"\n",
      "  Using cached https://files.pythonhosted.org/packages/20/38/f5c473fe9b90c8debdd29ea68d5add0289f1936d6f923b6b9cc0b931194c/zipp-3.19.2-py3-none-any.whl\n",
      "\u001b[31mERROR: mosaic-utils 1.0.2 has requirement scikit-learn==1.2.1; python_version >= \"3.8\", but you'll have scikit-learn 1.5.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: fosforml 1.0.1 has requirement cloudpickle==3.0.0, but you'll have cloudpickle 2.2.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: fosforml 1.0.1 has requirement numpy==1.26.4; python_version > \"3.8\", but you'll have numpy 2.0.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: fosforml 1.0.1 has requirement urllib3==2.2.1, but you'll have urllib3 1.26.15 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: fosforio 1.0.1 has requirement pandas==2.0.0, but you'll have pandas 2.2.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: openapi-schema-validator 0.6.2 has requirement jsonschema<5.0.0,>=4.19.1, but you'll have jsonschema 4.19.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: numba 0.58.1 has requirement numpy<1.27,>=1.22, but you'll have numpy 2.0.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: mosaic-ai-serving 1.0.0 has requirement Flask==2.1.1; python_version >= \"3.7\", but you'll have flask 2.2.5 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: mosaic-ai-serving 1.0.0 has requirement matplotlib==3.6.0; python_version >= \"3.8\", but you'll have matplotlib 3.9.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: mosaic-ai-client 1.0.0 has requirement matplotlib==3.1.1, but you'll have matplotlib 3.9.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: mosaic-ai-client 1.0.0 has requirement requests-toolbelt==0.9.1, but you'll have requests-toolbelt 1.0.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: jupyterlab 3.2.4 has requirement jupyter-server~=1.4, but you'll have jupyter-server 2.7.3 which is incompatible.\u001b[0m\n",
      "Installing collected packages: numpy, tzdata, six, python-dateutil, pytz, pandas, pyparsing, contourpy, zipp, importlib-resources, cycler, pillow, kiwisolver, packaging, fonttools, matplotlib, seaborn\n",
      "Successfully installed contourpy-1.2.1 cycler-0.12.1 fonttools-4.53.1 importlib-resources-6.4.0 kiwisolver-1.4.5 matplotlib-3.9.1 numpy-2.0.1 packaging-24.1 pandas-2.2.2 pillow-10.4.0 pyparsing-3.1.2 python-dateutil-2.9.0.post0 pytz-2024.1 seaborn-0.13.2 six-1.16.0 tzdata-2024.1 zipp-3.19.2\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/numpy.libs already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/numpy already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/tzdata already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/tzdata-2024.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/six.py already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/six-1.16.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/__pycache__ already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/dateutil already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/python_dateutil-2.9.0.post0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/pytz already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/pytz-2024.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/pandas already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/pandas-2.2.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/pyparsing already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/pyparsing-3.1.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/contourpy already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/contourpy-1.2.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/zipp already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/zipp-3.19.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/importlib_resources already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/importlib_resources-6.4.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/cycler already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/cycler-0.12.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/pillow.libs already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/PIL already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/pillow-10.4.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/kiwisolver-1.4.5.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/kiwisolver already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/packaging already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/packaging-24.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/fontTools already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/fonttools-4.53.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/pylab.py already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/matplotlib already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/matplotlib-3.9.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/mpl_toolkits already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/bin already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/share already exists. Specify --upgrade to force replacement.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 24.2 is available.\r\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "# Installing packages set for without init script\n",
    "# !pip install --upgrade pip\n",
    "\n",
    "!pip install \"snowflake-connector-python[pandas]\" \"snowflake-snowpark-python[pandas]\" snowflake-snowpark-python==1.9.0 fosforio==1.0.1 fosforml==1.0.1 numpy==1.26.4 pandas==2.2.2 matplotlib scikit-learn==1.5.1 xgboost python-dateutil \n",
    "!pip install tqdm \n",
    "# !pip install --upgrade --q snowflake-snowpark-python==1.9.0\n",
    "!pip uninstall urllib3 -y\n",
    "!pip install urllib3==1.26.15\n",
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72de8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip freeze"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06a4ab2",
   "metadata": {},
   "source": [
    "# Restart and clear outputs\n",
    "\n",
    "# Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf7fe85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fosforio import snowflake\n",
    "from fosforml import *\n",
    "from fosforml.constants import MLModelFlavours\n",
    "from fosforio import get_dataframe\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "pd.set_option('display.max_columns', 500)\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "from joblib import dump, load\n",
    "import requests\n",
    "#from tqdm import tqdm\n",
    "import time\n",
    "import calendar\n",
    "import configparser\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import datetime\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from time import sleep\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from dateutil.easter import easter\n",
    "from scipy.optimize import minimize_scalar\n",
    "from scipy.optimize import curve_fit\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5999d5f2",
   "metadata": {},
   "source": [
    "# Importing data from snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e536f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from fosforio import snowflake\n",
    "#from fosforio import get_dataframe\n",
    "# snowflake.get_connection(connection_name=\"ME_AD_SALES_CXN\")\n",
    "#df = get_dataframe(\"AD_SALES_IMP\")\n",
    "# df_all = get_dataframe(\"AD_TECH_INPUT\")\n",
    "df_all = pd.read_csv(\"./ad_tech_input.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb41bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df_all.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9d379d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f59857",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d633377b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.columns = df.columns.str.lower()\n",
    "df_all.columns = df_all.columns.str.lower()\n",
    "#df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3758d0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2db2869-09aa-4132-8972-a3cc74bb0263",
   "metadata": {},
   "source": [
    "# Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158fc2cd-8e2e-4e27-b288-87a549556779",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_col=['ad_date', 'site_id','advertiser_id', 'order_id','ad_type', 'ad_format', 'ad_media_type',\n",
    "         'device_type', 'city', 'line_item_group', 'line_item_type', 'monetization_channel','os_type']\n",
    "scat_col = ['site_id','ad_type', 'ad_format', 'device_type', 'advertiser_id',\n",
    "            'line_item_group', 'line_item_type', 'os_type','monetization_channel']\n",
    "num_col=list(df_all.select_dtypes(np.number).columns)\n",
    "\n",
    "import seaborn as sns\n",
    "sns.heatmap(df_all.isnull(),cbar=False,cbar_kws={'color':'r'})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "34d3e90d",
   "metadata": {},
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(df_all.isnull(),cbar=False,cbar_kws={'color':'r'})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00e0244-4680-44bf-9dfb-a67f5f61eff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(4,2, figsize=(14,12))\n",
    "axes_ = [axes_row for axes in ax for axes_row in axes]\n",
    "\n",
    "for i,col in enumerate(scat_col):\n",
    "    sns.countplot(data=df_all,x=col,ax=axes_[i])\n",
    "    if col=='advertiser_id':\n",
    "        plt.xticks(rotation=90)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f37132-8305-4793-8c92-f8828d07970d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in num_col:\n",
    "    if i!='total_revenue':\n",
    "        sns.scatterplot(data=df_all,x=i,y='total_revenue')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb091da-8e4e-46a6-b24f-af4eb795f0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f266fcc2-2b3b-47a2-9dcb-cf2c2efb53de",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in (scat_col):\n",
    "    title='Relationship of '+col+' with total_revenue'\n",
    "    plt.figure(figsize=(6,4))\n",
    "    sns.barplot(y=df_all['total_revenue'],x=df_all[col])\n",
    "    if col=='advertiser_id':\n",
    "        plt.xticks(rotation=90)\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c88c3cf-8b3f-490d-8cdd-abef798c12dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in (scat_col):\n",
    "    title='Relationship of '+ col +' with total_impressions'\n",
    "    plt.figure(figsize=(6,4))\n",
    "    sns.barplot(y=df_all['total_impressions'],x=df_all[col],)\n",
    "    if col=='advertiser_id':\n",
    "        plt.xticks(rotation=90)\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a867e33c-830f-4478-89f8-10dc9e3c7c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cat_col:\n",
    "    df_all[i]=df_all[i].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8f14dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f35e75-ff39-485a-a87d-f01ff77b4399",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.drop(['ad_unit_id','revenue_share_percent','ad_type_id','site_id','advertiser_id',\n",
    "        'ad_date','geo_id','order_id', 'ad_type', 'ad_format', 'ad_media_type', 'line_item_group',\n",
    "            'city', 'city_code'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71b2543",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4698ba70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.drop(['device_category_id', 'line_item_type_id', 'os_id',\n",
    "       'monetization_channel_id','population', 'city_lat', 'city_lon'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963034fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.select_dtypes(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006f89ae-6bbc-4d63-8624-3f37c9c04fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df_all.select_dtypes(object).columns:\n",
    "    pd.crosstab(df_all['monetization_channel'],df_all[i]).plot(kind='bar')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab7196b",
   "metadata": {},
   "source": [
    "# Predictive Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12453c4-15b8-4d77-8d7d-b4a8aa2162db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4df5c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9147704-4046-457d-8ca2-c7235c0c0051",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xd = df_all.drop('total_revenue',axis=1)\n",
    "y = df_all['total_revenue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b3694b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xd.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a446e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d15e0b2-fc4c-4df7-93dc-ae3d829a5d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = pd.get_dummies(Xd,drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a35cbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86301728-34bc-4f81-8f38-9b73a6e5e206",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import StandardScaler\n",
    "#ss = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0caeacf-bba9-47e3-b386-ebd2c62d4f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X[pc_col] = pd.DataFrame(ss.fit_transform(X[pc_col]),columns=[pc_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a361d941-0784-4adc-aed8-69adba480dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(Xd,y,test_size=0.2,random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f62ad3-0adc-418b-8d21-e558d18a7a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_col = ['total_impressions', 'viewable_impressions', 'measurable_impressions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a39c2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline(steps=[\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('pca', PCA(n_components=2))\n",
    "        ]), pc_col),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), ['device_type', 'line_item_type', 'os_type',\n",
    "       'monetization_channel'])\n",
    "    ])\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3c3b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "\n",
    "    {\n",
    "        'name': 'RandomForestRegressor',\n",
    "        'regressor': [RandomForestRegressor()],\n",
    "        'regressor__n_estimators': [50],\n",
    "        'regressor__max_depth': [10],\n",
    "        'regressor__min_samples_split': [2],\n",
    "        'regressor__min_samples_leaf': [1],\n",
    "        'regressor__bootstrap': [True]\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb07eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline = Pipeline(steps=[\n",
    "#    ('preprocessor', preprocessor),\n",
    "#    ('regressor', LinearRegression())  # Placeholder\n",
    "#])\n",
    "\n",
    "best_estimators = []\n",
    "for model_params in models:\n",
    "    model_name = model_params.pop('name')  # Extract the model name\n",
    "    grid_search = GridSearchCV(pipeline, model_params, cv=3, scoring='r2', n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_estimator = grid_search.best_estimator_\n",
    "    best_estimators.append(best_estimator)\n",
    "    print(f\"Training completed for model {model_name}\")\n",
    "    \n",
    "    # Save the best model\n",
    "    joblib.dump(best_estimator, f'best_model_{model_name}.pkl')\n",
    "    print(f\"Best model {model_name} saved to best_model_{model_name}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7411d987",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d95ccda",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for estimator in best_estimators:\n",
    "    y_pred_train = estimator.predict(X_train)\n",
    "    y_pred_test = estimator.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred_test)\n",
    "    r2 = r2_score(y_test, y_pred_test)\n",
    "    results.append({\n",
    "        'model': estimator.named_steps['regressor'].__class__.__name__,\n",
    "        'best_params': estimator.named_steps['regressor'].get_params(),\n",
    "        'mse': mse,\n",
    "        'r2': r2\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7391ab90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['predicted_revenue'] = best_estimator.predict(Xd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59701539",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy['predicted_revenue'] = best_estimator.predict(Xd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00dadc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17063d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c786b737",
   "metadata": {},
   "source": [
    "# In this section we are joining multiple tables, realigning indexes to get the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ded1557",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check type of data (series/ array/ dataframe)\n",
    "\n",
    "type(Xd), type(X_train), type(X_test), type(y), type(y_train), type(y_test), type(results), type(y_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca293e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62a676a",
   "metadata": {},
   "source": [
    "# Creating Data frames as necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32c7977",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df= pd.DataFrame(y)\n",
    "y_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687b267c-3d9a-4dfe-b133-f57d9a7c18d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_df= pd.DataFrame(y_train)\n",
    "y_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f5446b-9b87-4bdc-9221-ab78e778b0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_df= pd.DataFrame(y_test)\n",
    "y_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa94720",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list_temp = y_train_df.index.values.tolist()\n",
    "min(index_list_temp), max(index_list_temp), len(index_list_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f287897",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list_temp = y_test_df.index.values.tolist()\n",
    "min(index_list_temp), max(index_list_temp), len(index_list_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fd6e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fc0ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check type of data (series/ array/ dataframe)\n",
    "\n",
    "type(X_train), type(X_test), type(y_train_df), type(y_test_df), type(y_pred_train), type(y_pred_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa1fd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0f10db",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_df = pd.DataFrame(y_pred_train, columns=['predicted_revenue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcbf005",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e8f093",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_df = pd.DataFrame(y_pred_test,columns=['predicted_revenue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbcc5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_df.reset_index(drop = True)\n",
    "y_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba05dcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining Actuals and predicted Y columns\n",
    "\n",
    "y_train_final= pd.concat([y_train_df, y_train_pred_df.set_index(y_train_df.index)], axis=1)\n",
    "y_train_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9f7c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_final= pd.concat([y_test_df, y_test_pred_df.set_index(y_test_df.index)], axis=1)\n",
    "y_test_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b72733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining Train and test Y columns\n",
    "\n",
    "y_all = pd.concat([y_train_final, y_test_final])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e9f598",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832f863b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_compare = pd.merge(y_df, y_all, left_index=True, right_index=True)\n",
    "y_compare.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd061042",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_compare[y_compare['total_revenue_x']!=y_compare['total_revenue_y']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062ec433",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_all = y_all.sort_index(axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183fdd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_all.sort_index(axis=0, inplace = True)\n",
    "y_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469aee3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf11e052",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4246596",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5b941a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_all.sort_index(axis=0)\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f0d593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining x and y columns with all details\n",
    "\n",
    "model_output = pd.merge(df_final, y_all, left_index=True, right_index=True)\n",
    "#model_output = pd.concat([df_all, y_all], axis = 1)\n",
    "#model_output = df_all.join(y_all)\n",
    "model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27330f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check\n",
    "\n",
    "print(model_output['predicted_revenue_x'].sum())\n",
    "print(model_output['total_revenue_x'].sum())\n",
    "print(model_output['total_revenue_y'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f760ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_output.columns\n",
    "# fixing column names of revenue which comes in input as well as output data\n",
    "\n",
    "model_output.columns = ['ad_date', 'site_id', 'ad_type_id', 'geo_id', 'device_category_id',\n",
    "       'advertiser_id', 'order_id', 'line_item_type_id', 'os_id',\n",
    "       'monetization_channel_id', 'ad_unit_id', 'total_impressions', 'total_revenue',\n",
    "       'viewable_impressions', 'measurable_impressions',\n",
    "       'revenue_share_percent', 'ad_type', 'ad_format', 'ad_media_type',\n",
    "       'device_type', 'city', 'city_code', 'population', 'city_lat',\n",
    "       'city_lon', 'line_item_group', 'line_item_type', 'monetization_channel',\n",
    "       'os_type', 'total_revenue2', 'predicted_revenue']\n",
    "model_output.info()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "978febe5",
   "metadata": {},
   "source": [
    "# fixing column names of revenue which comes in input as well as output data\n",
    "\n",
    "model_output.columns = ['ad_date', 'site_id', 'ad_type_id', 'geo_id', 'device_category_id',\n",
    "       'advertiser_id', 'order_id', 'line_item_type_id', 'os_id',\n",
    "       'monetization_channel_id', 'ad_unit_id', 'total_impressions', 'total_revenue',\n",
    "       'viewable_impressions', 'measurable_impressions',\n",
    "       'revenue_share_percent', 'ad_type', 'ad_format', 'ad_media_type',\n",
    "       'device_type', 'city', 'city_code', 'population', 'city_lat',\n",
    "       'city_lon', 'line_item_group', 'line_item_type', 'monetization_channel',\n",
    "       'os_type', 'total_revenue2', 'predicted_revenue']\n",
    "model_output.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b7f5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output[model_output['total_revenue_x']!=model_output['total_revenue_y']].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb6010a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if both the columns actually have same values\n",
    "\n",
    "#model_output['total_revenue'].equals(model_output['total_revenue2']) \n",
    "model_output['total_revenue_x'].equals(model_output['total_revenue_y']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515b17b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output['check'] = model_output.apply(lambda x: x['total_revenue_x'] if x['total_revenue_x'] <\n",
    "                     x['total_revenue_y'] else np.nan, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dc7a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output['check'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4501ef",
   "metadata": {},
   "source": [
    "# Pushing Model output to Snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc1f342",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from snowflake.snowpark.session import Session\n",
    "user = os.getenv(\"user\")\n",
    "warehouse = os.getenv(\"warehouse\")\n",
    "schema= os.getenv(\"schema\")\n",
    "database = os.getenv(\"database\")\n",
    "role =  os.getenv(\"role\")\n",
    "account =  os.getenv(\"account\")\n",
    "password= os.getenv(\"password\")\n",
    "\n",
    "connection_params = dict(user=user, \n",
    "                         password=password, \n",
    "                         account=account, \n",
    "                         warehouse=warehouse, \n",
    "                         database=database,\n",
    "                         schema=schema, \n",
    "                         role=role)\n",
    "\n",
    "session = Session.builder.configs(connection_params).create()\n",
    "\n",
    "session.sql('use warehouse {};'.format(warehouse)).collect()\n",
    "\n",
    "session.sql('use database {};'.format(database)).collect()\n",
    "\n",
    "session.sql('use schema {}.{};'.format(database, schema)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731f951b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_snowflake = session.createDataFrame(df_all.values.tolist(),\n",
    "        schema = df_all.columns.tolist())\n",
    "\n",
    "df_snowflake.write.mode(\"overwrite\").save_as_table(\"ME_DB.ME_AD_SALES_SCHEMA.AD_TECH_OUTPUT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f999a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245f5ae1",
   "metadata": {},
   "source": [
    "# Model Registrartion using fosforml SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19b3564",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Snowpark lib\n",
    "from snowflake.snowpark import Session\n",
    "\n",
    "# Data Science Libs\n",
    "#import numpy as np\n",
    "#import pandas as pd\n",
    "\n",
    "# create_temp_table warning suppresion\n",
    "#import warnings; warnings.simplefilter('ignore')\n",
    "\n",
    "#ConfigParser to read ini file\n",
    "# import configparser\n",
    "#!pip install fosforml\n",
    "from fosforio import snowflake\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60650415",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688c4ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fosforml import *\n",
    "from fosforml.constants import MLModelFlavours\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7c13c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@scoring_func\n",
    "def score(model, request):\n",
    "\n",
    "    import json\n",
    "    payload = request.json[\"payload\"]\n",
    "    if isinstance(request.json[\"payload\"],str):\n",
    "        payload_data = eval(payload)\n",
    "        if isinstance(payload_data['total_impressions'], int):\n",
    "                data_json = eval(payload)\n",
    "                data = pd.DataFrame([data_json])\n",
    "                prediction = pd.DataFrame(model.predict(data))\n",
    "                return prediction[0].to_list()[0]\n",
    "        elif isinstance(payload_data['total_impressions'], dict):\n",
    "                data = pd.DataFrame(eval(payload))\n",
    "                prediction = pd.DataFrame(model.predict(data))\n",
    "                return prediction[0].tolist()\n",
    "        elif isinstance(payload_data['total_impressions'], list):\n",
    "                data = pd.DataFrame(payload_data)\n",
    "                prediction = pd.DataFrame(model.predict(data))\n",
    "                return prediction.tolist()\n",
    "    return \"This method is not allowed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e082e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "payload = str(X_test.iloc[1:3].to_dict())\n",
    "req = requests.Request()\n",
    "req.json = {\"payload\": payload}\n",
    "print(score(best_estimator, req))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2ec1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee733fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "payload = str(X_test.iloc[1].to_dict())\n",
    "req = requests.Request()\n",
    "req.json = {\"payload\": payload}\n",
    "print(score(best_estimator, req))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42572f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64668451",
   "metadata": {},
   "source": [
    "# Sample Payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b293079",
   "metadata": {},
   "outputs": [],
   "source": [
    "req.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c03957",
   "metadata": {},
   "outputs": [],
   "source": [
    "yo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf5f4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## registering the model in Fosfor.\n",
    "register_model(best_estimator,\n",
    "               score, \n",
    "               name=\"Ad_Sales_Prediction_Model_3_9\", \n",
    "               description=\"Ad_Sales_Prediction_RandomForest_Model_3_9\",\n",
    "               flavour=MLModelFlavours.sklearn,\n",
    "               model_type=\"regression\",\n",
    "#                init_script=\"\\\\n pip install fosforml==1.0.1 \\\\n pip install fosforio[snowflake] \\\\n pip install sklearn\\\\n pip install snowflake-connector-python[pandas]\",\n",
    "               init_script=\"\\\\n pip install scikit-learn==1.5.1 --no-deps\\\\n pip install joblib==1.4.2\\\\n pip install scipy==1.13.1\\\\n pip install threadpoolctl==3.5.0\\\\n pip install fosforml==1.0.1\\\\n pip install fosforio==1.0.1 --no-deps\\\\n pip install holidays==0.9.9\\\\n pip install pandas==2.2.2 --no-deps\\\\n pip install holidays==0.9.9\\\\n pip install python-dateutil==2.9.0\\\\n pip install pytz==2024.1\\\\n pip install six==1.16.0\\\\n pip install tzdata==2024.1\\\\n pip install numpy==1.26.4\",\n",
    "               y_true=y_test,\n",
    "               y_pred=y_pred_test,\n",
    "               #prob=y_prob,\n",
    "               features=X_train.columns,\n",
    "               input_type=\"json\", \n",
    "               explain_ai=True,\n",
    "               x_train=X_train, \n",
    "               x_test=X_test, \n",
    "               y_train=y_train,\n",
    "               y_test=y_test,\n",
    "               feature_names=X_train.columns.tolist(),\n",
    "               original_features=X_train.columns.tolist(),\n",
    "               feature_ids=X_train.columns,\n",
    "               kyd=True, kyd_score = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b12bedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b7d581",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
