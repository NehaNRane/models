{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "485bbc66",
   "metadata": {},
   "source": [
    "# Importing helper libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c858f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install \"snowflake-connector-python[pandas]\" \"snowflake-snowpark-python[pandas]\" snowflake-snowpark-python==1.9.0 fosforio fosforml numpy pandas matplotlib scikit-learn xgboost seaborn python-dateutil tqdm holidays faker\n",
    "!pip install --upgrade --q snowflake-snowpark-python==1.9.0\n",
    "!pip uninstall urllib3 -y\n",
    "!pip install urllib3==1.26.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d9dbed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aiohttp==3.9.3\n",
      "aiosignal==1.3.1\n",
      "alembic==1.13.1\n",
      "anyio==4.2.0\n",
      "archspec @ file:///croot/archspec_1697725767277/work\n",
      "argon2-cffi==23.1.0\n",
      "argon2-cffi-bindings==21.2.0\n",
      "asn1crypto==1.5.1\n",
      "asttokens==2.4.1\n",
      "async-generator==1.10\n",
      "async-timeout==4.0.3\n",
      "attrs==23.2.0\n",
      "Babel==2.14.0\n",
      "beautifulsoup4==4.12.3\n",
      "bleach==4.1.0\n",
      "boltons @ file:///croot/boltons_1677628692245/work\n",
      "bqplot==0.12.42\n",
      "Brotli @ file:///tmp/abs_ecyw11_7ze/croots/recipe/brotli-split_1659616059936/work\n",
      "certifi==2024.7.4\n",
      "certipy==0.1.3\n",
      "cffi==1.16.0\n",
      "charset-normalizer==3.3.2\n",
      "click==8.1.7\n",
      "clickclick==20.10.2\n",
      "cloudpickle==2.2.1\n",
      "comm==0.2.1\n",
      "conda @ file:///croot/conda_1701719518285/work\n",
      "conda-content-trust @ file:///tmp/abs_5952f1c8-355c-4855-ad2e-538535021ba5h26t22e5/croots/recipe/conda-content-trust_1658126371814/work\n",
      "conda-libmamba-solver @ file:///croot/conda-libmamba-solver_1702997573971/work/src\n",
      "conda-package-handling @ file:///croot/conda-package-handling_1690999929514/work\n",
      "conda_package_streaming @ file:///croot/conda-package-streaming_1690987966409/work\n",
      "configparser==7.0.0\n",
      "connexion==2.6.0\n",
      "contourpy==1.2.1\n",
      "cryptography==42.0.8\n",
      "cycler==0.12.1\n",
      "Cython==0.29.15\n",
      "decorator==5.1.1\n",
      "defusedxml==0.7.1\n",
      "dill==0.3.8\n",
      "distro @ file:///croot/distro_1701455004953/work\n",
      "ds-lime==0.1.1.27\n",
      "entrypoints==0.4\n",
      "exceptiongroup==1.2.0\n",
      "executing==2.0.1\n",
      "Faker==9.9.1\n",
      "fastjsonschema==2.19.1\n",
      "filelock==3.15.4\n",
      "flasgger==0.9.5\n",
      "Flask==2.1.1\n",
      "fonttools==4.53.1\n",
      "fosforio==1.0.2\n",
      "fosforml==1.0.0\n",
      "frozenlist==1.4.1\n",
      "greenlet==3.0.3\n",
      "gunicorn==19.9.0\n",
      "holidays==0.9.9\n",
      "idna==3.7\n",
      "importlib_metadata==8.0.0\n",
      "importlib_resources==6.4.0\n",
      "inflection==0.5.1\n",
      "ipykernel==5.5.5\n",
      "ipython==8.18.1\n",
      "ipython-genutils==0.2.0\n",
      "ipywidgets==8.0.4\n",
      "itsdangerous==2.2.0\n",
      "jedi==0.19.1\n",
      "Jinja2==3.1.4\n",
      "joblib==1.3.2\n",
      "json5==0.9.14\n",
      "jsonpatch @ file:///tmp/build/80754af9/jsonpatch_1615747632069/work\n",
      "jsonpointer==2.1\n",
      "jsonschema==4.19.0\n",
      "jsonschema-path==0.3.2\n",
      "jsonschema-specifications==2023.12.1\n",
      "jupyter-events==0.9.0\n",
      "jupyter-lsp==2.2.1\n",
      "jupyter-telemetry==0.1.0\n",
      "jupyter_client==8.6.0\n",
      "jupyter_core==5.7.1\n",
      "jupyter_server==2.7.3\n",
      "jupyter_server_proxy==4.1.0\n",
      "jupyter_server_terminals==0.5.2\n",
      "jupyterhub==1.5.0\n",
      "jupyterlab==3.2.4\n",
      "jupyterlab-widgets==3.0.9\n",
      "jupyterlab_pygments==0.3.0\n",
      "jupyterlab_server==2.25.2\n",
      "kiwisolver==1.4.5\n",
      "lazy-object-proxy==1.10.0\n",
      "libmambapy @ file:///croot/mamba-split_1704219408234/work/libmambapy\n",
      "llvmlite==0.41.1\n",
      "Mako==1.3.2\n",
      "MarkupSafe==2.1.5\n",
      "marshmallow==2.19.5\n",
      "matplotlib==3.9.1\n",
      "matplotlib-inline==0.1.6\n",
      "menuinst @ file:///croot/menuinst_1702390294373/work\n",
      "mistune==3.0.2\n",
      "mosaic-ai-client==1.0.0\n",
      "mosaic-ai-serving==1.0.0\n",
      "mosaic-common-utils==1.0.0\n",
      "mosaic-utils==1.0.2\n",
      "multidict==6.0.4\n",
      "multiprocess==0.70.16\n",
      "nbclassic==0.5.6\n",
      "nbclient==0.5.4\n",
      "nbconvert==7.14.2\n",
      "nbformat==5.9.2\n",
      "nest-asyncio==1.6.0\n",
      "notebook==6.4.10\n",
      "notebook_shim==0.2.3\n",
      "numba==0.58.1\n",
      "numpy==1.26.4\n",
      "nvidia-nccl-cu12==2.22.3\n",
      "oauthlib==3.2.2\n",
      "openapi-schema-validator==0.6.2\n",
      "openapi-spec-validator==0.7.1\n",
      "overrides==7.7.0\n",
      "packaging==24.1\n",
      "pamela==1.1.0\n",
      "pandas==1.4.1\n",
      "pandocfilters==1.5.1\n",
      "parso==0.8.3\n",
      "pathable==0.4.3\n",
      "pexpect==4.9.0\n",
      "pillow==10.4.0\n",
      "platformdirs==4.2.2\n",
      "pluggy @ file:///tmp/build/80754af9/pluggy_1648024445381/work\n",
      "prometheus-client==0.19.0\n",
      "prompt-toolkit==3.0.43\n",
      "protobuf==3.20.2\n",
      "psycopg2-binary==2.8.6\n",
      "ptyprocess==0.7.0\n",
      "pure-eval==0.2.2\n",
      "pyarrow==16.1.0\n",
      "pycosat @ file:///croot/pycosat_1696536503704/work\n",
      "pycparser==2.22\n",
      "Pygments==2.17.2\n",
      "PyJWT==2.8.0\n",
      "PyMySQL==1.1.1\n",
      "pyOpenSSL==24.1.0\n",
      "pyparsing==3.1.2\n",
      "PySocks @ file:///tmp/build/80754af9/pysocks_1605305812635/work\n",
      "python-dateutil==2.9.0\n",
      "python-dotenv==0.20.0\n",
      "python-json-logger==2.0.7\n",
      "pytz==2024.1\n",
      "PyYAML==6.0.1\n",
      "pyzmq==25.1.2\n",
      "referencing==0.33.0\n",
      "requests==2.32.3\n",
      "requests-toolbelt==1.0.0\n",
      "rfc3339-validator==0.1.4\n",
      "rfc3986-validator==0.1.1\n",
      "rpds-py==0.17.1\n",
      "ruamel.yaml==0.16.9\n",
      "ruamel.yaml.clib @ file:///croot/ruamel.yaml.clib_1666302247304/work\n",
      "scikit-learn==1.3.2\n",
      "scipy==1.13.1\n",
      "seaborn==0.9.1\n",
      "Send2Trash==1.8.2\n",
      "shap==0.44.1\n",
      "shutils==0.1.0\n",
      "simpervisor==1.0.0\n",
      "six==1.16.0\n",
      "skater==1.0.4\n",
      "slicer==0.0.7\n",
      "sniffio==1.3.0\n",
      "snowflake-connector-python==3.9.1\n",
      "snowflake-snowpark-python==1.9.0\n",
      "sortedcontainers==2.4.0\n",
      "soupsieve==2.5\n",
      "SQLAlchemy==1.3.5\n",
      "stack-data==0.6.3\n",
      "terminado==0.18.0\n",
      "text-unidecode==1.3\n",
      "threadpoolctl==3.5.0\n",
      "tinycss2==1.2.1\n",
      "tomlkit==0.13.0\n",
      "tornado==6.4\n",
      "tqdm==4.9.0\n",
      "traitlets==5.9.0\n",
      "traittypes==0.2.1\n",
      "typing_extensions==4.12.2\n",
      "tzdata==2024.1\n",
      "urllib3==2.2.1\n",
      "uWSGI @ file:///home/conda/feedstock_root/build_artifacts/uwsgi_1681743169039/work\n",
      "wcwidth==0.2.13\n",
      "webencodings==0.5.1\n",
      "websocket-client==1.7.0\n",
      "Werkzeug==3.0.3\n",
      "widgetsnbextension==4.0.9\n",
      "xgboost==2.1.0\n",
      "yarl==1.9.4\n",
      "zipp==3.19.2\n",
      "zstandard @ file:///croot/zstandard_1677013143055/work\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "!pip install fosforml==\n",
    "pip freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03dac850",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection manager service url initialised to http://fdc-project-manager:80/project-manager\n",
      "If you need to update its value then update the variable CONNECTION_MANAGER_BASE_URL in os env.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfosforio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m snowflake\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfosforml\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfosforml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstants\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MLModelFlavours\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfosforio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_dataframe\n",
      "File \u001b[0;32m/tmp/pip_packages/fosforml/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# -*- coding: utf-8 -*-\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      4\u001b[0m     add_version,\n\u001b[1;32m      5\u001b[0m     apply_model_strategy,\n\u001b[1;32m      6\u001b[0m     build_time_metrics,\n\u001b[1;32m      7\u001b[0m     delete_model,\n\u001b[1;32m      8\u001b[0m     deploy_model,\n\u001b[1;32m      9\u001b[0m     describe_model,\n\u001b[1;32m     10\u001b[0m     describe_model_using_model_name,\n\u001b[1;32m     11\u001b[0m     ensemble_model_list,\n\u001b[1;32m     12\u001b[0m     fetch_model_resources,\n\u001b[1;32m     13\u001b[0m     generate_schema,\n\u001b[1;32m     14\u001b[0m     get_model_info,\n\u001b[1;32m     15\u001b[0m     get_model_profiling,\n\u001b[1;32m     16\u001b[0m     list_models,\n\u001b[1;32m     17\u001b[0m     load_model,\n\u001b[1;32m     18\u001b[0m     load_train_and_test_data,\n\u001b[1;32m     19\u001b[0m     promote_model,\n\u001b[1;32m     20\u001b[0m     register_ensemble_model,\n\u001b[1;32m     21\u001b[0m     register_model,\n\u001b[1;32m     22\u001b[0m     stop_model,\n\u001b[1;32m     23\u001b[0m     update_existing_model,\n\u001b[1;32m     24\u001b[0m     update_metadata_info,\n\u001b[1;32m     25\u001b[0m     update_model_details,\n\u001b[1;32m     26\u001b[0m     update_version_details,\n\u001b[1;32m     27\u001b[0m     fetch_feedback_accuracy,\n\u001b[1;32m     28\u001b[0m     delete_model_version,\n\u001b[1;32m     29\u001b[0m     add_artifacts,\n\u001b[1;32m     30\u001b[0m     download_artifacts,\n\u001b[1;32m     31\u001b[0m     get_model_obj\n\u001b[1;32m     32\u001b[0m )\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfosforml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwidgets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregister_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RegisterModel\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecorators\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m scoring_func\n",
      "File \u001b[0;32m/tmp/pip_packages/fosforml/api.py:13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datetime\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmosaic_utils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbuild_time_metrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m metrics_stats\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmosaic_utils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mencoding_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m base64_encode\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmosaic_utils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfile_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     16\u001b[0m     create_model_tar,\n\u001b[1;32m     17\u001b[0m     extract_tar,\n\u001b[1;32m     18\u001b[0m     pickle_dumps,\n\u001b[1;32m     19\u001b[0m     pickle_loads,\n\u001b[1;32m     20\u001b[0m )\n",
      "File \u001b[0;32m/packages/Python-3.9/a7fcbb14-006d-40b8-a5b4-e2ee0c9146a1/3.9/mosaic_utils/ai/build_time_metrics/metrics.py:7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01myaml\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m metrics\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      9\u001b[0m     accuracy_score,\n\u001b[1;32m     10\u001b[0m     average_precision_score,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m     roc_auc_score,\n\u001b[1;32m     27\u001b[0m )\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     30\u001b[0m     get_headers,\n\u001b[1;32m     31\u001b[0m     get_model_type_handler,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     35\u001b[0m     update_progress,\n\u001b[1;32m     36\u001b[0m )\n",
      "File \u001b[0;32m/packages/Python-3.9/a7fcbb14-006d-40b8-a5b4-e2ee0c9146a1/3.9/sklearn/__init__.py:83\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# We are not importing the rest of scikit-learn during the build\u001b[39;00m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;66;03m# process, as it may not be compiled yet\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;66;03m# later is linked to the OpenMP runtime to make it possible to introspect\u001b[39;00m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;66;03m# it and importing it first would fail if the OpenMP dll cannot be found.\u001b[39;00m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     80\u001b[0m         __check_build,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     81\u001b[0m         _distributor_init,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     82\u001b[0m     )\n\u001b[0;32m---> 83\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clone\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_show_versions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m show_versions\n\u001b[1;32m     86\u001b[0m     __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     87\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcalibration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     88\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshow_versions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    130\u001b[0m     ]\n",
      "File \u001b[0;32m/packages/Python-3.9/a7fcbb14-006d-40b8-a5b4-e2ee0c9146a1/3.9/sklearn/base.py:19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config_context, get_config\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InconsistentVersionWarning\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _IS_32BIT\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_estimator_html_repr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m estimator_html_repr\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_metadata_requests\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _MetadataRequester\n",
      "File \u001b[0;32m/packages/Python-3.9/a7fcbb14-006d-40b8-a5b4-e2ee0c9146a1/3.9/sklearn/utils/__init__.py:27\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdiscovery\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m all_estimators\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfixes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parse_version, threadpool_info\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmurmurhash\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m murmurhash3_32\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     29\u001b[0m     _is_arraylike_not_scalar,\n\u001b[1;32m     30\u001b[0m     as_float_array,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     39\u001b[0m     indexable,\n\u001b[1;32m     40\u001b[0m )\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Do not deprecate parallel_backend and register_parallel_backend as they are\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# needed to tune `scikit-learn` behavior and have different effect if called\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# from the vendored version or or the site-package version. The other are\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# utilities that are independent of scikit-learn so they are not part of\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# scikit-learn public API.\u001b[39;00m\n",
      "File \u001b[0;32msklearn/utils/murmurhash.pyx:1\u001b[0m, in \u001b[0;36minit sklearn.utils.murmurhash\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "from fosforio import snowflake\n",
    "from fosforml import *\n",
    "from fosforml.constants import MLModelFlavours\n",
    "from fosforio import get_dataframe\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "import numpy as np\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "from joblib import dump, load\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import calendar\n",
    "\n",
    "from time import sleep\n",
    "import configparser\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import datetime\n",
    "from dateutil.easter import easter\n",
    "from scipy.optimize import minimize_scalar\n",
    "from scipy.optimize import curve_fit\n",
    "import holidays, itertools\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28f4004",
   "metadata": {},
   "source": [
    "# Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b5a014",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./bookings_transformed_latest.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75255b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "\n",
    "# Define the demand curve function\n",
    "def demand_curve(x, a, b, c, d, max_demand):\n",
    "    demand = a * np.exp(-b * x) + c\n",
    "    demand = np.where(x <= max_demand, np.minimum(demand, max_demand), demand)\n",
    "    return demand + d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046d8280",
   "metadata": {},
   "outputs": [],
   "source": [
    "def revenue(price):\n",
    "    return price * demand_curve(price, a_fit, b_fit,c_fit,d_fit,max_demand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928f97a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import brentq\n",
    "\n",
    "def demand_to_price(num_rooms, a, b, c, d, max_demand):\n",
    "    def root_func(x):\n",
    "        return num_rooms - (a * np.exp(-b * x) + c)\n",
    "\n",
    "    try:\n",
    "        price = brentq(root_func, 0, 200)  # Adjust the interval bounds as needed\n",
    "    except ValueError:\n",
    "        # Fallback to default price if no root is found\n",
    "        price_range=(0, 200)\n",
    "        price = np.random.uniform(*price_range)\n",
    "\n",
    "    return price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b44e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_holiday_dates(start_year, end_year):\n",
    "    holidays = {}\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        holidays[datetime.date(year, 1, 1)] = 'new_year'\n",
    "        easter_date = easter(year)\n",
    "        holidays[easter_date] = 'easter'\n",
    "        holidays[datetime.date(year, 12, 25)] = 'christmas'\n",
    "    return holidays\n",
    "\n",
    "holidays = generate_holiday_dates(2020, 2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f830a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_conversion(data):\n",
    "    import holidays\n",
    "    hotels = data['hotel'].unique()\n",
    "    room_types = data['reserved_room_type'].unique()\n",
    "    expanded_df = pd.DataFrame()\n",
    "    for _, row in data.iterrows():\n",
    "        num_stay_dates = row['total_rns']\n",
    "        try:\n",
    "            # Create a row for each stay date\n",
    "            expanded_booking = pd.DataFrame({\n",
    "                'hotel': row['hotel'],\n",
    "                'room_type': row['reserved_room_type'], \n",
    "                'arrival_date': pd.date_range(start=row['expected_arrival_date'], periods=num_stay_dates),\n",
    "                'total_rns': 1,\n",
    "                'adr': row['adr'],\n",
    "                'room_limit': row['room_limit']\n",
    "            })\n",
    "\n",
    "            # Append the stay date information to the new dataframe\n",
    "            expanded_df = pd.concat([expanded_df, expanded_booking], ignore_index=True)\n",
    "        except ValueError as e:\n",
    "            print(f\"Error processing booking for {row['hotel']} on {row['expected_arrival_date']} : {num_stay_dates} {e}\")\n",
    "    expanded_df = expanded_df.sort_values('arrival_date')\n",
    "    expanded_df = expanded_df.reset_index(drop=True)\n",
    "    expanded_df['adr']= np.round(expanded_df['adr'], 2)\n",
    "           \n",
    "    expanded_df['dow'] = expanded_df.arrival_date.dt.strftime('%A')\n",
    "    expanded_df['month'] = expanded_df.arrival_date.dt.strftime('%B')\n",
    "\n",
    "    return expanded_df\n",
    "\n",
    "data['total_rns'] = data['stays_in_week_nights'] + data['stays_in_weekend_nights']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f8a024",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[(data['is_canceled'] == 0) & (data['reservation_status'] !='No-Show')] \n",
    "data = data[(data.market_segment != 'Complementary') ]\n",
    "data = data[(data.reserved_room_type == 'A') |(data.reserved_room_type == 'D') | (data.reserved_room_type == 'E')]\n",
    "\n",
    "converted_df = data_conversion(data[['hotel', 'reserved_room_type', 'expected_arrival_date', 'adr', 'room_limit', 'total_rns']])\n",
    "converted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537fbc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "@scoring_func\n",
    "def format_data(request, call=None):\n",
    "    import json\n",
    "    file_obj = FileStorage(request.files[\"file1\"])\n",
    "    file_obj.save('./input_file.csv')    \n",
    "    \n",
    "    expanded_df = pd.read_csv('./input_file.csv')\n",
    "\n",
    "    results = pd.DataFrame(columns=['month', 'hotel','room_limit', 'room_type', 'dow', 'optimal_rate', 'expected_rn','expected_rev','optimal_rate_lim_inv'])\n",
    "    hotel_types = ['Resort Hotel', 'City Hotel']\n",
    "    room_types = ['A', 'D', 'E']\n",
    "    daily_rns= expanded_df.groupby(['arrival_date','dow','month', 'hotel', 'room_type']).agg({'room_limit': 'mean', 'total_rns':'sum'}).reset_index() # ge total stays per day\n",
    "\n",
    "    daily_rns = daily_rns.groupby(['dow','month', 'hotel', 'room_type']).agg({'room_limit': 'mean','total_rns':['sum','mean','median']}).reset_index() # get Rns metrics by Dow & Month\n",
    "\n",
    "    daily_rns.columns = ['_'.join(col) for col in daily_rns.columns] #remove multi level column\n",
    "    adr_frequency = expanded_df.groupby(['dow','month','adr', 'hotel', 'room_type']).agg({'room_limit': 'mean','total_rns':'sum'})\n",
    "    adr_frequency.reset_index(inplace=True)\n",
    "    merged_df = pd.merge(adr_frequency, daily_rns,how='left',left_on=['dow','month', 'hotel', 'room_type'], right_on=['dow_','month_', 'hotel_', 'room_type_'],suffixes=('_act', '_tot'))\n",
    "\n",
    "    merged_df = merged_df.drop(['dow_','month_'],axis=1)\n",
    "\n",
    "    merged_df['probability'] = merged_df['total_rns']/merged_df['total_rns_sum']\n",
    "    merged_df['expected_rns'] = merged_df['probability'] * merged_df['total_rns_median']\n",
    "    merged_df = merged_df.sort_values(by=['dow', 'month', 'adr'], ascending=[True, True, False])\n",
    "    merged_df['expected_demand']=merged_df.groupby(['dow', 'month'])['expected_rns'].cumsum()\n",
    "    merged_df['expected_rev'] = merged_df['adr']* merged_df['expected_demand']\n",
    "    results = pd.DataFrame(columns=['month', 'hotel','room_limit', 'room_type', 'dow', 'optimal_rate', 'expected_rn','expected_rev','optimal_rate_lim_inv'])\n",
    "    months = merged_df.month.unique()\n",
    "    dow = merged_df.dow.unique()\n",
    "    for hotel in hotels:\n",
    "        for room_type in room_types:\n",
    "            for month in months:\n",
    "                for day in dow:\n",
    "                    # Get data for the specific combination\n",
    "                    data_subset = merged_df[(merged_df['dow'] == day) & \n",
    "                                            (merged_df['hotel'] == hotel) & \n",
    "                                            (merged_df['room_type'] == room_type) & \n",
    "                                            (merged_df['month'] == month)].reset_index()\n",
    "\n",
    "                    if data_subset.empty:\n",
    "                        continue\n",
    "\n",
    "                    # Remove outliers\n",
    "                    mean = data_subset['adr'].mean()\n",
    "                    std_dev = data_subset['adr'].std()\n",
    "                    data_subset['z_scores'] = np.abs((data_subset['adr'] - mean) / std_dev)\n",
    "                    data_subset = data_subset[data_subset['z_scores'] <= 2]\n",
    "\n",
    "                    # Fit demand curve\n",
    "                    x_data = data_subset['adr'].values\n",
    "                    y_data = data_subset['expected_demand'].values\n",
    "\n",
    "                    try:\n",
    "                        initial_guess = [1, 0.01, 1, 1, data_subset['total_rns_median'].values[0]]\n",
    "                        bounds = ([0, 0, 0, 0, 0], [np.inf, np.inf, np.inf, np.inf, np.inf])\n",
    "                        maxfev = 10000  # Increase the number of maximum function evaluations\n",
    "                        params, _ = curve_fit(demand_curve, x_data, y_data, bounds=bounds, p0=initial_guess, maxfev=maxfev)\n",
    "                    except RuntimeError as e:\n",
    "                        print(f\"Error fitting demand curve for {hotel}, {room_type}, {month}, {day}: {e}\")\n",
    "                        continue\n",
    "\n",
    "                    a_fit, b_fit, c_fit, d_fit, max_demand = params\n",
    "\n",
    "                    # Optimize revenue\n",
    "                    def revenue(price):\n",
    "                        return price * demand_curve(price, a_fit, b_fit, c_fit, d_fit, max_demand)\n",
    "\n",
    "                    objective = lambda price: -revenue(price)\n",
    "                    optimize = minimize_scalar(objective, bounds=(45, 200), method='bounded')\n",
    "                    optimal_price = optimize.x\n",
    "                    max_revenue = -optimize.fun\n",
    "                    expected_rns = demand_curve(optimal_price, a_fit, b_fit, c_fit, d_fit, max_demand)\n",
    "\n",
    "                    optimal_rate_lim_inv = demand_to_price(data_subset['room_limit'].mean(), a_fit, b_fit, c_fit, d_fit, max_demand)\n",
    "\n",
    "                    new_row = pd.DataFrame({'hotel': hotel,\n",
    "                                            'room_type': room_type,\n",
    "                                            'room_limit': data_subset['room_limit'].mean(),\n",
    "                                            'month': month,\n",
    "                                            'dow': day,\n",
    "                                            'optimal_rate': optimal_price,\n",
    "                                            'expected_rev': max_revenue,\n",
    "                                            'expected_rn': expected_rns,\n",
    "                                            'optimal_rate_lim_inv': optimal_rate_lim_inv}, index=[0])\n",
    "                    results = pd.concat([results, new_row], ignore_index=True)\n",
    "\n",
    "    \n",
    "    results['optimal_rate'] = results['optimal_rate'].round()\n",
    "    results['optimal_rate_lim_inv'] = results['optimal_rate_lim_inv'].round()\n",
    "\n",
    "    results['expected_rn'] = results['expected_rn'].round().astype(int)\n",
    "    results['expected_rev'] = results['expected_rev'].round()\n",
    "    combinations = list(itertools.product(hotel_types, room_types))\n",
    "    combinations_df = pd.DataFrame(combinations, columns=['hotel', 'room_type'])\n",
    "    month_dict = {month: index for index, month in enumerate(pd.date_range('2020-01-01', periods=12, freq='M').strftime('%B'), 1)}\n",
    "\n",
    "\n",
    "    new_data = pd.DataFrame()\n",
    "\n",
    "    for year in range(2020, 2024):\n",
    "        for month in month_dict.values():\n",
    "            start_date = pd.to_datetime(f'{year}-{month}-01').replace(day=1)\n",
    "            end_date = pd.to_datetime(f'{year}-{month}-01').replace(day=1) + pd.offsets.MonthEnd(0)\n",
    "            date_range = pd.date_range(start_date, end_date, freq='D')\n",
    "            df = pd.DataFrame(date_range, columns=['arrival_date'])\n",
    "            df['dow'] = df['arrival_date'].dt.day_name()\n",
    "            df['month'] = df['arrival_date'].dt.month_name()\n",
    "\n",
    "            result_df = df.assign(key=1).merge(combinations_df.assign(key=1), on='key').drop('key', axis=1)\n",
    "            new_data = pd.concat([new_data, result_df], ignore_index=True)\n",
    "\n",
    "    final_data = pd.merge(new_data, results, how='left', on=['dow', 'hotel', 'room_type', 'month'])\n",
    "    print(final_data.isna().sum())\n",
    "    final_data['room_limit'] = final_data['room_limit'].astype(int)\n",
    "    return final_data\n",
    "\n",
    "\n",
    "# req = requests.Request()\n",
    "# req.files = {'file1': 'sample.csv'}\n",
    "# score(clf, req)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2597667",
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_df.to_csv('./dates_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24f309d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "format_data(converted_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecbaf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "register_model(None, \n",
    "               format_data, \n",
    "               name=\"predict_optimal_price\", \n",
    "               description=\"predict_optimal_price\",\n",
    "               flavour=MLModelFlavours.sklearn,\n",
    "               init_script=\"\\\\n pip install fosforml \\\\n pip install fosforio[snowflake] \\\\n pip install seaborn \\\\n pip install snowflake-connector-python[pandas] \\\\n pip install joblib==1.3.2 scikit-learn=1.3.2\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a34d0ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
