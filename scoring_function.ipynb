{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "485bbc66",
   "metadata": {},
   "source": [
    "# Importing helper libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06c858f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "Collecting pip\n",
      "  Downloading pip-24.1.2-py3-none-any.whl.metadata (3.6 kB)\n",
      "Downloading pip-24.1.2-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "Successfully installed pip-24.1.2\n",
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "Collecting snowflake-snowpark-python==1.9.0\n",
      "  Using cached snowflake_snowpark_python-1.9.0-py3-none-any.whl.metadata (44 kB)\n",
      "Collecting fosforio\n",
      "  Using cached fosforio-1.0.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting fosforml\n",
      "  Downloading fosforml-1.0.8-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting xgboost\n",
      "  Using cached xgboost-2.1.0-py3-none-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting seaborn\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting python-dateutil\n",
      "  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting tqdm\n",
      "  Using cached tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting holidays\n",
      "  Using cached holidays-0.52-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting faker\n",
      "  Using cached Faker-26.0.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting snowflake-connector-python[pandas]\n",
      "  Using cached snowflake_connector_python-3.11.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (63 kB)\n",
      "Collecting setuptools>=40.6.0 (from snowflake-snowpark-python==1.9.0)\n",
      "  Using cached setuptools-70.3.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting wheel (from snowflake-snowpark-python==1.9.0)\n",
      "  Using cached wheel-0.43.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting typing-extensions<5.0.0,>=4.1.0 (from snowflake-snowpark-python==1.9.0)\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting pyyaml (from snowflake-snowpark-python==1.9.0)\n",
      "  Using cached PyYAML-6.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting cloudpickle<=2.0.0,>=1.6.0 (from snowflake-snowpark-python==1.9.0)\n",
      "  Using cached cloudpickle-2.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting asn1crypto<2.0.0,>0.24.0 (from snowflake-connector-python[pandas])\n",
      "  Using cached asn1crypto-1.5.1-py2.py3-none-any.whl.metadata (13 kB)\n",
      "Collecting cffi<2.0.0,>=1.9 (from snowflake-connector-python[pandas])\n",
      "  Using cached cffi-1.16.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting cryptography<43.0.0,>=3.1.0 (from snowflake-connector-python[pandas])\n",
      "  Using cached cryptography-42.0.8-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting pyOpenSSL<25.0.0,>=16.2.0 (from snowflake-connector-python[pandas])\n",
      "  Using cached pyOpenSSL-24.1.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pyjwt<3.0.0 (from snowflake-connector-python[pandas])\n",
      "  Using cached PyJWT-2.8.0-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting pytz (from snowflake-connector-python[pandas])\n",
      "  Using cached pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting requests<3.0.0 (from snowflake-connector-python[pandas])\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting packaging (from snowflake-connector-python[pandas])\n",
      "  Using cached packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from snowflake-connector-python[pandas])\n",
      "  Using cached charset_normalizer-3.3.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (33 kB)\n",
      "Collecting idna<4,>=2.5 (from snowflake-connector-python[pandas])\n",
      "  Using cached idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting certifi>=2017.4.17 (from snowflake-connector-python[pandas])\n",
      "  Using cached certifi-2024.7.4-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting filelock<4,>=3.5 (from snowflake-connector-python[pandas])\n",
      "  Using cached filelock-3.15.4-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting sortedcontainers>=2.4.0 (from snowflake-connector-python[pandas])\n",
      "  Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting platformdirs<5.0.0,>=2.6.0 (from snowflake-connector-python[pandas])\n",
      "  Using cached platformdirs-4.2.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting tomlkit (from snowflake-connector-python[pandas])\n",
      "  Using cached tomlkit-0.13.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting urllib3<2.0.0,>=1.21.1 (from snowflake-connector-python[pandas])\n",
      "  Using cached urllib3-1.26.19-py2.py3-none-any.whl.metadata (49 kB)\n",
      "Collecting pandas<3.0.0,>=1.0.0 (from snowflake-connector-python[pandas])\n",
      "  Using cached pandas-2.2.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Collecting pyarrow (from snowflake-connector-python[pandas])\n",
      "  Using cached pyarrow-16.1.0-cp39-cp39-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting pandas<3.0.0,>=1.0.0 (from snowflake-connector-python[pandas])\n",
      "  Using cached pandas-2.0.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting tzdata>=2022.1 (from pandas<3.0.0,>=1.0.0->snowflake-connector-python[pandas])\n",
      "  Using cached tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting numpy>=1.20.3 (from pandas<3.0.0,>=1.0.0->snowflake-connector-python[pandas])\n",
      "  Using cached numpy-2.0.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "INFO: pip is looking at multiple versions of fosforml to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting fosforml\n",
      "  Using cached fosforml-1.0.7-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Using cached fosforml-1.0.6-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Using cached fosforml-1.0.5-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Using cached fosforml-1.0.4-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Using cached fosforml-1.0.3-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Using cached fosforml-1.0.2-py3-none-any.whl.metadata (878 bytes)\n",
      "  Using cached fosforml-1.0.1-py3-none-any.whl.metadata (1.5 kB)\n",
      "INFO: pip is still looking at multiple versions of fosforml to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached fosforml-1.0.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting cloudpickle<=2.0.0,>=1.6.0 (from snowflake-snowpark-python==1.9.0)\n",
      "  Using cached cloudpickle-1.6.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting requests-toolbelt==0.9.1 (from fosforml)\n",
      "  Using cached requests_toolbelt-0.9.1-py2.py3-none-any.whl.metadata (13 kB)\n",
      "Collecting shutils==0.1.0 (from fosforml)\n",
      "  Using cached shutils-0.1.0-py3-none-any.whl\n",
      "Collecting pyyaml (from snowflake-snowpark-python==1.9.0)\n",
      "  Using cached PyYAML-6.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting mosaic-utils (from fosforml)\n",
      "  Using cached mosaic_utils-1.0.2-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<2.0.0,>=1.21.1 (from snowflake-connector-python[pandas])\n",
      "  Using cached urllib3-1.26.15-py2.py3-none-any.whl.metadata (48 kB)\n",
      "Collecting configparser (from shutils==0.1.0->fosforml)\n",
      "  Using cached configparser-7.0.0-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting pymysql (from shutils==0.1.0->fosforml)\n",
      "  Using cached PyMySQL-1.1.1-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting nvidia-nccl-cu12 (from xgboost)\n",
      "  Using cached nvidia_nccl_cu12-2.22.3-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting scipy (from xgboost)\n",
      "  Using cached scipy-1.13.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "Collecting matplotlib!=3.6.1,>=3.4 (from seaborn)\n",
      "  Using cached matplotlib-3.9.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting six>=1.5 (from python-dateutil)\n",
      "  Using cached six-1.16.0-py2.py3-none-any.whl.metadata (1.8 kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pycparser (from cffi<2.0.0,>=1.9->snowflake-connector-python[pandas])\n",
      "  Using cached pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Using cached contourpy-1.2.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Using cached fonttools-4.53.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (162 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Using cached kiwisolver-1.4.5-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting pillow>=8 (from matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Using cached pillow-10.4.0-cp39-cp39-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Using cached pyparsing-3.1.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting importlib-resources>=3.2.0 (from matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Using cached importlib_resources-6.4.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting scikit-learn==1.2.1 (from mosaic-utils->fosforml)\n",
      "  Using cached scikit_learn-1.2.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting joblib>=1.1.1 (from scikit-learn==1.2.1->mosaic-utils->fosforml)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn==1.2.1->mosaic-utils->fosforml)\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting zipp>=3.1.0 (from importlib-resources>=3.2.0->matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Using cached zipp-3.19.2-py3-none-any.whl.metadata (3.6 kB)\n",
      "Using cached snowflake_snowpark_python-1.9.0-py3-none-any.whl (327 kB)\n",
      "Using cached fosforio-1.0.2-py3-none-any.whl (20 kB)\n",
      "Using cached pandas-2.0.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
      "Using cached fosforml-1.0.0-py3-none-any.whl (42 kB)\n",
      "Using cached cloudpickle-1.6.0-py3-none-any.whl (23 kB)\n",
      "Using cached PyYAML-6.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (661 kB)\n",
      "Using cached requests_toolbelt-0.9.1-py2.py3-none-any.whl (54 kB)\n",
      "Using cached urllib3-1.26.15-py2.py3-none-any.whl (140 kB)\n",
      "Using cached xgboost-2.1.0-py3-none-manylinux_2_28_x86_64.whl (153.9 MB)\n",
      "Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "Using cached tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "Using cached holidays-0.52-py3-none-any.whl (1.0 MB)\n",
      "Using cached Faker-26.0.0-py3-none-any.whl (1.8 MB)\n",
      "Using cached asn1crypto-1.5.1-py2.py3-none-any.whl (105 kB)\n",
      "Using cached certifi-2024.7.4-py3-none-any.whl (162 kB)\n",
      "Using cached cffi-1.16.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (443 kB)\n",
      "Using cached charset_normalizer-3.3.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
      "Using cached cryptography-42.0.8-cp39-abi3-manylinux_2_28_x86_64.whl (3.9 MB)\n",
      "Using cached filelock-3.15.4-py3-none-any.whl (16 kB)\n",
      "Using cached idna-3.7-py3-none-any.whl (66 kB)\n",
      "Using cached matplotlib-3.9.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
      "Using cached numpy-2.0.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.3 MB)\n",
      "Using cached packaging-24.1-py3-none-any.whl (53 kB)\n",
      "Using cached platformdirs-4.2.2-py3-none-any.whl (18 kB)\n",
      "Using cached PyJWT-2.8.0-py3-none-any.whl (22 kB)\n",
      "Using cached pyOpenSSL-24.1.0-py3-none-any.whl (56 kB)\n",
      "Using cached pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached setuptools-70.3.0-py3-none-any.whl (931 kB)\n",
      "Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Using cached snowflake_connector_python-3.11.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
      "Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Using cached mosaic_utils-1.0.2-py2.py3-none-any.whl (70 kB)\n",
      "Using cached scikit_learn-1.2.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.6 MB)\n",
      "Using cached scipy-1.13.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
      "Using cached nvidia_nccl_cu12-2.22.3-py3-none-manylinux2014_x86_64.whl (190.9 MB)\n",
      "Using cached pyarrow-16.1.0-cp39-cp39-manylinux_2_28_x86_64.whl (40.8 MB)\n",
      "Using cached tomlkit-0.13.0-py3-none-any.whl (37 kB)\n",
      "Using cached wheel-0.43.0-py3-none-any.whl (65 kB)\n",
      "Using cached contourpy-1.2.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (304 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached fonttools-4.53.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "Using cached importlib_resources-6.4.0-py3-none-any.whl (38 kB)\n",
      "Using cached kiwisolver-1.4.5-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "Using cached pillow-10.4.0-cp39-cp39-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "Using cached pyparsing-3.1.2-py3-none-any.whl (103 kB)\n",
      "Using cached tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "Using cached configparser-7.0.0-py3-none-any.whl (16 kB)\n",
      "Using cached pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Using cached PyMySQL-1.1.1-py3-none-any.whl (44 kB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Using cached zipp-3.19.2-py3-none-any.whl (9.0 kB)\n",
      "Installing collected packages: sortedcontainers, pytz, asn1crypto, zipp, wheel, urllib3, tzdata, typing-extensions, tqdm, tomlkit, threadpoolctl, six, setuptools, pyyaml, pyparsing, pymysql, pyjwt, pycparser, platformdirs, pillow, packaging, nvidia-nccl-cu12, numpy, kiwisolver, joblib, idna, fonttools, filelock, cycler, configparser, cloudpickle, charset-normalizer, certifi, shutils, scipy, requests, python-dateutil, pyarrow, importlib-resources, contourpy, cffi, xgboost, scikit-learn, requests-toolbelt, pandas, matplotlib, holidays, faker, cryptography, seaborn, pyOpenSSL, mosaic-utils, fosforio, snowflake-connector-python, fosforml, snowflake-snowpark-python\n",
      "  Installing build dependencies ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpip subprocess to install build dependencies\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[38 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m Collecting meson-python<0.18.0,>=0.15.0\n",
      "  \u001b[31m   \u001b[0m   Downloading meson_python-0.16.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "  \u001b[31m   \u001b[0m Collecting Cython<3.1.0,>=3.0.8\n",
      "  \u001b[31m   \u001b[0m   Downloading Cython-3.0.10-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
      "  \u001b[31m   \u001b[0m Collecting pybind11<2.13.0,>=2.12.0\n",
      "  \u001b[31m   \u001b[0m   Downloading pybind11-2.12.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "  \u001b[31m   \u001b[0m Collecting pythran<0.16.0,>=0.14.0\n",
      "  \u001b[31m   \u001b[0m   Downloading pythran-0.15.0-py3-none-any.whl.metadata (7.8 kB)\n",
      "  \u001b[31m   \u001b[0m Collecting numpy<2.3,>=2.0.0rc1\n",
      "  \u001b[31m   \u001b[0m   Using cached numpy-2.0.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "  \u001b[31m   \u001b[0m Collecting meson>=0.63.3 (from meson-python<0.18.0,>=0.15.0)\n",
      "  \u001b[31m   \u001b[0m   Downloading meson-1.5.0.tar.gz (2.3 MB)\n",
      "  \u001b[31m   \u001b[0m      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.3/2.3 MB 30.6 MB/s eta 0:00:00\n",
      "  \u001b[31m   \u001b[0m   Installing build dependencies: started\n",
      "  \u001b[31m   \u001b[0m   Installing build dependencies: finished with status 'error'\n",
      "  \u001b[31m   \u001b[0m   error: subprocess-exited-with-error\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m   × pip subprocess to install build dependencies did not run successfully.\n",
      "  \u001b[31m   \u001b[0m   │ exit code: 1\n",
      "  \u001b[31m   \u001b[0m   ╰─> [8 lines of output]\n",
      "  \u001b[31m   \u001b[0m       Collecting setuptools>=42\n",
      "  \u001b[31m   \u001b[0m         Using cached setuptools-70.3.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "  \u001b[31m   \u001b[0m       Collecting wheel\n",
      "  \u001b[31m   \u001b[0m         Using cached wheel-0.43.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "  \u001b[31m   \u001b[0m       Using cached setuptools-70.3.0-py3-none-any.whl (931 kB)\n",
      "  \u001b[31m   \u001b[0m       Using cached wheel-0.43.0-py3-none-any.whl (65 kB)\n",
      "  \u001b[31m   \u001b[0m       Installing collected packages: wheel, setuptools\n",
      "  \u001b[31m   \u001b[0m       ERROR: Cannot set --home and --prefix together\n",
      "  \u001b[31m   \u001b[0m       [end of output]\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m   note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  \u001b[31m   \u001b[0m error: subprocess-exited-with-error\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m × pip subprocess to install build dependencies did not run successfully.\n",
      "  \u001b[31m   \u001b[0m │ exit code: 1\n",
      "  \u001b[31m   \u001b[0m ╰─> See above for output.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m \u001b[32mpip subprocess to install build dependencies\u001b[0m did not run successfully.\n",
      "\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25hWARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "Found existing installation: urllib3 1.26.15\n",
      "Uninstalling urllib3-1.26.15:\n",
      "  Successfully uninstalled urllib3-1.26.15\n",
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "Collecting urllib3==1.26.15\n",
      "  Using cached urllib3-1.26.15-py2.py3-none-any.whl.metadata (48 kB)\n",
      "Using cached urllib3-1.26.15-py2.py3-none-any.whl (140 kB)\n",
      "Installing collected packages: urllib3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "jsonschema-path 0.3.2 requires referencing<0.32.0,>=0.28.0, but you have referencing 0.33.0 which is incompatible.\n",
      "mosaic-ai-client 1.0.0 requires matplotlib==3.1.1, but you have matplotlib 3.6.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed urllib3-1.26.15\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/urllib3 already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install \"snowflake-connector-python[pandas]\" \"snowflake-snowpark-python[pandas]\" snowflake-snowpark-python==1.9.0 fosforio fosforml xgboost seaborn python-dateutil tqdm holidays faker\n",
    "!pip install --upgrade --q snowflake-snowpark-python==1.9.0\n",
    "!pip install --no-binary scipy scikit-learn\n",
    "!pip uninstall urllib3 -y\n",
    "!pip install urllib3==1.26.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf832a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade numpy==1.25.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c459a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy                      1.25.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip list | grep -i numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a3e66ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: scipy 1.13.1\n",
      "Uninstalling scipy-1.13.1:\n",
      "  Successfully uninstalled scipy-1.13.1\n",
      "Found existing installation: scikit-learn 1.2.1\n",
      "Uninstalling scikit-learn-1.2.1:\n",
      "  Successfully uninstalled scikit-learn-1.2.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip uninstall -y scipy scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b034b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scikit-learn               1.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip list | grep -i scikit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03dac850",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection manager service url initialised to http://fdc-project-manager:80/project-manager\n",
      "If you need to update its value then update the variable CONNECTION_MANAGER_BASE_URL in os env.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/pip_packages/_distutils_hack/__init__.py:32: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from fosforio import snowflake\n",
    "from fosforml import *\n",
    "from fosforml.constants import MLModelFlavours\n",
    "from fosforio import get_dataframe\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "import numpy as np\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "from joblib import dump, load\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import calendar\n",
    "\n",
    "from time import sleep\n",
    "import configparser\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import datetime\n",
    "from dateutil.easter import easter\n",
    "from scipy.optimize import minimize_scalar\n",
    "from scipy.optimize import curve_fit\n",
    "import holidays, itertools\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28f4004",
   "metadata": {},
   "source": [
    "# Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22b5a014",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./bookings_transformed_latest.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75255b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "\n",
    "# Define the demand curve function\n",
    "def demand_curve(x, a, b, c, d, max_demand):\n",
    "    demand = a * np.exp(-b * x) + c\n",
    "    demand = np.where(x <= max_demand, np.minimum(demand, max_demand), demand)\n",
    "    return demand + d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "046d8280",
   "metadata": {},
   "outputs": [],
   "source": [
    "def revenue(price):\n",
    "    return price * demand_curve(price, a_fit, b_fit,c_fit,d_fit,max_demand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "928f97a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import brentq\n",
    "\n",
    "def demand_to_price(num_rooms, a, b, c, d, max_demand):\n",
    "    def root_func(x):\n",
    "        return num_rooms - (a * np.exp(-b * x) + c)\n",
    "\n",
    "    try:\n",
    "        price = brentq(root_func, 0, 200)  # Adjust the interval bounds as needed\n",
    "    except ValueError:\n",
    "        # Fallback to default price if no root is found\n",
    "        price_range=(0, 200)\n",
    "        price = np.random.uniform(*price_range)\n",
    "\n",
    "    return price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27b44e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_holiday_dates(start_year, end_year):\n",
    "    holidays = {}\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        holidays[datetime.date(year, 1, 1)] = 'new_year'\n",
    "        easter_date = easter(year)\n",
    "        holidays[easter_date] = 'easter'\n",
    "        holidays[datetime.date(year, 12, 25)] = 'christmas'\n",
    "    return holidays\n",
    "\n",
    "holidays = generate_holiday_dates(2020, 2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f830a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_conversion(data):\n",
    "    import holidays\n",
    "    hotels = data['hotel'].unique()\n",
    "    room_types = data['reserved_room_type'].unique()\n",
    "    expanded_df = pd.DataFrame()\n",
    "    for _, row in data.iterrows():\n",
    "        num_stay_dates = row['total_rns']\n",
    "        try:\n",
    "            # Create a row for each stay date\n",
    "            expanded_booking = pd.DataFrame({\n",
    "                'hotel': row['hotel'],\n",
    "                'room_type': row['reserved_room_type'], \n",
    "                'arrival_date': pd.date_range(start=row['expected_arrival_date'], periods=num_stay_dates),\n",
    "                'total_rns': 1,\n",
    "                'adr': row['adr'],\n",
    "                'room_limit': row['room_limit']\n",
    "            })\n",
    "\n",
    "            # Append the stay date information to the new dataframe\n",
    "            expanded_df = pd.concat([expanded_df, expanded_booking], ignore_index=True)\n",
    "        except ValueError as e:\n",
    "            print(f\"Error processing booking for {row['hotel']} on {row['expected_arrival_date']} : {num_stay_dates} {e}\")\n",
    "    expanded_df = expanded_df.sort_values('arrival_date')\n",
    "    expanded_df = expanded_df.reset_index(drop=True)\n",
    "    expanded_df['adr']= np.round(expanded_df['adr'], 2)\n",
    "           \n",
    "    expanded_df['dow'] = expanded_df.arrival_date.dt.strftime('%A')\n",
    "    expanded_df['month'] = expanded_df.arrival_date.dt.strftime('%B')\n",
    "\n",
    "    return expanded_df\n",
    "\n",
    "data['total_rns'] = data['stays_in_week_nights'] + data['stays_in_weekend_nights']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9f8a024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing booking for City Hotel on 29-02-2022 : 1 day is out of range for month\n",
      "Error processing booking for Resort Hotel on 29-02-2022 : 1 day is out of range for month\n",
      "Error processing booking for City Hotel on 29-02-2022 : 1 day is out of range for month\n",
      "Error processing booking for City Hotel on 29-02-2022 : 1 day is out of range for month\n",
      "Error processing booking for City Hotel on 29-02-2022 : 1 day is out of range for month\n",
      "Error processing booking for Resort Hotel on 29-02-2022 : 1 day is out of range for month\n",
      "Error processing booking for City Hotel on 29-02-2022 : 1 day is out of range for month\n",
      "Error processing booking for City Hotel on 29-02-2022 : 1 day is out of range for month\n",
      "Error processing booking for Resort Hotel on 29-02-2022 : 1 day is out of range for month\n",
      "Error processing booking for City Hotel on 29-02-2022 : 2 day is out of range for month\n",
      "Error processing booking for Resort Hotel on 29-02-2022 : 2 day is out of range for month\n",
      "Error processing booking for City Hotel on 29-02-2022 : 2 day is out of range for month\n",
      "Error processing booking for Resort Hotel on 29-02-2022 : 2 day is out of range for month\n",
      "Error processing booking for City Hotel on 29-02-2022 : 2 day is out of range for month\n",
      "Error processing booking for City Hotel on 29-02-2022 : 2 day is out of range for month\n",
      "Error processing booking for City Hotel on 29-02-2022 : 2 day is out of range for month\n",
      "Error processing booking for City Hotel on 29-02-2022 : 2 day is out of range for month\n",
      "Error processing booking for City Hotel on 29-02-2022 : 3 day is out of range for month\n",
      "Error processing booking for City Hotel on 29-02-2022 : 3 day is out of range for month\n",
      "Error processing booking for Resort Hotel on 29-02-2022 : 3 day is out of range for month\n",
      "Error processing booking for City Hotel on 29-02-2022 : 3 day is out of range for month\n",
      "Error processing booking for City Hotel on 29-02-2022 : 3 day is out of range for month\n",
      "Error processing booking for City Hotel on 29-02-2022 : 3 day is out of range for month\n",
      "Error processing booking for Resort Hotel on 29-02-2022 : 3 day is out of range for month\n",
      "Error processing booking for City Hotel on 29-02-2022 : 3 day is out of range for month\n",
      "Error processing booking for City Hotel on 29-02-2022 : 3 day is out of range for month\n",
      "Error processing booking for Resort Hotel on 29-02-2022 : 3 day is out of range for month\n",
      "Error processing booking for Resort Hotel on 29-02-2022 : 3 day is out of range for month\n",
      "Error processing booking for City Hotel on 29-02-2022 : 3 day is out of range for month\n",
      "Error processing booking for Resort Hotel on 29-02-2022 : 3 day is out of range for month\n",
      "Error processing booking for Resort Hotel on 29-02-2022 : 3 day is out of range for month\n",
      "Error processing booking for Resort Hotel on 29-02-2022 : 3 day is out of range for month\n",
      "Error processing booking for City Hotel on 29-02-2022 : 3 day is out of range for month\n",
      "Error processing booking for Resort Hotel on 29-02-2022 : 3 day is out of range for month\n",
      "Error processing booking for Resort Hotel on 29-02-2022 : 3 day is out of range for month\n",
      "Error processing booking for City Hotel on 29-02-2022 : 3 day is out of range for month\n",
      "Error processing booking for Resort Hotel on 29-02-2022 : 3 day is out of range for month\n",
      "Error processing booking for City Hotel on 29-02-2022 : 4 day is out of range for month\n",
      "Error processing booking for Resort Hotel on 29-02-2022 : 4 day is out of range for month\n",
      "Error processing booking for City Hotel on 29-02-2022 : 4 day is out of range for month\n",
      "Error processing booking for Resort Hotel on 29-02-2022 : 4 day is out of range for month\n",
      "Error processing booking for Resort Hotel on 29-02-2022 : 4 day is out of range for month\n",
      "Error processing booking for City Hotel on 29-02-2022 : 4 day is out of range for month\n",
      "Error processing booking for Resort Hotel on 29-02-2022 : 4 day is out of range for month\n",
      "Error processing booking for Resort Hotel on 29-02-2022 : 4 day is out of range for month\n",
      "Error processing booking for City Hotel on 29-02-2022 : 4 day is out of range for month\n",
      "Error processing booking for Resort Hotel on 29-02-2022 : 4 day is out of range for month\n",
      "Error processing booking for Resort Hotel on 29-02-2022 : 4 day is out of range for month\n",
      "Error processing booking for Resort Hotel on 29-02-2022 : 4 day is out of range for month\n",
      "Error processing booking for City Hotel on 29-02-2022 : 4 day is out of range for month\n",
      "Error processing booking for City Hotel on 29-02-2022 : 5 day is out of range for month\n",
      "Error processing booking for City Hotel on 29-02-2022 : 6 day is out of range for month\n",
      "Error processing booking for City Hotel on 29-02-2022 : 10 day is out of range for month\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hotel</th>\n",
       "      <th>room_type</th>\n",
       "      <th>arrival_date</th>\n",
       "      <th>total_rns</th>\n",
       "      <th>adr</th>\n",
       "      <th>room_limit</th>\n",
       "      <th>dow</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>City Hotel</td>\n",
       "      <td>A</td>\n",
       "      <td>2021-01-07</td>\n",
       "      <td>1</td>\n",
       "      <td>76.50</td>\n",
       "      <td>150</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>January</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>City Hotel</td>\n",
       "      <td>A</td>\n",
       "      <td>2021-01-07</td>\n",
       "      <td>1</td>\n",
       "      <td>101.50</td>\n",
       "      <td>150</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>January</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>City Hotel</td>\n",
       "      <td>A</td>\n",
       "      <td>2021-01-07</td>\n",
       "      <td>1</td>\n",
       "      <td>101.50</td>\n",
       "      <td>150</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>January</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>A</td>\n",
       "      <td>2021-01-07</td>\n",
       "      <td>1</td>\n",
       "      <td>98.00</td>\n",
       "      <td>150</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>January</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>City Hotel</td>\n",
       "      <td>A</td>\n",
       "      <td>2021-01-07</td>\n",
       "      <td>1</td>\n",
       "      <td>80.00</td>\n",
       "      <td>150</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>January</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232598</th>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>A</td>\n",
       "      <td>2023-12-18</td>\n",
       "      <td>1</td>\n",
       "      <td>169.00</td>\n",
       "      <td>150</td>\n",
       "      <td>Monday</td>\n",
       "      <td>December</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232599</th>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>A</td>\n",
       "      <td>2023-12-18</td>\n",
       "      <td>1</td>\n",
       "      <td>40.95</td>\n",
       "      <td>150</td>\n",
       "      <td>Monday</td>\n",
       "      <td>December</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232600</th>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>A</td>\n",
       "      <td>2023-12-18</td>\n",
       "      <td>1</td>\n",
       "      <td>151.00</td>\n",
       "      <td>150</td>\n",
       "      <td>Monday</td>\n",
       "      <td>December</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232601</th>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>E</td>\n",
       "      <td>2023-12-19</td>\n",
       "      <td>1</td>\n",
       "      <td>158.00</td>\n",
       "      <td>60</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>December</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232602</th>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>E</td>\n",
       "      <td>2023-12-19</td>\n",
       "      <td>1</td>\n",
       "      <td>172.00</td>\n",
       "      <td>60</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>December</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>232603 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               hotel room_type arrival_date  total_rns     adr  room_limit   \n",
       "0         City Hotel         A   2021-01-07          1   76.50         150  \\\n",
       "1         City Hotel         A   2021-01-07          1  101.50         150   \n",
       "2         City Hotel         A   2021-01-07          1  101.50         150   \n",
       "3       Resort Hotel         A   2021-01-07          1   98.00         150   \n",
       "4         City Hotel         A   2021-01-07          1   80.00         150   \n",
       "...              ...       ...          ...        ...     ...         ...   \n",
       "232598  Resort Hotel         A   2023-12-18          1  169.00         150   \n",
       "232599  Resort Hotel         A   2023-12-18          1   40.95         150   \n",
       "232600  Resort Hotel         A   2023-12-18          1  151.00         150   \n",
       "232601  Resort Hotel         E   2023-12-19          1  158.00          60   \n",
       "232602  Resort Hotel         E   2023-12-19          1  172.00          60   \n",
       "\n",
       "             dow     month  \n",
       "0       Thursday   January  \n",
       "1       Thursday   January  \n",
       "2       Thursday   January  \n",
       "3       Thursday   January  \n",
       "4       Thursday   January  \n",
       "...          ...       ...  \n",
       "232598    Monday  December  \n",
       "232599    Monday  December  \n",
       "232600    Monday  December  \n",
       "232601   Tuesday  December  \n",
       "232602   Tuesday  December  \n",
       "\n",
       "[232603 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[(data['is_canceled'] == 0) & (data['reservation_status'] !='No-Show')] \n",
    "data = data[(data.market_segment != 'Complementary') ]\n",
    "data = data[(data.reserved_room_type == 'A') |(data.reserved_room_type == 'D') | (data.reserved_room_type == 'E')]\n",
    "\n",
    "converted_df = data_conversion(data[['hotel', 'reserved_room_type', 'expected_arrival_date', 'adr', 'room_limit', 'total_rns']])\n",
    "converted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "537fbc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "@scoring_func\n",
    "def format_data(request, call=None):\n",
    "    import json\n",
    "    file_obj = FileStorage(request.files[\"file1\"])\n",
    "    file_obj.save('./input_file.csv')    \n",
    "    \n",
    "    expanded_df = pd.read_csv('./input_file.csv')\n",
    "\n",
    "    results = pd.DataFrame(columns=['month', 'hotel','room_limit', 'room_type', 'dow', 'optimal_rate', 'expected_rn','expected_rev','optimal_rate_lim_inv'])\n",
    "    hotel_types = ['Resort Hotel', 'City Hotel']\n",
    "    room_types = ['A', 'D', 'E']\n",
    "    daily_rns= expanded_df.groupby(['arrival_date','dow','month', 'hotel', 'room_type']).agg({'room_limit': 'mean', 'total_rns':'sum'}).reset_index() # ge total stays per day\n",
    "\n",
    "    daily_rns = daily_rns.groupby(['dow','month', 'hotel', 'room_type']).agg({'room_limit': 'mean','total_rns':['sum','mean','median']}).reset_index() # get Rns metrics by Dow & Month\n",
    "\n",
    "    daily_rns.columns = ['_'.join(col) for col in daily_rns.columns] #remove multi level column\n",
    "    adr_frequency = expanded_df.groupby(['dow','month','adr', 'hotel', 'room_type']).agg({'room_limit': 'mean','total_rns':'sum'})\n",
    "    adr_frequency.reset_index(inplace=True)\n",
    "    merged_df = pd.merge(adr_frequency, daily_rns,how='left',left_on=['dow','month', 'hotel', 'room_type'], right_on=['dow_','month_', 'hotel_', 'room_type_'],suffixes=('_act', '_tot'))\n",
    "\n",
    "    merged_df = merged_df.drop(['dow_','month_'],axis=1)\n",
    "\n",
    "    merged_df['probability'] = merged_df['total_rns']/merged_df['total_rns_sum']\n",
    "    merged_df['expected_rns'] = merged_df['probability'] * merged_df['total_rns_median']\n",
    "    merged_df = merged_df.sort_values(by=['dow', 'month', 'adr'], ascending=[True, True, False])\n",
    "    merged_df['expected_demand']=merged_df.groupby(['dow', 'month'])['expected_rns'].cumsum()\n",
    "    merged_df['expected_rev'] = merged_df['adr']* merged_df['expected_demand']\n",
    "    results = pd.DataFrame(columns=['month', 'hotel','room_limit', 'room_type', 'dow', 'optimal_rate', 'expected_rn','expected_rev','optimal_rate_lim_inv'])\n",
    "    months = merged_df.month.unique()\n",
    "    dow = merged_df.dow.unique()\n",
    "    for hotel in hotels:\n",
    "        for room_type in room_types:\n",
    "            for month in months:\n",
    "                for day in dow:\n",
    "                    # Get data for the specific combination\n",
    "                    data_subset = merged_df[(merged_df['dow'] == day) & \n",
    "                                            (merged_df['hotel'] == hotel) & \n",
    "                                            (merged_df['room_type'] == room_type) & \n",
    "                                            (merged_df['month'] == month)].reset_index()\n",
    "\n",
    "                    if data_subset.empty:\n",
    "                        continue\n",
    "\n",
    "                    # Remove outliers\n",
    "                    mean = data_subset['adr'].mean()\n",
    "                    std_dev = data_subset['adr'].std()\n",
    "                    data_subset['z_scores'] = np.abs((data_subset['adr'] - mean) / std_dev)\n",
    "                    data_subset = data_subset[data_subset['z_scores'] <= 2]\n",
    "\n",
    "                    # Fit demand curve\n",
    "                    x_data = data_subset['adr'].values\n",
    "                    y_data = data_subset['expected_demand'].values\n",
    "\n",
    "                    try:\n",
    "                        initial_guess = [1, 0.01, 1, 1, data_subset['total_rns_median'].values[0]]\n",
    "                        bounds = ([0, 0, 0, 0, 0], [np.inf, np.inf, np.inf, np.inf, np.inf])\n",
    "                        maxfev = 10000  # Increase the number of maximum function evaluations\n",
    "                        params, _ = curve_fit(demand_curve, x_data, y_data, bounds=bounds, p0=initial_guess, maxfev=maxfev)\n",
    "                    except RuntimeError as e:\n",
    "                        print(f\"Error fitting demand curve for {hotel}, {room_type}, {month}, {day}: {e}\")\n",
    "                        continue\n",
    "\n",
    "                    a_fit, b_fit, c_fit, d_fit, max_demand = params\n",
    "\n",
    "                    # Optimize revenue\n",
    "                    def revenue(price):\n",
    "                        return price * demand_curve(price, a_fit, b_fit, c_fit, d_fit, max_demand)\n",
    "\n",
    "                    objective = lambda price: -revenue(price)\n",
    "                    optimize = minimize_scalar(objective, bounds=(45, 200), method='bounded')\n",
    "                    optimal_price = optimize.x\n",
    "                    max_revenue = -optimize.fun\n",
    "                    expected_rns = demand_curve(optimal_price, a_fit, b_fit, c_fit, d_fit, max_demand)\n",
    "\n",
    "                    optimal_rate_lim_inv = demand_to_price(data_subset['room_limit'].mean(), a_fit, b_fit, c_fit, d_fit, max_demand)\n",
    "\n",
    "                    new_row = pd.DataFrame({'hotel': hotel,\n",
    "                                            'room_type': room_type,\n",
    "                                            'room_limit': data_subset['room_limit'].mean(),\n",
    "                                            'month': month,\n",
    "                                            'dow': day,\n",
    "                                            'optimal_rate': optimal_price,\n",
    "                                            'expected_rev': max_revenue,\n",
    "                                            'expected_rn': expected_rns,\n",
    "                                            'optimal_rate_lim_inv': optimal_rate_lim_inv}, index=[0])\n",
    "                    results = pd.concat([results, new_row], ignore_index=True)\n",
    "\n",
    "    \n",
    "    results['optimal_rate'] = results['optimal_rate'].round()\n",
    "    results['optimal_rate_lim_inv'] = results['optimal_rate_lim_inv'].round()\n",
    "\n",
    "    results['expected_rn'] = results['expected_rn'].round().astype(int)\n",
    "    results['expected_rev'] = results['expected_rev'].round()\n",
    "    combinations = list(itertools.product(hotel_types, room_types))\n",
    "    combinations_df = pd.DataFrame(combinations, columns=['hotel', 'room_type'])\n",
    "    month_dict = {month: index for index, month in enumerate(pd.date_range('2020-01-01', periods=12, freq='M').strftime('%B'), 1)}\n",
    "\n",
    "\n",
    "    new_data = pd.DataFrame()\n",
    "\n",
    "    for year in range(2020, 2024):\n",
    "        for month in month_dict.values():\n",
    "            start_date = pd.to_datetime(f'{year}-{month}-01').replace(day=1)\n",
    "            end_date = pd.to_datetime(f'{year}-{month}-01').replace(day=1) + pd.offsets.MonthEnd(0)\n",
    "            date_range = pd.date_range(start_date, end_date, freq='D')\n",
    "            df = pd.DataFrame(date_range, columns=['arrival_date'])\n",
    "            df['dow'] = df['arrival_date'].dt.day_name()\n",
    "            df['month'] = df['arrival_date'].dt.month_name()\n",
    "\n",
    "            result_df = df.assign(key=1).merge(combinations_df.assign(key=1), on='key').drop('key', axis=1)\n",
    "            new_data = pd.concat([new_data, result_df], ignore_index=True)\n",
    "\n",
    "    final_data = pd.merge(new_data, results, how='left', on=['dow', 'hotel', 'room_type', 'month'])\n",
    "    print(final_data.isna().sum())\n",
    "    final_data['room_limit'] = final_data['room_limit'].astype(int)\n",
    "    return final_data\n",
    "\n",
    "\n",
    "# req = requests.Request()\n",
    "# req.files = {'file1': 'sample.csv'}\n",
    "# score(clf, req)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2597667",
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_df.to_csv('./dates_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24f309d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "format_data(converted_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ecbaf70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d47912dac9be4126836cb0174e0d5c60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<style>.grad_1{background: #2468a4;} .grad_2{ color:white; background: #2468a4;}</s…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "register_model(None, \n",
    "               format_data, \n",
    "               name=\"predict_optimal_price_1\", \n",
    "               description=\"predict_optimal_price_1\",\n",
    "               flavour=MLModelFlavours.sklearn,\n",
    "               init_script=\"\\\\n pip install fosforml \\\\n pip install fosforio[snowflake] \\\\n pip install seaborn \\\\n pip install snowflake-connector-python[pandas] \\\\n pip install joblib==1.3.2 scikit-learn=1.3.2\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a34d0ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
